{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "from pathlib import Path\n",
    "# from typing import Optional, Tuple\n",
    "# import cv2\n",
    "# import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from PIL import Image\n",
    "from scipy.sparse.linalg import eigsh\n",
    "# from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# from torchvision.utils import draw_bounding_boxes\n",
    "from tqdm import tqdm\n",
    "import extract_utils as utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from scipy.ndimage import affine_transform\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract Eigen Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_root=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/images\"\n",
    "features_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16\"\n",
    "output_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/eigs_dot1PCA64pred_dssubmax_10_histbhattacharya\"\n",
    "which_matrix= 'laplacian'\n",
    "which_color_matrix= 'knn'\n",
    "which_features= 'k'\n",
    "normalize=True\n",
    "threshold_at_zero=True\n",
    "lapnorm= True\n",
    "K= 5\n",
    "image_downsample_factor = None\n",
    "image_color_lambda = 0.0\n",
    "multiprocessing = 0\n",
    "batch_size=2\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Incorporating SimSiam with PCA projector and a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def bhattacharyya_distance(hist1, hist2):\n",
    "    \"\"\"\n",
    "    Compute the Bhattacharyya distance between two histograms.\n",
    "    Args:\n",
    "        hist1 (torch.Tensor): Histogram 1.\n",
    "        hist2 (torch.Tensor): Histogram 2.\n",
    "    Returns:\n",
    "        torch.Tensor: Bhattacharyya distance.\n",
    "    \"\"\"\n",
    "    # Normalize histograms\n",
    "    hist1_normalized = hist1 / torch.sum(hist1)\n",
    "    hist2_normalized = hist2 / torch.sum(hist2)\n",
    "\n",
    "    # Calculate square root of histograms\n",
    "    sqrt_hist1 = torch.sqrt(hist1_normalized)\n",
    "    sqrt_hist2 = torch.sqrt(hist2_normalized)\n",
    "\n",
    "    # Calculate Bhattacharyya coefficient\n",
    "    b_coefficient = torch.sum(torch.sqrt(sqrt_hist1 * sqrt_hist2))\n",
    "\n",
    "    # Calculate Bhattacharyya distance\n",
    "    distance = -torch.log(b_coefficient + 1e-8)\n",
    "\n",
    "    return distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "# for inp in tqdm(inputs[:1]):\n",
    "#     index, features_file = inp\n",
    "#     print(index, features_file)\n",
    "#      # Load\n",
    "#     data_dict = torch.load(features_file, map_location='cpu')\n",
    "#     # print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "#     # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "#     image_id = data_dict['file'][:-4]\n",
    "#     print(image_id)\n",
    "#     # Load\n",
    "#     output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "#     if Path(output_file).is_file():\n",
    "#         print(f'Skipping existing file {str(output_file)}')\n",
    "#         # break\n",
    "#         # return  # skip because already generated\n",
    "#\n",
    "#     # Load affinity matrix\n",
    "#     feats = data_dict[which_features].squeeze().cuda()\n",
    "#     # print(feats.shape)\n",
    "#     tanh_feats=torch.tanh(feats)\n",
    "#     print(\"tanh_feats.shape=\", tanh_feats.shape)\n",
    "#     rows=tanh_feats.shape[0]\n",
    "#     W_feat_jsd=torch.empty(rows, rows)\n",
    "#     for i in range(rows):\n",
    "#         t1=tanh_feats[i]\n",
    "#         # print(\"t1.shape=\", t1.shape)\n",
    "#         min_t1=torch.min(t1)\n",
    "#         max_t1=torch.max(t1)\n",
    "#         # print(\"minimum of t1=\", min_t1)\n",
    "#         # print(\"maximum of t1=\", max_t1)\n",
    "#         # Calculate the histogram\n",
    "#         hist1 = torch.histc(t1, bins=20, min=-1, max=1)\n",
    "#         # print(hist1)\n",
    "#         for j in range(rows):\n",
    "#             t2=tanh_feats[i]\n",
    "#             # t1_float = t1.float()\n",
    "#             # print(\"t1.shape=\", t1.shape)\n",
    "#             min_t1=torch.min(t2)\n",
    "#             max_t1=torch.max(t2)\n",
    "#             # print(\"minimum of t1=\", min_t1)\n",
    "#             # print(\"maximum of t1=\", max_t1)\n",
    "#             # print()\n",
    "#             # Calculate the histogram\n",
    "#             hist2 = torch.histc(t1, bins=20, min=-1, max=1)\n",
    "#             # print(hist2)\n",
    "#             jsd=js_divergence(hist1, hist2)\n",
    "#             W_feat_jsd[i,j]=jsd.item()\n",
    "#\n",
    "#\n",
    "#\n",
    "#     # hist = torch.histc(tanh_feats.cpu(), bins=20, min=-100, max=100)\n",
    "#     # x=np.linspace(-100, 100, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0001.pth\n",
      "0001\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:935: LinAlgWarning: Diagonal number 139 is exactly zero. Singular matrix.\n",
      "  self.M_lu = lu_factor(M)\n",
      "  0%|          | 1/1000 [02:09<36:00:28, 129.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "1 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0002.pth\n",
      "0002\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [04:08<34:13:10, 123.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "2 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0003.pth\n",
      "0003\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [06:09<33:48:03, 122.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "3 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0004.pth\n",
      "0004\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [08:08<33:29:06, 121.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "4 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0005.pth\n",
      "0005\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [10:08<33:21:05, 120.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "5 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0006.pth\n",
      "0006\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [12:02<32:39:53, 118.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "6 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0007.pth\n",
      "0007\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [13:52<31:51:26, 115.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "7 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0008.pth\n",
      "0008\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [15:45<31:38:18, 114.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "8 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0009.pth\n",
      "0009\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [17:41<31:44:15, 115.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "9 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0010.pth\n",
      "0010\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [19:39<31:52:13, 115.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "10 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0011.pth\n",
      "0011\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [21:55<33:33:50, 122.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "11 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0012.pth\n",
      "0012\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [24:13<34:50:07, 126.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "12 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0013.pth\n",
      "0013\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [26:37<36:15:40, 132.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "13 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0014.pth\n",
      "0014\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 14/1000 [28:42<35:35:35, 129.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "14 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0015.pth\n",
      "0015\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/1000 [30:49<35:20:10, 129.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "15 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0016.pth\n",
      "0016\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [33:09<36:13:02, 132.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "16 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0017.pth\n",
      "0017\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/1000 [35:40<37:37:45, 137.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "17 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0018.pth\n",
      "0018\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1000 [37:45<36:34:27, 134.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "18 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0019.pth\n",
      "0019\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1000 [39:42<35:10:16, 129.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "19 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0020.pth\n",
      "0020\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [41:37<33:59:22, 124.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "20 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0021.pth\n",
      "0021\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1000 [43:35<33:20:10, 122.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "21 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0022.pth\n",
      "0022\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 22/1000 [45:43<33:46:11, 124.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "22 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0023.pth\n",
      "0023\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [48:00<34:43:44, 127.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "23 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0024.pth\n",
      "0024\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 24/1000 [50:13<35:07:09, 129.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0025.pth\n",
      "0025\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 25/1000 [52:36<36:11:10, 133.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "25 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0026.pth\n",
      "0026\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [54:57<36:47:39, 136.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "26 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0027.pth\n",
      "0027\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [57:20<37:17:23, 137.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "27 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0028.pth\n",
      "0028\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1000 [59:41<37:30:39, 138.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "28 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0029.pth\n",
      "0029\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [1:02:01<37:31:43, 139.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "29 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0030.pth\n",
      "0030\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1000 [1:04:20<37:28:41, 139.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "30 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0031.pth\n",
      "0031\n",
      "tanh_feats.shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 31/1000 [1:06:39<37:26:36, 139.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "31 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0032.pth\n",
      "0032\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1000 [1:08:53<36:59:11, 137.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "32 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0033.pth\n",
      "0033\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1000 [1:11:07<36:42:25, 136.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "33 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0034.pth\n",
      "0034\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1000 [1:13:26<36:50:07, 137.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "34 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0035.pth\n",
      "0035\n",
      "tanh_feats.shape= torch.Size([400, 384])\n",
      "W_feat_ds.shape= torch.Size([400, 400])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([400, 400])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35/1000 [1:15:46<36:58:25, 137.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "35 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0036.pth\n",
      "0036\n",
      "tanh_feats.shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 35/1000 [1:18:41<36:09:33, 134.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_feat_ds.shape= torch.Size([450, 450])\n",
      "W_feat_hist_bhattacharyya.shape= torch.Size([450, 450])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (400,400) (450,450) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 158\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     eigenvalues, eigenvectors \u001B[38;5;241m=\u001B[39m eigsh(\u001B[43mD_comb\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mW_comb\u001B[49m, k\u001B[38;5;241m=\u001B[39mK, sigma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLM\u001B[39m\u001B[38;5;124m'\u001B[39m, M\u001B[38;5;241m=\u001B[39mD_comb)\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (400,400) (450,450) ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 160\u001B[0m\n\u001B[1;32m    158\u001B[0m         eigenvalues, eigenvectors \u001B[38;5;241m=\u001B[39m eigsh(D_comb \u001B[38;5;241m-\u001B[39m W_comb, k\u001B[38;5;241m=\u001B[39mK, sigma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLM\u001B[39m\u001B[38;5;124m'\u001B[39m, M\u001B[38;5;241m=\u001B[39mD_comb)\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m--> 160\u001B[0m         eigenvalues, eigenvectors \u001B[38;5;241m=\u001B[39m eigsh(\u001B[43mD_comb\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mW_comb\u001B[49m, k\u001B[38;5;241m=\u001B[39mK, which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSM\u001B[39m\u001B[38;5;124m'\u001B[39m, M\u001B[38;5;241m=\u001B[39mD_comb)\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (400,400) (450,450) "
     ]
    }
   ],
   "source": [
    "#Incorporating JS-Divergence in addition to Cosine Affinity\n",
    "utils.make_output_dir(output_dir)\n",
    "inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for inp in tqdm(inputs):\n",
    "    index, features_file = inp\n",
    "    print(index, features_file)\n",
    "     # Load\n",
    "    data_dict = torch.load(features_file, map_location='cpu')\n",
    "    # print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "    # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "    image_id = data_dict['file'][:-4]\n",
    "    print(image_id)\n",
    "    # Load\n",
    "    output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "    if Path(output_file).is_file():\n",
    "        print(f'Skipping existing file {str(output_file)}')\n",
    "        # break\n",
    "        # return  # skip because already generated\n",
    "\n",
    "    # Load affinity matrix\n",
    "    feats = data_dict[which_features].squeeze().cuda()\n",
    "    # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "    if normalize:\n",
    "        feats = F.normalize(feats, p=2, dim=-1)\n",
    "    # print(\"After normalization, Features Shape\",feats.shape)\n",
    "    # print(\"which_matrix=\", which_matrix)\n",
    "    # Eigenvectors of affinity matrix\n",
    "    if which_matrix == 'affinity_torch':\n",
    "        W = feats @ feats.T\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "            # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = torch.eig(W, eigenvectors=True)\n",
    "        eigenvalues = eigenvalues.cpu()\n",
    "        eigenvectors = eigenvectors.cpu()\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity_svd':\n",
    "        USV = torch.linalg.svd(feats, full_matrices=False)\n",
    "        eigenvectors = USV[0][:, :K].T.to('cpu', non_blocking=True)\n",
    "        eigenvalues = USV[1][:K].to('cpu', non_blocking=True)\n",
    "        print(\"which matrix=\",which_matrix,\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity':\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "        W = (feats @ feats.T)\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "        W = W.cpu().numpy()\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = eigsh(W, which='LM', k=K)\n",
    "        eigenvectors = torch.flip(torch.from_numpy(eigenvectors), dims=(-1,)).T\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of matting laplacian matrix\n",
    "    elif which_matrix in ['matting_laplacian', 'laplacian']:\n",
    "\n",
    "        # Get sizes\n",
    "        B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "        if image_downsample_factor is None:\n",
    "            image_downsample_factor = P\n",
    "        H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "        # Upscale features to match the resolution\n",
    "        if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "            feats = F.interpolate(\n",
    "                feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "                size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "            ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "        ### Feature affinities\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "\n",
    "        W_feat_ds = (feats @ feats.T)\n",
    "        tanh_feats=torch.tanh(feats)\n",
    "        print(\"tanh_feats.shape=\", tanh_feats.shape)\n",
    "        rows=tanh_feats.shape[0]\n",
    "        W_feat_hist_bhattacharyya=torch.zeros(rows, rows)\n",
    "        for i in range(rows):\n",
    "            t1=tanh_feats[i]\n",
    "            # print(\"t1.shape=\", t1.shape)\n",
    "            min_t1=torch.min(t1)\n",
    "            max_t1=torch.max(t1)\n",
    "            # print(\"minimum of t1=\", min_t1)\n",
    "            # print(\"maximum of t1=\", max_t1)\n",
    "            # Calculate the histogram\n",
    "            hist1 = torch.histc(t1, bins=20, min=-1, max=1)\n",
    "            # print(hist1)\n",
    "            for j in range(rows):\n",
    "                t2=tanh_feats[i]\n",
    "                # t1_float = t1.float()\n",
    "                # print(\"t1.shape=\", t1.shape)\n",
    "                min_t1=torch.min(t2)\n",
    "                max_t1=torch.max(t2)\n",
    "                # print(\"minimum of t1=\", min_t1)\n",
    "                # print(\"maximum of t1=\", max_t1)\n",
    "                # print()\n",
    "                # Calculate the histogram\n",
    "                hist2 = torch.histc(t1, bins=20, min=-1, max=1)\n",
    "                # print(hist2)\n",
    "                hist_bhattacharyya=bhattacharyya_distance(hist1, hist2)\n",
    "                W_feat_hist_bhattacharyya[i,j]=hist_bhattacharyya.item()\n",
    "        W_feat_ds=W_feat_ds.to(device)\n",
    "        W_feat_hist_bhattacharyya=W_feat_hist_bhattacharyya.to(device)\n",
    "        print(\"W_feat_ds.shape=\", W_feat_ds.shape)\n",
    "        print(\"W_feat_hist_bhattacharyya.shape=\", W_feat_hist_bhattacharyya.shape)\n",
    "        W_feat=W_feat_ds+W_feat_hist_bhattacharyya\n",
    "        print(type(W_feat_hist_bhattacharyya))\n",
    "        # print(W_feat.shape)\n",
    "        # print(W_feat)\n",
    "        if threshold_at_zero:\n",
    "            W_feat = (W_feat * (W_feat > 0))\n",
    "        W_feat = W_feat / W_feat.max()  # NOTE: If features are normalized, this naturally does nothing\n",
    "        # W_feat = W_feat.cpu().numpy()\n",
    "        W_feat = W_feat.detach().cpu().numpy()\n",
    "        # print(\"W_feat shape=\",W_feat.shape)\n",
    "\n",
    "        ### Color affinities\n",
    "        # If we are fusing with color affinites, then load the image and compute\n",
    "        if image_color_lambda > 0:\n",
    "\n",
    "            # Load image\n",
    "            image_file = str(Path(images_root) / f'{image_id}.jpg')\n",
    "            image_lr = Image.open(image_file).resize((W_pad_lr, H_pad_lr), Image.BILINEAR)\n",
    "            image_lr = np.array(image_lr) / 255.\n",
    "\n",
    "            # Color affinities (of type scipy.sparse.csr_matrix)\n",
    "            if which_color_matrix == 'knn':\n",
    "                W_lr = utils.knn_affinity(image_lr / 255)\n",
    "            elif which_color_matrix == 'rw':\n",
    "                W_lr = utils.rw_affinity(image_lr / 255)\n",
    "\n",
    "            # Convert to dense numpy array\n",
    "            W_color = np.array(W_lr.todense().astype(np.float32))\n",
    "            # print(\"W_color shape\", W_color.shape)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # No color affinity\n",
    "            W_color = 0\n",
    "\n",
    "        # Combine\n",
    "        W_comb = W_feat + W_color * image_color_lambda  # combination\n",
    "        D_comb = np.array(utils.get_diagonal(W_comb_tmp).todense())  # is dense or sparse faster? not sure, should check\n",
    "        # W_comb=np.nan_to_num(W_comb_tmp, nan=0.0)\n",
    "        # D_comb=np.nan_to_num(D_comb_tmp, nan=0.0)\n",
    "        # print(\"W_comb shape= \", W_comb.shape, \"D_comb shape\",  D_comb.shape)\n",
    "        if lapnorm:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM', M=D_comb)\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM', M=D_comb)\n",
    "        else:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM')\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM')\n",
    "        eigenvalues, eigenvectors = torch.from_numpy(eigenvalues), torch.from_numpy(eigenvectors.T).float()\n",
    "    print(\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "    # Sign ambiguity\n",
    "    for k in range(eigenvectors.shape[0]):\n",
    "        if 0.5 < torch.mean((eigenvectors[k] > 0).float()).item() < 1.0:  # reverse segment\n",
    "            eigenvectors[k] = 0 - eigenvectors[k]\n",
    "\n",
    "    # Save dict\n",
    "    output_dict = {'eigenvalues': eigenvalues, 'eigenvectors': eigenvectors}\n",
    "    torch.save(output_dict, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}