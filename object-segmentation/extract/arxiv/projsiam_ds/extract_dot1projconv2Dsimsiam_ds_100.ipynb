{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "from pathlib import Path\n",
    "# from typing import Optional, Tuple\n",
    "# import cv2\n",
    "# import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from PIL import Image\n",
    "from scipy.sparse.linalg import eigsh\n",
    "# from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "# from torchvision.utils import draw_bounding_boxes\n",
    "from tqdm import tqdm\n",
    "import extract_utils as utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# images_list=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/lists/images.txt\"\n",
    "# images_root=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/images\"\n",
    "# model_name=\"dino_vits16\"\n",
    "# batch_size=1\n",
    "# output_dir=\"//home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16\"\n",
    "# which_block=-1\n",
    "# # Output\n",
    "# utils.make_output_dir(output_dir)\n",
    "# # Models\n",
    "# model_name = model_name.lower()\n",
    "# model, val_transform, patch_size, num_heads = utils.get_model(model_name)    #patch size= 16 number of heads= 6\n",
    "# # print(\"patch size=\", patch_size, \"number of heads=\", num_heads)\n",
    "# # Add hook\n",
    "# if 'dino' in model_name or 'mocov3' in model_name:\n",
    "#     feat_out = {}\n",
    "#     def hook_fn_forward_qkv(module, input, output):\n",
    "#         # print(\"feat_out.keys()\", feat_out.keys())\n",
    "#         feat_out[\"qkv\"] = output\n",
    "#     model._modules[\"blocks\"][which_block]._modules[\"attn\"]._modules[\"qkv\"].register_forward_hook(hook_fn_forward_qkv)\n",
    "# else:\n",
    "#     raise ValueError(model_name)\n",
    "# # Dataset\n",
    "# filenames = Path(images_list).read_text().splitlines()\n",
    "# dataset = utils.ImagesDataset(filenames=filenames, images_root=images_root, transform=val_transform)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=8)\n",
    "# # print(f'Dataset size: {len(dataset)=}')\n",
    "# # print(f'Dataloader size: {len(dataloader)=}')\n",
    "# # Prepare\n",
    "# # accelerator = Accelerator(fp16=True, cpu=False)\n",
    "# accelerator = Accelerator(cpu=False)\n",
    "# # model, dataloader = accelerator.prepare(model, dataloader)\n",
    "# model = model.to(accelerator.device)\n",
    "# model.num_features\n",
    "# # print(\"model.num_features=\", model.num_features)\n",
    "# # model.get_submodule\n",
    "# # Process\n",
    "# pbar = list(tqdm(dataloader, desc='Processing'))\n",
    "# # Process\n",
    "# # pbar = list(tqdm(dataloader, desc='Processing'))\n",
    "# # print(\"feat_out.keys()=\", feat_out.keys())\n",
    "# for i, (images, files, indices) in enumerate(pbar):\n",
    "#     output_dict = {}\n",
    "#     # print(\"images.shape=\", images.shape, \"files =\", files, \"indices\", indices)\n",
    "#\n",
    "#     # Check if file already exists\n",
    "#     id = Path(files[0]).stem\n",
    "#     # print(\"id=\", id)\n",
    "#     output_file = Path(output_dir) / f'{id}.pth'\n",
    "#     # if output_file.is_file():\n",
    "#     #     pbar.write(f'Skipping existing file {str(output_file)}')\n",
    "#     #     continue\n",
    "#\n",
    "#     # Reshape image\n",
    "#     P = patch_size\n",
    "#     B, C, H, W = images.shape\n",
    "#     H_patch, W_patch = H // P, W // P\n",
    "#     H_pad, W_pad = H_patch * P, W_patch * P\n",
    "#     T = H_patch * W_patch + 1  # number of tokens, add 1 for [CLS]\n",
    "#     # images = F.interpolate(images, size=(H_pad, W_pad), mode='bilinear')  # resize image\n",
    "#     images = images[:, :, :H_pad, :W_pad]\n",
    "#     images = images.to(accelerator.device)\n",
    "#     # print(\"images.shape after padding=\", images.shape)\n",
    "#\n",
    "#     # Forward and collect features into output dict\n",
    "#     if 'dino' in model_name or 'mocov3' in model_name:\n",
    "#         # accelerator.unwrap_model(model).get_intermediate_layers(images)[0].squeeze(0)\n",
    "#         model.get_intermediate_layers(images)[0].squeeze(0)\n",
    "#         # print(model.get_intermediate_layers(images)[0])\n",
    "#         # output_dict['out'] = out\n",
    "#         # print(\"feat_out.keys()=\", feat_out.keys())\n",
    "#         output_qkv = feat_out[\"qkv\"].reshape(B, T, 3, num_heads, -1 // num_heads).permute(2, 0, 3, 1, 4)\n",
    "#         # print(\"type(output_qkv)\", type(output_qkv))\n",
    "#         # print(\"output_qkv.shape\", output_qkv.shape)    #3, 1, 6, 931, 64]\n",
    "#         # print(\"output_qkv[0].shape\", output_qkv[0].shape)\n",
    "#         # print(\"output_qkv[1].shape\", output_qkv[1].shape)\n",
    "#         # print(\"output_qkv[2].shape\", output_qkv[2].shape)\n",
    "#         # output_dict['q'] = output_qkv[0].transpose(1, 2).reshape(B, T, -1)[:, 1:, :]\n",
    "#         output_dict['k'] = output_qkv[1].transpose(1, 2).reshape(B, T, -1)[:, 1:, :]\n",
    "#         # print(\"output_dict[k].shape=\", output_dict['k'].shape)\n",
    "#         # output_dict['v'] = output_qkv[2].transpose(1, 2).reshape(B, T, -1)[:, 1:, :]\n",
    "#     else:\n",
    "#         raise ValueError(model_name)\n",
    "#\n",
    "#     # print(\"output_dict.items=\", output_dict.items())\n",
    "#     # Metadata\n",
    "#     output_dict['indices'] = indices[0]\n",
    "#     output_dict['file'] = files[0]\n",
    "#     output_dict['id'] = id\n",
    "#     output_dict['model_name'] = model_name\n",
    "#     output_dict['patch_size'] = patch_size\n",
    "#     output_dict['shape'] = (B, C, H, W)\n",
    "#     output_dict = {k: (v.detach().cpu() if torch.is_tensor(v) else v) for k, v in output_dict.items()}\n",
    "#     # for k, v in output_dict.items():\n",
    "#     #     print(\"k=\", k)\n",
    "#     #     if torch.is_tensor(v):\n",
    "#     #         print(\"v.shape\", v.shape)\n",
    "#     #     else:\n",
    "#     #         print(\"v=\", v)\n",
    "#     # print(\"output_dict.keys()\", output_dict.keys())\n",
    "#     # print(\"output_dict['k'].shape=\", output_dict['k'].shape,\"output_dict['indices'] =\", indices[0],\"output_dict['file'] =\", files[0],\"output_dict['id']=\" , id, \"output_dict['model_name'] =\", model_name,\" output_dict['shape'] =(\", B, C, H, W,\")output_dict['patch_size'] =\",  patch_size )\n",
    "#     # Save\n",
    "#     accelerator.save(output_dict, str(output_file))\n",
    "#     accelerator.wait_for_everyone()\n",
    "# print(f'Saved features to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# output_dict = {k: (v.detach().cpu() if torch.is_tensor(v) else v) for k, v in output_dict.items()}\n",
    "# print(output_dict.keys())\n",
    "# for k, v in output_dict.items():\n",
    "#     print(\"k=\", k)\n",
    "#     print(\"v.shape=\", v.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract Eigen Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_root=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/images\"\n",
    "features_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16\"\n",
    "output_dir=\"//home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/eigs_dot1residualsimsiam_ds_100_jn\"\n",
    "which_matrix= 'laplacian'\n",
    "which_color_matrix= 'knn'\n",
    "which_features= 'k'\n",
    "normalize=True\n",
    "threshold_at_zero=True\n",
    "lapnorm= True\n",
    "K= 5\n",
    "image_downsample_factor = None\n",
    "image_color_lambda = 0.0\n",
    "multiprocessing = 0\n",
    "batch_size=2\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet Residual Block"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=128, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(128, out_channels * self.expansion, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        # print(\"Before squeezing, out shape=\", out.shape)\n",
    "        out =  out.squeeze().to('cuda')\n",
    "        # print(\"After squeezing, out shape=\", out.shape)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False):\n",
    "#         super(ResidualBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "#         self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "#         self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "#         # shortcut connection\n",
    "#         self.shortcut = nn.Sequential()\n",
    "#         if stride != 1 or in_channels != out_channels:\n",
    "#             self.shortcut = nn.Sequential(\n",
    "#                 nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=bias),\n",
    "#                 nn.BatchNorm1d(out_channels)\n",
    "#             )\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu(out)\n",
    "#\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#\n",
    "#         out += self.shortcut(residual)\n",
    "#         out = self.relu(out)\n",
    "#\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# class ResNetBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "#         super(ResNetBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "#         self.downsample = downsample\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         identity = x\n",
    "#\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu(out)\n",
    "#\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#\n",
    "#         if self.downsample is not None:\n",
    "#             identity = self.downsample(x)\n",
    "#\n",
    "#         out += identity\n",
    "#         out = self.relu(out)\n",
    "#\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incorporating SimSiam"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class Feature_Dataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# print(feats.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.projection_head = SimSiamProjectionHead(feats.shape[1], 128,feats.shape[1])\n",
    "        self.projection_head = BasicBlock()\n",
    "        # self.projection_head = ResidualBlock(feats.shape[1], feats.shape[1])\n",
    "        self.prediction_head = SimSiamPredictionHead(feats.shape[1], 128, feats.shape[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.projection_head(x)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# utils.make_output_dir(output_dir)\n",
    "# feat_list=[]\n",
    "# inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "# batch_size=2\n",
    "# token_feature_size=384\n",
    "# for inp in tqdm(inputs[:2]):\n",
    "#     index, features_file = inp\n",
    "#     print(index, features_file)\n",
    "#      # Load\n",
    "#     data_dict = torch.load(features_file, map_location='cpu')\n",
    "#     # Load affinity matrix\n",
    "#     # feats_unsqueeze=data_dict[which_features].cuda()\n",
    "#     feats = data_dict[which_features].squeeze().cuda()\n",
    "#     print(feats.shape)\n",
    "#     # print(feats_unsqueeze.shape)\n",
    "#     feat_dataset = Feature_Dataset(feats)\n",
    "#     features_dataloader = DataLoader(feat_dataset, batch_size=2, shuffle=True)\n",
    "#     i=0\n",
    "#     for x0 in features_dataloader:\n",
    "#         if i==0:\n",
    "#         # for (x0), _, _ in features_dataloader:\n",
    "#             print(\"before unsqueezing x0.shape=\", x0.shape)\n",
    "#             x0 = x0.unsqueeze(0).to(device)\n",
    "#             x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "#             x0 = x0.squeeze(0).to(device)\n",
    "#             x0 = torch.tensor(x0).view(batch_size, 1, 1, token_feature_size)\n",
    "#             print(\"After squeezing and viewing x0 shape=\", x0.shape)\n",
    "#             # print(\"x0.shape=\", x0.shape)\n",
    "#             x1 = x1.squeeze(0).to(device)\n",
    "#             x1 = torch.tensor(x1).view(batch_size, 1, 1,token_feature_size)\n",
    "#             print(\"After squeezing and viewing x0 shape=\", x1.shape)\n",
    "#             print(\"x1 shape=\", x1.shape)\n",
    "#         else:\n",
    "#             break\n",
    "#         i+=1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0001.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0001\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.48143\n",
      "epoch: 01, loss: -0.64673\n",
      "epoch: 02, loss: -0.65935\n",
      "epoch: 03, loss: -0.67249\n",
      "epoch: 04, loss: -0.68101\n",
      "epoch: 05, loss: -0.68597\n",
      "epoch: 06, loss: -0.69369\n",
      "epoch: 07, loss: -0.69350\n",
      "epoch: 08, loss: -0.69919\n",
      "epoch: 09, loss: -0.69386\n",
      "epoch: 10, loss: -0.69781\n",
      "epoch: 11, loss: -0.67664\n",
      "epoch: 12, loss: -0.69767\n",
      "epoch: 13, loss: -0.69201\n",
      "epoch: 14, loss: -0.69668\n",
      "epoch: 15, loss: -0.70057\n",
      "epoch: 16, loss: -0.70835\n",
      "epoch: 17, loss: -0.70973\n",
      "epoch: 18, loss: -0.71710\n",
      "epoch: 19, loss: -0.72031\n",
      "epoch: 20, loss: -0.72057\n",
      "epoch: 21, loss: -0.73174\n",
      "epoch: 22, loss: -0.73419\n",
      "epoch: 23, loss: -0.73549\n",
      "epoch: 24, loss: -0.73660\n",
      "epoch: 25, loss: -0.72715\n",
      "epoch: 26, loss: -0.73888\n",
      "epoch: 27, loss: -0.73200\n",
      "epoch: 28, loss: -0.73319\n",
      "epoch: 29, loss: -0.73485\n",
      "epoch: 30, loss: -0.73958\n",
      "epoch: 31, loss: -0.73836\n",
      "epoch: 32, loss: -0.74994\n",
      "epoch: 33, loss: -0.76093\n",
      "epoch: 34, loss: -0.76755\n",
      "epoch: 35, loss: -0.77777\n",
      "epoch: 36, loss: -0.77979\n",
      "epoch: 37, loss: -0.78046\n",
      "epoch: 38, loss: -0.77921\n",
      "epoch: 39, loss: -0.76899\n",
      "epoch: 40, loss: -0.78361\n",
      "epoch: 41, loss: -0.80504\n",
      "epoch: 42, loss: -0.80061\n",
      "epoch: 43, loss: -0.80974\n",
      "epoch: 44, loss: -0.81080\n",
      "epoch: 45, loss: -0.80305\n",
      "epoch: 46, loss: -0.79136\n",
      "epoch: 47, loss: -0.79177\n",
      "epoch: 48, loss: -0.77491\n",
      "epoch: 49, loss: -0.78335\n",
      "epoch: 50, loss: -0.78174\n",
      "epoch: 51, loss: -0.76919\n",
      "epoch: 52, loss: -0.75940\n",
      "epoch: 53, loss: -0.73866\n",
      "epoch: 54, loss: -0.74219\n",
      "epoch: 55, loss: -0.75639\n",
      "epoch: 56, loss: -0.76018\n",
      "epoch: 57, loss: -0.75975\n",
      "epoch: 58, loss: -0.76522\n",
      "epoch: 59, loss: -0.75859\n",
      "epoch: 60, loss: -0.76527\n",
      "epoch: 61, loss: -0.75528\n",
      "epoch: 62, loss: -0.76002\n",
      "epoch: 63, loss: -0.75250\n",
      "epoch: 64, loss: -0.75494\n",
      "epoch: 65, loss: -0.76585\n",
      "epoch: 66, loss: -0.78375\n",
      "epoch: 67, loss: -0.79050\n",
      "epoch: 68, loss: -0.77961\n",
      "epoch: 69, loss: -0.78372\n",
      "epoch: 70, loss: -0.76565\n",
      "epoch: 71, loss: -0.77245\n",
      "epoch: 72, loss: -0.76738\n",
      "epoch: 73, loss: -0.78963\n",
      "epoch: 74, loss: -0.78669\n",
      "epoch: 75, loss: -0.78045\n",
      "epoch: 76, loss: -0.79055\n",
      "epoch: 77, loss: -0.78815\n",
      "epoch: 78, loss: -0.77330\n",
      "epoch: 79, loss: -0.77172\n",
      "epoch: 80, loss: -0.77190\n",
      "epoch: 81, loss: -0.77328\n",
      "epoch: 82, loss: -0.78813\n",
      "epoch: 83, loss: -0.78548\n",
      "epoch: 84, loss: -0.78909\n",
      "epoch: 85, loss: -0.79661\n",
      "epoch: 86, loss: -0.79746\n",
      "epoch: 87, loss: -0.80701\n",
      "epoch: 88, loss: -0.81341\n",
      "epoch: 89, loss: -0.80496\n",
      "epoch: 90, loss: -0.82844\n",
      "epoch: 91, loss: -0.83247\n",
      "epoch: 92, loss: -0.83014\n",
      "epoch: 93, loss: -0.83137\n",
      "epoch: 94, loss: -0.84385\n",
      "epoch: 95, loss: -0.85830\n",
      "epoch: 96, loss: -0.86037\n",
      "epoch: 97, loss: -0.85259\n",
      "epoch: 98, loss: -0.86031\n",
      "epoch: 99, loss: -0.86216\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [02:57<49:09:19, 177.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "1 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0002.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0002\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.51807\n",
      "epoch: 01, loss: -0.66034\n",
      "epoch: 02, loss: -0.67368\n",
      "epoch: 03, loss: -0.68107\n",
      "epoch: 04, loss: -0.70233\n",
      "epoch: 05, loss: -0.71811\n",
      "epoch: 06, loss: -0.71345\n",
      "epoch: 07, loss: -0.74150\n",
      "epoch: 08, loss: -0.74957\n",
      "epoch: 09, loss: -0.75809\n",
      "epoch: 10, loss: -0.76401\n",
      "epoch: 11, loss: -0.76892\n",
      "epoch: 12, loss: -0.75685\n",
      "epoch: 13, loss: -0.75874\n",
      "epoch: 14, loss: -0.76645\n",
      "epoch: 15, loss: -0.76239\n",
      "epoch: 16, loss: -0.76978\n",
      "epoch: 17, loss: -0.76315\n",
      "epoch: 18, loss: -0.78060\n",
      "epoch: 19, loss: -0.78411\n",
      "epoch: 20, loss: -0.78885\n",
      "epoch: 21, loss: -0.79332\n",
      "epoch: 22, loss: -0.80930\n",
      "epoch: 23, loss: -0.81411\n",
      "epoch: 24, loss: -0.81812\n",
      "epoch: 25, loss: -0.81909\n",
      "epoch: 26, loss: -0.82603\n",
      "epoch: 27, loss: -0.82323\n",
      "epoch: 28, loss: -0.82028\n",
      "epoch: 29, loss: -0.80765\n",
      "epoch: 30, loss: -0.82136\n",
      "epoch: 31, loss: -0.82745\n",
      "epoch: 32, loss: -0.83717\n",
      "epoch: 33, loss: -0.83247\n",
      "epoch: 34, loss: -0.84806\n",
      "epoch: 35, loss: -0.84214\n",
      "epoch: 36, loss: -0.84959\n",
      "epoch: 37, loss: -0.84427\n",
      "epoch: 38, loss: -0.84102\n",
      "epoch: 39, loss: -0.83968\n",
      "epoch: 40, loss: -0.83311\n",
      "epoch: 41, loss: -0.84418\n",
      "epoch: 42, loss: -0.85902\n",
      "epoch: 43, loss: -0.85378\n",
      "epoch: 44, loss: -0.85971\n",
      "epoch: 45, loss: -0.85651\n",
      "epoch: 46, loss: -0.85488\n",
      "epoch: 47, loss: -0.84792\n",
      "epoch: 48, loss: -0.84340\n",
      "epoch: 49, loss: -0.83778\n",
      "epoch: 50, loss: -0.82503\n",
      "epoch: 51, loss: -0.82844\n",
      "epoch: 52, loss: -0.82618\n",
      "epoch: 53, loss: -0.82053\n",
      "epoch: 54, loss: -0.81742\n",
      "epoch: 55, loss: -0.82042\n",
      "epoch: 56, loss: -0.83522\n",
      "epoch: 57, loss: -0.83977\n",
      "epoch: 58, loss: -0.83385\n",
      "epoch: 59, loss: -0.83837\n",
      "epoch: 60, loss: -0.83921\n",
      "epoch: 61, loss: -0.83937\n",
      "epoch: 62, loss: -0.83387\n",
      "epoch: 63, loss: -0.83314\n",
      "epoch: 64, loss: -0.82477\n",
      "epoch: 65, loss: -0.82667\n",
      "epoch: 66, loss: -0.83215\n",
      "epoch: 67, loss: -0.83124\n",
      "epoch: 68, loss: -0.83031\n",
      "epoch: 69, loss: -0.82313\n",
      "epoch: 70, loss: -0.81400\n",
      "epoch: 71, loss: -0.81495\n",
      "epoch: 72, loss: -0.80301\n",
      "epoch: 73, loss: -0.80348\n",
      "epoch: 74, loss: -0.80039\n",
      "epoch: 75, loss: -0.81156\n",
      "epoch: 76, loss: -0.81472\n",
      "epoch: 77, loss: -0.81015\n",
      "epoch: 78, loss: -0.80908\n",
      "epoch: 79, loss: -0.82299\n",
      "epoch: 80, loss: -0.79744\n",
      "epoch: 81, loss: -0.78275\n",
      "epoch: 82, loss: -0.77886\n",
      "epoch: 83, loss: -0.76670\n",
      "epoch: 84, loss: -0.78205\n",
      "epoch: 85, loss: -0.79277\n",
      "epoch: 86, loss: -0.78742\n",
      "epoch: 87, loss: -0.78299\n",
      "epoch: 88, loss: -0.77960\n",
      "epoch: 89, loss: -0.78204\n",
      "epoch: 90, loss: -0.78803\n",
      "epoch: 91, loss: -0.78156\n",
      "epoch: 92, loss: -0.78709\n",
      "epoch: 93, loss: -0.79096\n",
      "epoch: 94, loss: -0.79189\n",
      "epoch: 95, loss: -0.77048\n",
      "epoch: 96, loss: -0.77742\n",
      "epoch: 97, loss: -0.76956\n",
      "epoch: 98, loss: -0.72185\n",
      "epoch: 99, loss: -0.72452\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [05:56<49:23:24, 178.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "2 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0003.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0003\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.50068\n",
      "epoch: 01, loss: -0.68636\n",
      "epoch: 02, loss: -0.67728\n",
      "epoch: 03, loss: -0.67919\n",
      "epoch: 04, loss: -0.69123\n",
      "epoch: 05, loss: -0.70245\n",
      "epoch: 06, loss: -0.69624\n",
      "epoch: 07, loss: -0.70913\n",
      "epoch: 08, loss: -0.70305\n",
      "epoch: 09, loss: -0.70470\n",
      "epoch: 10, loss: -0.71071\n",
      "epoch: 11, loss: -0.71465\n",
      "epoch: 12, loss: -0.70677\n",
      "epoch: 13, loss: -0.72265\n",
      "epoch: 14, loss: -0.72609\n",
      "epoch: 15, loss: -0.73418\n",
      "epoch: 16, loss: -0.74125\n",
      "epoch: 17, loss: -0.73953\n",
      "epoch: 18, loss: -0.74909\n",
      "epoch: 19, loss: -0.74994\n",
      "epoch: 20, loss: -0.75824\n",
      "epoch: 21, loss: -0.77368\n",
      "epoch: 22, loss: -0.78297\n",
      "epoch: 23, loss: -0.78804\n",
      "epoch: 24, loss: -0.77666\n",
      "epoch: 25, loss: -0.77795\n",
      "epoch: 26, loss: -0.78469\n",
      "epoch: 27, loss: -0.78621\n",
      "epoch: 28, loss: -0.78829\n",
      "epoch: 29, loss: -0.79875\n",
      "epoch: 30, loss: -0.78797\n",
      "epoch: 31, loss: -0.79518\n",
      "epoch: 32, loss: -0.79176\n",
      "epoch: 33, loss: -0.79132\n",
      "epoch: 34, loss: -0.78938\n",
      "epoch: 35, loss: -0.79785\n",
      "epoch: 36, loss: -0.80639\n",
      "epoch: 37, loss: -0.80441\n",
      "epoch: 38, loss: -0.81182\n",
      "epoch: 39, loss: -0.81535\n",
      "epoch: 40, loss: -0.81879\n",
      "epoch: 41, loss: -0.82036\n",
      "epoch: 42, loss: -0.82270\n",
      "epoch: 43, loss: -0.82981\n",
      "epoch: 44, loss: -0.82887\n",
      "epoch: 45, loss: -0.82642\n",
      "epoch: 46, loss: -0.81899\n",
      "epoch: 47, loss: -0.83250\n",
      "epoch: 48, loss: -0.82887\n",
      "epoch: 49, loss: -0.83394\n",
      "epoch: 50, loss: -0.83575\n",
      "epoch: 51, loss: -0.83836\n",
      "epoch: 52, loss: -0.84079\n",
      "epoch: 53, loss: -0.83084\n",
      "epoch: 54, loss: -0.83484\n",
      "epoch: 55, loss: -0.83224\n",
      "epoch: 56, loss: -0.81889\n",
      "epoch: 57, loss: -0.81809\n",
      "epoch: 58, loss: -0.80255\n",
      "epoch: 59, loss: -0.80875\n",
      "epoch: 60, loss: -0.81424\n",
      "epoch: 61, loss: -0.82835\n",
      "epoch: 62, loss: -0.82918\n",
      "epoch: 63, loss: -0.82583\n",
      "epoch: 64, loss: -0.81008\n",
      "epoch: 65, loss: -0.80217\n",
      "epoch: 66, loss: -0.80163\n",
      "epoch: 67, loss: -0.79564\n",
      "epoch: 68, loss: -0.80745\n",
      "epoch: 69, loss: -0.81111\n",
      "epoch: 70, loss: -0.81744\n",
      "epoch: 71, loss: -0.82733\n",
      "epoch: 72, loss: -0.82564\n",
      "epoch: 73, loss: -0.83022\n",
      "epoch: 74, loss: -0.81313\n",
      "epoch: 75, loss: -0.81056\n",
      "epoch: 76, loss: -0.81326\n",
      "epoch: 77, loss: -0.81570\n",
      "epoch: 78, loss: -0.81579\n",
      "epoch: 79, loss: -0.79618\n",
      "epoch: 80, loss: -0.79432\n",
      "epoch: 81, loss: -0.79773\n",
      "epoch: 82, loss: -0.79730\n",
      "epoch: 83, loss: -0.80094\n",
      "epoch: 84, loss: -0.80453\n",
      "epoch: 85, loss: -0.82475\n",
      "epoch: 86, loss: -0.82616\n",
      "epoch: 87, loss: -0.82687\n",
      "epoch: 88, loss: -0.82587\n",
      "epoch: 89, loss: -0.82170\n",
      "epoch: 90, loss: -0.82370\n",
      "epoch: 91, loss: -0.82508\n",
      "epoch: 92, loss: -0.80982\n",
      "epoch: 93, loss: -0.79924\n",
      "epoch: 94, loss: -0.79998\n",
      "epoch: 95, loss: -0.81086\n",
      "epoch: 96, loss: -0.78080\n",
      "epoch: 97, loss: -0.77296\n",
      "epoch: 98, loss: -0.77846\n",
      "epoch: 99, loss: -0.78456\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [08:53<49:16:32, 177.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "3 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0004.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0004\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.48895\n",
      "epoch: 01, loss: -0.65727\n",
      "epoch: 02, loss: -0.68538\n",
      "epoch: 03, loss: -0.70139\n",
      "epoch: 04, loss: -0.70402\n",
      "epoch: 05, loss: -0.72253\n",
      "epoch: 06, loss: -0.71826\n",
      "epoch: 07, loss: -0.71364\n",
      "epoch: 08, loss: -0.73179\n",
      "epoch: 09, loss: -0.71983\n",
      "epoch: 10, loss: -0.69912\n",
      "epoch: 11, loss: -0.70186\n",
      "epoch: 12, loss: -0.71500\n",
      "epoch: 13, loss: -0.69970\n",
      "epoch: 14, loss: -0.70604\n",
      "epoch: 15, loss: -0.71555\n",
      "epoch: 16, loss: -0.71978\n",
      "epoch: 17, loss: -0.72045\n",
      "epoch: 18, loss: -0.73213\n",
      "epoch: 19, loss: -0.73312\n",
      "epoch: 20, loss: -0.72994\n",
      "epoch: 21, loss: -0.72349\n",
      "epoch: 22, loss: -0.72488\n",
      "epoch: 23, loss: -0.71510\n",
      "epoch: 24, loss: -0.71091\n",
      "epoch: 25, loss: -0.71972\n",
      "epoch: 26, loss: -0.72337\n",
      "epoch: 27, loss: -0.72487\n",
      "epoch: 28, loss: -0.72932\n",
      "epoch: 29, loss: -0.74057\n",
      "epoch: 30, loss: -0.75479\n",
      "epoch: 31, loss: -0.76260\n",
      "epoch: 32, loss: -0.76835\n",
      "epoch: 33, loss: -0.76506\n",
      "epoch: 34, loss: -0.77753\n",
      "epoch: 35, loss: -0.78101\n",
      "epoch: 36, loss: -0.78648\n",
      "epoch: 37, loss: -0.78014\n",
      "epoch: 38, loss: -0.78336\n",
      "epoch: 39, loss: -0.79457\n",
      "epoch: 40, loss: -0.79446\n",
      "epoch: 41, loss: -0.78644\n",
      "epoch: 42, loss: -0.79418\n",
      "epoch: 43, loss: -0.79371\n",
      "epoch: 44, loss: -0.79997\n",
      "epoch: 45, loss: -0.80578\n",
      "epoch: 46, loss: -0.79851\n",
      "epoch: 47, loss: -0.81073\n",
      "epoch: 48, loss: -0.81115\n",
      "epoch: 49, loss: -0.79244\n",
      "epoch: 50, loss: -0.79641\n",
      "epoch: 51, loss: -0.79859\n",
      "epoch: 52, loss: -0.79869\n",
      "epoch: 53, loss: -0.80256\n",
      "epoch: 54, loss: -0.80035\n",
      "epoch: 55, loss: -0.80386\n",
      "epoch: 56, loss: -0.80521\n",
      "epoch: 57, loss: -0.80818\n",
      "epoch: 58, loss: -0.79484\n",
      "epoch: 59, loss: -0.79373\n",
      "epoch: 60, loss: -0.79851\n",
      "epoch: 61, loss: -0.79417\n",
      "epoch: 62, loss: -0.79629\n",
      "epoch: 63, loss: -0.80180\n",
      "epoch: 64, loss: -0.80071\n",
      "epoch: 65, loss: -0.80017\n",
      "epoch: 66, loss: -0.80485\n",
      "epoch: 67, loss: -0.80006\n",
      "epoch: 68, loss: -0.80774\n",
      "epoch: 69, loss: -0.79168\n",
      "epoch: 70, loss: -0.79105\n",
      "epoch: 71, loss: -0.78256\n",
      "epoch: 72, loss: -0.77762\n",
      "epoch: 73, loss: -0.78605\n",
      "epoch: 74, loss: -0.79053\n",
      "epoch: 75, loss: -0.78811\n",
      "epoch: 76, loss: -0.79570\n",
      "epoch: 77, loss: -0.79645\n",
      "epoch: 78, loss: -0.80599\n",
      "epoch: 79, loss: -0.80664\n",
      "epoch: 80, loss: -0.79417\n",
      "epoch: 81, loss: -0.78942\n",
      "epoch: 82, loss: -0.79403\n",
      "epoch: 83, loss: -0.79209\n",
      "epoch: 84, loss: -0.81060\n",
      "epoch: 85, loss: -0.81572\n",
      "epoch: 86, loss: -0.81045\n",
      "epoch: 87, loss: -0.80448\n",
      "epoch: 88, loss: -0.82531\n",
      "epoch: 89, loss: -0.81892\n",
      "epoch: 90, loss: -0.82105\n",
      "epoch: 91, loss: -0.82140\n",
      "epoch: 92, loss: -0.81069\n",
      "epoch: 93, loss: -0.80823\n",
      "epoch: 94, loss: -0.81758\n",
      "epoch: 95, loss: -0.81362\n",
      "epoch: 96, loss: -0.80583\n",
      "epoch: 97, loss: -0.80577\n",
      "epoch: 98, loss: -0.80976\n",
      "epoch: 99, loss: -0.80994\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [11:55<49:36:52, 179.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "4 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0005.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0005\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.49660\n",
      "epoch: 01, loss: -0.65306\n",
      "epoch: 02, loss: -0.67419\n",
      "epoch: 03, loss: -0.69249\n",
      "epoch: 04, loss: -0.70684\n",
      "epoch: 05, loss: -0.71994\n",
      "epoch: 06, loss: -0.71404\n",
      "epoch: 07, loss: -0.71104\n",
      "epoch: 08, loss: -0.71221\n",
      "epoch: 09, loss: -0.72489\n",
      "epoch: 10, loss: -0.72437\n",
      "epoch: 11, loss: -0.73399\n",
      "epoch: 12, loss: -0.73783\n",
      "epoch: 13, loss: -0.74099\n",
      "epoch: 14, loss: -0.74839\n",
      "epoch: 15, loss: -0.76448\n",
      "epoch: 16, loss: -0.74959\n",
      "epoch: 17, loss: -0.73820\n",
      "epoch: 18, loss: -0.74773\n",
      "epoch: 19, loss: -0.74237\n",
      "epoch: 20, loss: -0.75183\n",
      "epoch: 21, loss: -0.75890\n",
      "epoch: 22, loss: -0.75299\n",
      "epoch: 23, loss: -0.74616\n",
      "epoch: 24, loss: -0.75231\n",
      "epoch: 25, loss: -0.74934\n",
      "epoch: 26, loss: -0.76885\n",
      "epoch: 27, loss: -0.77662\n",
      "epoch: 28, loss: -0.78498\n",
      "epoch: 29, loss: -0.79502\n",
      "epoch: 30, loss: -0.80183\n",
      "epoch: 31, loss: -0.79328\n",
      "epoch: 32, loss: -0.78739\n",
      "epoch: 33, loss: -0.79235\n",
      "epoch: 34, loss: -0.79406\n",
      "epoch: 35, loss: -0.78467\n",
      "epoch: 36, loss: -0.77608\n",
      "epoch: 37, loss: -0.76059\n",
      "epoch: 38, loss: -0.76209\n",
      "epoch: 39, loss: -0.76908\n",
      "epoch: 40, loss: -0.78428\n",
      "epoch: 41, loss: -0.79244\n",
      "epoch: 42, loss: -0.77929\n",
      "epoch: 43, loss: -0.78407\n",
      "epoch: 44, loss: -0.78482\n",
      "epoch: 45, loss: -0.79091\n",
      "epoch: 46, loss: -0.79356\n",
      "epoch: 47, loss: -0.80429\n",
      "epoch: 48, loss: -0.80767\n",
      "epoch: 49, loss: -0.81571\n",
      "epoch: 50, loss: -0.81941\n",
      "epoch: 51, loss: -0.82263\n",
      "epoch: 52, loss: -0.82503\n",
      "epoch: 53, loss: -0.81863\n",
      "epoch: 54, loss: -0.81843\n",
      "epoch: 55, loss: -0.81009\n",
      "epoch: 56, loss: -0.81258\n",
      "epoch: 57, loss: -0.82546\n",
      "epoch: 58, loss: -0.81873\n",
      "epoch: 59, loss: -0.83430\n",
      "epoch: 60, loss: -0.83934\n",
      "epoch: 61, loss: -0.84120\n",
      "epoch: 62, loss: -0.84163\n",
      "epoch: 63, loss: -0.83655\n",
      "epoch: 64, loss: -0.82704\n",
      "epoch: 65, loss: -0.82073\n",
      "epoch: 66, loss: -0.82173\n",
      "epoch: 67, loss: -0.82037\n",
      "epoch: 68, loss: -0.81774\n",
      "epoch: 69, loss: -0.81184\n",
      "epoch: 70, loss: -0.80730\n",
      "epoch: 71, loss: -0.81002\n",
      "epoch: 72, loss: -0.80076\n",
      "epoch: 73, loss: -0.79572\n",
      "epoch: 74, loss: -0.78517\n",
      "epoch: 75, loss: -0.80271\n",
      "epoch: 76, loss: -0.82193\n",
      "epoch: 77, loss: -0.81676\n",
      "epoch: 78, loss: -0.83038\n",
      "epoch: 79, loss: -0.81351\n",
      "epoch: 80, loss: -0.81108\n",
      "epoch: 81, loss: -0.80412\n",
      "epoch: 82, loss: -0.81616\n",
      "epoch: 83, loss: -0.82780\n",
      "epoch: 84, loss: -0.82458\n",
      "epoch: 85, loss: -0.81391\n",
      "epoch: 86, loss: -0.80575\n",
      "epoch: 87, loss: -0.80350\n",
      "epoch: 88, loss: -0.80806\n",
      "epoch: 89, loss: -0.80250\n",
      "epoch: 90, loss: -0.81286\n",
      "epoch: 91, loss: -0.79965\n",
      "epoch: 92, loss: -0.80757\n",
      "epoch: 93, loss: -0.81383\n",
      "epoch: 94, loss: -0.79951\n",
      "epoch: 95, loss: -0.78292\n",
      "epoch: 96, loss: -0.78993\n",
      "epoch: 97, loss: -0.78882\n",
      "epoch: 98, loss: -0.79099\n",
      "epoch: 99, loss: -0.79470\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [14:56<49:48:14, 180.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "5 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0006.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0006\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.49678\n",
      "epoch: 01, loss: -0.62444\n",
      "epoch: 02, loss: -0.65616\n",
      "epoch: 03, loss: -0.67038\n",
      "epoch: 04, loss: -0.67328\n",
      "epoch: 05, loss: -0.68244\n",
      "epoch: 06, loss: -0.67194\n",
      "epoch: 07, loss: -0.68425\n",
      "epoch: 08, loss: -0.66386\n",
      "epoch: 09, loss: -0.67473\n",
      "epoch: 10, loss: -0.69302\n",
      "epoch: 11, loss: -0.69720\n",
      "epoch: 12, loss: -0.70611\n",
      "epoch: 13, loss: -0.71015\n",
      "epoch: 14, loss: -0.72012\n",
      "epoch: 15, loss: -0.72441\n",
      "epoch: 16, loss: -0.72799\n",
      "epoch: 17, loss: -0.73781\n",
      "epoch: 18, loss: -0.74010\n",
      "epoch: 19, loss: -0.74252\n",
      "epoch: 20, loss: -0.73782\n",
      "epoch: 21, loss: -0.74613\n",
      "epoch: 22, loss: -0.74326\n",
      "epoch: 23, loss: -0.74482\n",
      "epoch: 24, loss: -0.74181\n",
      "epoch: 25, loss: -0.75124\n",
      "epoch: 26, loss: -0.74955\n",
      "epoch: 27, loss: -0.75059\n",
      "epoch: 28, loss: -0.74331\n",
      "epoch: 29, loss: -0.74130\n",
      "epoch: 30, loss: -0.73798\n",
      "epoch: 31, loss: -0.73147\n",
      "epoch: 32, loss: -0.72710\n",
      "epoch: 33, loss: -0.74341\n",
      "epoch: 34, loss: -0.73811\n",
      "epoch: 35, loss: -0.74161\n",
      "epoch: 36, loss: -0.74238\n",
      "epoch: 37, loss: -0.75317\n",
      "epoch: 38, loss: -0.76010\n",
      "epoch: 39, loss: -0.73626\n",
      "epoch: 40, loss: -0.72354\n",
      "epoch: 41, loss: -0.73705\n",
      "epoch: 42, loss: -0.74957\n",
      "epoch: 43, loss: -0.75606\n",
      "epoch: 44, loss: -0.75979\n",
      "epoch: 45, loss: -0.76445\n",
      "epoch: 46, loss: -0.74953\n",
      "epoch: 47, loss: -0.74084\n",
      "epoch: 48, loss: -0.74509\n",
      "epoch: 49, loss: -0.72904\n",
      "epoch: 50, loss: -0.76063\n",
      "epoch: 51, loss: -0.75248\n",
      "epoch: 52, loss: -0.76268\n",
      "epoch: 53, loss: -0.74601\n",
      "epoch: 54, loss: -0.76058\n",
      "epoch: 55, loss: -0.78918\n",
      "epoch: 56, loss: -0.79832\n",
      "epoch: 57, loss: -0.79831\n",
      "epoch: 58, loss: -0.80542\n",
      "epoch: 59, loss: -0.81589\n",
      "epoch: 60, loss: -0.80416\n",
      "epoch: 61, loss: -0.81020\n",
      "epoch: 62, loss: -0.80438\n",
      "epoch: 63, loss: -0.79673\n",
      "epoch: 64, loss: -0.80460\n",
      "epoch: 65, loss: -0.80885\n",
      "epoch: 66, loss: -0.81138\n",
      "epoch: 67, loss: -0.81865\n",
      "epoch: 68, loss: -0.81944\n",
      "epoch: 69, loss: -0.80709\n",
      "epoch: 70, loss: -0.80453\n",
      "epoch: 71, loss: -0.79278\n",
      "epoch: 72, loss: -0.80439\n",
      "epoch: 73, loss: -0.80179\n",
      "epoch: 74, loss: -0.78794\n",
      "epoch: 75, loss: -0.79503\n",
      "epoch: 76, loss: -0.79292\n",
      "epoch: 77, loss: -0.80195\n",
      "epoch: 78, loss: -0.80475\n",
      "epoch: 79, loss: -0.80635\n",
      "epoch: 80, loss: -0.79864\n",
      "epoch: 81, loss: -0.78575\n",
      "epoch: 82, loss: -0.79713\n",
      "epoch: 83, loss: -0.80242\n",
      "epoch: 84, loss: -0.79154\n",
      "epoch: 85, loss: -0.79131\n",
      "epoch: 86, loss: -0.80119\n",
      "epoch: 87, loss: -0.82105\n",
      "epoch: 88, loss: -0.81385\n",
      "epoch: 89, loss: -0.82471\n",
      "epoch: 90, loss: -0.82563\n",
      "epoch: 91, loss: -0.81660\n",
      "epoch: 92, loss: -0.81783\n",
      "epoch: 93, loss: -0.81076\n",
      "epoch: 94, loss: -0.81872\n",
      "epoch: 95, loss: -0.82080\n",
      "epoch: 96, loss: -0.82293\n",
      "epoch: 97, loss: -0.82228\n",
      "epoch: 98, loss: -0.81544\n",
      "epoch: 99, loss: -0.80858\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1000 [18:00<50:02:22, 181.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "6 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0007.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0007\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.50217\n",
      "epoch: 01, loss: -0.64313\n",
      "epoch: 02, loss: -0.68277\n",
      "epoch: 03, loss: -0.70644\n",
      "epoch: 04, loss: -0.71716\n",
      "epoch: 05, loss: -0.70890\n",
      "epoch: 06, loss: -0.70317\n",
      "epoch: 07, loss: -0.70831\n",
      "epoch: 08, loss: -0.72595\n",
      "epoch: 09, loss: -0.74714\n",
      "epoch: 10, loss: -0.75233\n",
      "epoch: 11, loss: -0.75945\n",
      "epoch: 12, loss: -0.75794\n",
      "epoch: 13, loss: -0.75163\n",
      "epoch: 14, loss: -0.76027\n",
      "epoch: 15, loss: -0.77546\n",
      "epoch: 16, loss: -0.77229\n",
      "epoch: 17, loss: -0.77546\n",
      "epoch: 18, loss: -0.78963\n",
      "epoch: 19, loss: -0.79118\n",
      "epoch: 20, loss: -0.79062\n",
      "epoch: 21, loss: -0.80112\n",
      "epoch: 22, loss: -0.79035\n",
      "epoch: 23, loss: -0.79025\n",
      "epoch: 24, loss: -0.79300\n",
      "epoch: 25, loss: -0.79650\n",
      "epoch: 26, loss: -0.79428\n",
      "epoch: 27, loss: -0.79472\n",
      "epoch: 28, loss: -0.80768\n",
      "epoch: 29, loss: -0.82598\n",
      "epoch: 30, loss: -0.81787\n",
      "epoch: 31, loss: -0.81011\n",
      "epoch: 32, loss: -0.80964\n",
      "epoch: 33, loss: -0.81139\n",
      "epoch: 34, loss: -0.82374\n",
      "epoch: 35, loss: -0.83000\n",
      "epoch: 36, loss: -0.83859\n",
      "epoch: 37, loss: -0.85028\n",
      "epoch: 38, loss: -0.85119\n",
      "epoch: 39, loss: -0.86922\n",
      "epoch: 40, loss: -0.87898\n",
      "epoch: 41, loss: -0.88482\n",
      "epoch: 42, loss: -0.88122\n",
      "epoch: 43, loss: -0.88510\n",
      "epoch: 44, loss: -0.87695\n",
      "epoch: 45, loss: -0.87786\n",
      "epoch: 46, loss: -0.87738\n",
      "epoch: 47, loss: -0.87117\n",
      "epoch: 48, loss: -0.85910\n",
      "epoch: 49, loss: -0.86184\n",
      "epoch: 50, loss: -0.86239\n",
      "epoch: 51, loss: -0.87017\n",
      "epoch: 52, loss: -0.87076\n",
      "epoch: 53, loss: -0.85919\n",
      "epoch: 54, loss: -0.86878\n",
      "epoch: 55, loss: -0.85760\n",
      "epoch: 56, loss: -0.84967\n",
      "epoch: 57, loss: -0.84986\n",
      "epoch: 58, loss: -0.85352\n",
      "epoch: 59, loss: -0.85883\n",
      "epoch: 60, loss: -0.85878\n",
      "epoch: 61, loss: -0.86880\n",
      "epoch: 62, loss: -0.87217\n",
      "epoch: 63, loss: -0.87621\n",
      "epoch: 64, loss: -0.87275\n",
      "epoch: 65, loss: -0.87905\n",
      "epoch: 66, loss: -0.88116\n",
      "epoch: 67, loss: -0.88525\n",
      "epoch: 68, loss: -0.88352\n",
      "epoch: 69, loss: -0.88596\n",
      "epoch: 70, loss: -0.88796\n",
      "epoch: 71, loss: -0.89925\n",
      "epoch: 72, loss: -0.90064\n",
      "epoch: 73, loss: -0.90364\n",
      "epoch: 74, loss: -0.89952\n",
      "epoch: 75, loss: -0.90402\n",
      "epoch: 76, loss: -0.90490\n",
      "epoch: 77, loss: -0.90712\n",
      "epoch: 78, loss: -0.90700\n",
      "epoch: 79, loss: -0.91576\n",
      "epoch: 80, loss: -0.92089\n",
      "epoch: 81, loss: -0.92987\n",
      "epoch: 82, loss: -0.92846\n",
      "epoch: 83, loss: -0.92451\n",
      "epoch: 84, loss: -0.91241\n",
      "epoch: 85, loss: -0.90534\n",
      "epoch: 86, loss: -0.90317\n",
      "epoch: 87, loss: -0.91178\n",
      "epoch: 88, loss: -0.91466\n",
      "epoch: 89, loss: -0.91440\n",
      "epoch: 90, loss: -0.90816\n",
      "epoch: 91, loss: -0.89648\n",
      "epoch: 92, loss: -0.89595\n",
      "epoch: 93, loss: -0.89587\n",
      "epoch: 94, loss: -0.89004\n",
      "epoch: 95, loss: -0.88535\n",
      "epoch: 96, loss: -0.88252\n",
      "epoch: 97, loss: -0.88031\n",
      "epoch: 98, loss: -0.87881\n",
      "epoch: 99, loss: -0.87703\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1000 [20:53<49:16:25, 178.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "7 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0008.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0008\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.50540\n",
      "epoch: 01, loss: -0.66164\n",
      "epoch: 02, loss: -0.68461\n",
      "epoch: 03, loss: -0.70048\n",
      "epoch: 04, loss: -0.69750\n",
      "epoch: 05, loss: -0.69870\n",
      "epoch: 06, loss: -0.70267\n",
      "epoch: 07, loss: -0.70468\n",
      "epoch: 08, loss: -0.71534\n",
      "epoch: 09, loss: -0.71422\n",
      "epoch: 10, loss: -0.69783\n",
      "epoch: 11, loss: -0.71329\n",
      "epoch: 12, loss: -0.71958\n",
      "epoch: 13, loss: -0.73150\n",
      "epoch: 14, loss: -0.73962\n",
      "epoch: 15, loss: -0.74326\n",
      "epoch: 16, loss: -0.76135\n",
      "epoch: 17, loss: -0.76629\n",
      "epoch: 18, loss: -0.76176\n",
      "epoch: 19, loss: -0.76070\n",
      "epoch: 20, loss: -0.75379\n",
      "epoch: 21, loss: -0.76671\n",
      "epoch: 22, loss: -0.76844\n",
      "epoch: 23, loss: -0.77721\n",
      "epoch: 24, loss: -0.77564\n",
      "epoch: 25, loss: -0.78119\n",
      "epoch: 26, loss: -0.78513\n",
      "epoch: 27, loss: -0.78580\n",
      "epoch: 28, loss: -0.80285\n",
      "epoch: 29, loss: -0.81220\n",
      "epoch: 30, loss: -0.80889\n",
      "epoch: 31, loss: -0.80849\n",
      "epoch: 32, loss: -0.81398\n",
      "epoch: 33, loss: -0.79968\n",
      "epoch: 34, loss: -0.78716\n",
      "epoch: 35, loss: -0.78656\n",
      "epoch: 36, loss: -0.78618\n",
      "epoch: 37, loss: -0.77676\n",
      "epoch: 38, loss: -0.77582\n",
      "epoch: 39, loss: -0.78485\n",
      "epoch: 40, loss: -0.79183\n",
      "epoch: 41, loss: -0.78963\n",
      "epoch: 42, loss: -0.78540\n",
      "epoch: 43, loss: -0.78919\n",
      "epoch: 44, loss: -0.79859\n",
      "epoch: 45, loss: -0.80576\n",
      "epoch: 46, loss: -0.80691\n",
      "epoch: 47, loss: -0.80453\n",
      "epoch: 48, loss: -0.79566\n",
      "epoch: 49, loss: -0.79004\n",
      "epoch: 50, loss: -0.78752\n",
      "epoch: 51, loss: -0.79338\n",
      "epoch: 52, loss: -0.78782\n",
      "epoch: 53, loss: -0.78567\n",
      "epoch: 54, loss: -0.78390\n",
      "epoch: 55, loss: -0.77214\n",
      "epoch: 56, loss: -0.78503\n",
      "epoch: 57, loss: -0.79004\n",
      "epoch: 58, loss: -0.78762\n",
      "epoch: 59, loss: -0.77857\n",
      "epoch: 60, loss: -0.78925\n",
      "epoch: 61, loss: -0.80002\n",
      "epoch: 62, loss: -0.81162\n",
      "epoch: 63, loss: -0.80386\n",
      "epoch: 64, loss: -0.79397\n",
      "epoch: 65, loss: -0.79478\n",
      "epoch: 66, loss: -0.78751\n",
      "epoch: 67, loss: -0.78109\n",
      "epoch: 68, loss: -0.78803\n",
      "epoch: 69, loss: -0.79225\n",
      "epoch: 70, loss: -0.79434\n",
      "epoch: 71, loss: -0.79516\n",
      "epoch: 72, loss: -0.79450\n",
      "epoch: 73, loss: -0.77754\n",
      "epoch: 74, loss: -0.78127\n",
      "epoch: 75, loss: -0.77586\n",
      "epoch: 76, loss: -0.77882\n",
      "epoch: 77, loss: -0.75543\n",
      "epoch: 78, loss: -0.75047\n",
      "epoch: 79, loss: -0.75816\n",
      "epoch: 80, loss: -0.75921\n",
      "epoch: 81, loss: -0.76195\n",
      "epoch: 82, loss: -0.76223\n",
      "epoch: 83, loss: -0.76378\n",
      "epoch: 84, loss: -0.77741\n",
      "epoch: 85, loss: -0.76970\n",
      "epoch: 86, loss: -0.77446\n",
      "epoch: 87, loss: -0.78340\n",
      "epoch: 88, loss: -0.78665\n",
      "epoch: 89, loss: -0.77372\n",
      "epoch: 90, loss: -0.76820\n",
      "epoch: 91, loss: -0.76563\n",
      "epoch: 92, loss: -0.79186\n",
      "epoch: 93, loss: -0.79302\n",
      "epoch: 94, loss: -0.80254\n",
      "epoch: 95, loss: -0.80008\n",
      "epoch: 96, loss: -0.79798\n",
      "epoch: 97, loss: -0.80936\n",
      "epoch: 98, loss: -0.81236\n",
      "epoch: 99, loss: -0.78168\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1000 [23:45<48:40:42, 176.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "8 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0009.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0009\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.46613\n",
      "epoch: 01, loss: -0.66667\n",
      "epoch: 02, loss: -0.71304\n",
      "epoch: 03, loss: -0.74174\n",
      "epoch: 04, loss: -0.72664\n",
      "epoch: 05, loss: -0.72998\n",
      "epoch: 06, loss: -0.73687\n",
      "epoch: 07, loss: -0.76084\n",
      "epoch: 08, loss: -0.76966\n",
      "epoch: 09, loss: -0.78061\n",
      "epoch: 10, loss: -0.78413\n",
      "epoch: 11, loss: -0.79078\n",
      "epoch: 12, loss: -0.78909\n",
      "epoch: 13, loss: -0.78401\n",
      "epoch: 14, loss: -0.80306\n",
      "epoch: 15, loss: -0.82598\n",
      "epoch: 16, loss: -0.83292\n",
      "epoch: 17, loss: -0.83516\n",
      "epoch: 18, loss: -0.85019\n",
      "epoch: 19, loss: -0.84888\n",
      "epoch: 20, loss: -0.85130\n",
      "epoch: 21, loss: -0.86246\n",
      "epoch: 22, loss: -0.84810\n",
      "epoch: 23, loss: -0.84546\n",
      "epoch: 24, loss: -0.84935\n",
      "epoch: 25, loss: -0.84501\n",
      "epoch: 26, loss: -0.84250\n",
      "epoch: 27, loss: -0.85463\n",
      "epoch: 28, loss: -0.84438\n",
      "epoch: 29, loss: -0.83931\n",
      "epoch: 30, loss: -0.83417\n",
      "epoch: 31, loss: -0.84205\n",
      "epoch: 32, loss: -0.83996\n",
      "epoch: 33, loss: -0.81048\n",
      "epoch: 34, loss: -0.80400\n",
      "epoch: 35, loss: -0.79699\n",
      "epoch: 36, loss: -0.79250\n",
      "epoch: 37, loss: -0.81074\n",
      "epoch: 38, loss: -0.80736\n",
      "epoch: 39, loss: -0.78461\n",
      "epoch: 40, loss: -0.78181\n",
      "epoch: 41, loss: -0.78927\n",
      "epoch: 42, loss: -0.77833\n",
      "epoch: 43, loss: -0.77364\n",
      "epoch: 44, loss: -0.77149\n",
      "epoch: 45, loss: -0.77704\n",
      "epoch: 46, loss: -0.76900\n",
      "epoch: 47, loss: -0.77676\n",
      "epoch: 48, loss: -0.76845\n",
      "epoch: 49, loss: -0.73913\n",
      "epoch: 50, loss: -0.74838\n",
      "epoch: 51, loss: -0.76102\n",
      "epoch: 52, loss: -0.76848\n",
      "epoch: 53, loss: -0.77352\n",
      "epoch: 54, loss: -0.78040\n",
      "epoch: 55, loss: -0.77000\n",
      "epoch: 56, loss: -0.77487\n",
      "epoch: 57, loss: -0.78024\n",
      "epoch: 58, loss: -0.78947\n",
      "epoch: 59, loss: -0.79164\n",
      "epoch: 60, loss: -0.79030\n",
      "epoch: 61, loss: -0.79088\n",
      "epoch: 62, loss: -0.78815\n",
      "epoch: 63, loss: -0.80223\n",
      "epoch: 64, loss: -0.79960\n",
      "epoch: 65, loss: -0.80310\n",
      "epoch: 66, loss: -0.79620\n",
      "epoch: 67, loss: -0.80919\n",
      "epoch: 68, loss: -0.82428\n",
      "epoch: 69, loss: -0.82188\n",
      "epoch: 70, loss: -0.84010\n",
      "epoch: 71, loss: -0.84177\n",
      "epoch: 72, loss: -0.84453\n",
      "epoch: 73, loss: -0.83851\n",
      "epoch: 74, loss: -0.83250\n",
      "epoch: 75, loss: -0.82997\n",
      "epoch: 76, loss: -0.82087\n",
      "epoch: 77, loss: -0.83252\n",
      "epoch: 78, loss: -0.82425\n",
      "epoch: 79, loss: -0.82734\n",
      "epoch: 80, loss: -0.82115\n",
      "epoch: 81, loss: -0.82364\n",
      "epoch: 82, loss: -0.82741\n",
      "epoch: 83, loss: -0.81577\n",
      "epoch: 84, loss: -0.82667\n",
      "epoch: 85, loss: -0.81623\n",
      "epoch: 86, loss: -0.82784\n",
      "epoch: 87, loss: -0.82073\n",
      "epoch: 88, loss: -0.82744\n",
      "epoch: 89, loss: -0.84238\n",
      "epoch: 90, loss: -0.82941\n",
      "epoch: 91, loss: -0.83738\n",
      "epoch: 92, loss: -0.83459\n",
      "epoch: 93, loss: -0.82997\n",
      "epoch: 94, loss: -0.82019\n",
      "epoch: 95, loss: -0.83830\n",
      "epoch: 96, loss: -0.83037\n",
      "epoch: 97, loss: -0.82677\n",
      "epoch: 98, loss: -0.80705\n",
      "epoch: 99, loss: -0.82649\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1000 [26:35<48:03:16, 174.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "9 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0010.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0010\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.55586\n",
      "epoch: 01, loss: -0.71347\n",
      "epoch: 02, loss: -0.74304\n",
      "epoch: 03, loss: -0.76867\n",
      "epoch: 04, loss: -0.76584\n",
      "epoch: 05, loss: -0.76847\n",
      "epoch: 06, loss: -0.77239\n",
      "epoch: 07, loss: -0.77737\n",
      "epoch: 08, loss: -0.77617\n",
      "epoch: 09, loss: -0.78671\n",
      "epoch: 10, loss: -0.79740\n",
      "epoch: 11, loss: -0.80043\n",
      "epoch: 12, loss: -0.80337\n",
      "epoch: 13, loss: -0.79612\n",
      "epoch: 14, loss: -0.79137\n",
      "epoch: 15, loss: -0.81057\n",
      "epoch: 16, loss: -0.82005\n",
      "epoch: 17, loss: -0.82501\n",
      "epoch: 18, loss: -0.82648\n",
      "epoch: 19, loss: -0.81127\n",
      "epoch: 20, loss: -0.82080\n",
      "epoch: 21, loss: -0.84017\n",
      "epoch: 22, loss: -0.84354\n",
      "epoch: 23, loss: -0.85105\n",
      "epoch: 24, loss: -0.84498\n",
      "epoch: 25, loss: -0.85297\n",
      "epoch: 26, loss: -0.84245\n",
      "epoch: 27, loss: -0.85366\n",
      "epoch: 28, loss: -0.86061\n",
      "epoch: 29, loss: -0.86258\n",
      "epoch: 30, loss: -0.86663\n",
      "epoch: 31, loss: -0.86909\n",
      "epoch: 32, loss: -0.85830\n",
      "epoch: 33, loss: -0.84825\n",
      "epoch: 34, loss: -0.84892\n",
      "epoch: 35, loss: -0.85070\n",
      "epoch: 36, loss: -0.83757\n",
      "epoch: 37, loss: -0.83783\n",
      "epoch: 38, loss: -0.83306\n",
      "epoch: 39, loss: -0.82881\n",
      "epoch: 40, loss: -0.84151\n",
      "epoch: 41, loss: -0.84763\n",
      "epoch: 42, loss: -0.85024\n",
      "epoch: 43, loss: -0.85105\n",
      "epoch: 44, loss: -0.85413\n",
      "epoch: 45, loss: -0.85586\n",
      "epoch: 46, loss: -0.84501\n",
      "epoch: 47, loss: -0.84415\n",
      "epoch: 48, loss: -0.83830\n",
      "epoch: 49, loss: -0.83770\n",
      "epoch: 50, loss: -0.84510\n",
      "epoch: 51, loss: -0.86045\n",
      "epoch: 52, loss: -0.86868\n",
      "epoch: 53, loss: -0.86827\n",
      "epoch: 54, loss: -0.85758\n",
      "epoch: 55, loss: -0.86043\n",
      "epoch: 56, loss: -0.85261\n",
      "epoch: 57, loss: -0.84873\n",
      "epoch: 58, loss: -0.85079\n",
      "epoch: 59, loss: -0.85872\n",
      "epoch: 60, loss: -0.85390\n",
      "epoch: 61, loss: -0.86502\n",
      "epoch: 62, loss: -0.86678\n",
      "epoch: 63, loss: -0.86401\n",
      "epoch: 64, loss: -0.87437\n",
      "epoch: 65, loss: -0.88826\n",
      "epoch: 66, loss: -0.88527\n",
      "epoch: 67, loss: -0.87540\n",
      "epoch: 68, loss: -0.87594\n",
      "epoch: 69, loss: -0.86921\n",
      "epoch: 70, loss: -0.86752\n",
      "epoch: 71, loss: -0.87154\n",
      "epoch: 72, loss: -0.87028\n",
      "epoch: 73, loss: -0.87052\n",
      "epoch: 74, loss: -0.87025\n",
      "epoch: 75, loss: -0.85968\n",
      "epoch: 76, loss: -0.87386\n",
      "epoch: 77, loss: -0.88298\n",
      "epoch: 78, loss: -0.89242\n",
      "epoch: 79, loss: -0.90239\n",
      "epoch: 80, loss: -0.90089\n",
      "epoch: 81, loss: -0.89024\n",
      "epoch: 82, loss: -0.90564\n",
      "epoch: 83, loss: -0.90876\n",
      "epoch: 84, loss: -0.91455\n",
      "epoch: 85, loss: -0.90741\n",
      "epoch: 86, loss: -0.90179\n",
      "epoch: 87, loss: -0.89812\n",
      "epoch: 88, loss: -0.89302\n",
      "epoch: 89, loss: -0.90206\n",
      "epoch: 90, loss: -0.89815\n",
      "epoch: 91, loss: -0.90134\n",
      "epoch: 92, loss: -0.90338\n",
      "epoch: 93, loss: -0.90294\n",
      "epoch: 94, loss: -0.90613\n",
      "epoch: 95, loss: -0.90351\n",
      "epoch: 96, loss: -0.90807\n",
      "epoch: 97, loss: -0.90229\n",
      "epoch: 98, loss: -0.89375\n",
      "epoch: 99, loss: -0.90548\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [29:23<47:27:45, 172.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "10 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0011.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0011\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.52300\n",
      "epoch: 01, loss: -0.67079\n",
      "epoch: 02, loss: -0.69980\n",
      "epoch: 03, loss: -0.72098\n",
      "epoch: 04, loss: -0.73019\n",
      "epoch: 05, loss: -0.72768\n",
      "epoch: 06, loss: -0.73113\n",
      "epoch: 07, loss: -0.75172\n",
      "epoch: 08, loss: -0.76982\n",
      "epoch: 09, loss: -0.76108\n",
      "epoch: 10, loss: -0.76058\n",
      "epoch: 11, loss: -0.77833\n",
      "epoch: 12, loss: -0.75883\n",
      "epoch: 13, loss: -0.77390\n",
      "epoch: 14, loss: -0.76767\n",
      "epoch: 15, loss: -0.78035\n",
      "epoch: 16, loss: -0.79246\n",
      "epoch: 17, loss: -0.79146\n",
      "epoch: 18, loss: -0.79436\n",
      "epoch: 19, loss: -0.79796\n",
      "epoch: 20, loss: -0.79921\n",
      "epoch: 21, loss: -0.80348\n",
      "epoch: 22, loss: -0.82248\n",
      "epoch: 23, loss: -0.83009\n",
      "epoch: 24, loss: -0.83885\n",
      "epoch: 25, loss: -0.84306\n",
      "epoch: 26, loss: -0.83258\n",
      "epoch: 27, loss: -0.84325\n",
      "epoch: 28, loss: -0.83656\n",
      "epoch: 29, loss: -0.83257\n",
      "epoch: 30, loss: -0.83851\n",
      "epoch: 31, loss: -0.83934\n",
      "epoch: 32, loss: -0.83988\n",
      "epoch: 33, loss: -0.83701\n",
      "epoch: 34, loss: -0.83018\n",
      "epoch: 35, loss: -0.82332\n",
      "epoch: 36, loss: -0.82310\n",
      "epoch: 37, loss: -0.83179\n",
      "epoch: 38, loss: -0.83210\n",
      "epoch: 39, loss: -0.82140\n",
      "epoch: 40, loss: -0.81828\n",
      "epoch: 41, loss: -0.82073\n",
      "epoch: 42, loss: -0.83306\n",
      "epoch: 43, loss: -0.82914\n",
      "epoch: 44, loss: -0.82757\n",
      "epoch: 45, loss: -0.82667\n",
      "epoch: 46, loss: -0.83482\n",
      "epoch: 47, loss: -0.83011\n",
      "epoch: 48, loss: -0.83187\n",
      "epoch: 49, loss: -0.82834\n",
      "epoch: 50, loss: -0.83319\n",
      "epoch: 51, loss: -0.84656\n",
      "epoch: 52, loss: -0.85740\n",
      "epoch: 53, loss: -0.85014\n",
      "epoch: 54, loss: -0.85595\n",
      "epoch: 55, loss: -0.85105\n",
      "epoch: 56, loss: -0.85374\n",
      "epoch: 57, loss: -0.84947\n",
      "epoch: 58, loss: -0.85923\n",
      "epoch: 59, loss: -0.86464\n",
      "epoch: 60, loss: -0.86600\n",
      "epoch: 61, loss: -0.86427\n",
      "epoch: 62, loss: -0.86379\n",
      "epoch: 63, loss: -0.86021\n",
      "epoch: 64, loss: -0.87213\n",
      "epoch: 65, loss: -0.87544\n",
      "epoch: 66, loss: -0.87280\n",
      "epoch: 67, loss: -0.87044\n",
      "epoch: 68, loss: -0.87240\n",
      "epoch: 69, loss: -0.88351\n",
      "epoch: 70, loss: -0.88684\n",
      "epoch: 71, loss: -0.88856\n",
      "epoch: 72, loss: -0.88806\n",
      "epoch: 73, loss: -0.88217\n",
      "epoch: 74, loss: -0.87810\n",
      "epoch: 75, loss: -0.86561\n",
      "epoch: 76, loss: -0.87295\n",
      "epoch: 77, loss: -0.87703\n",
      "epoch: 78, loss: -0.86926\n",
      "epoch: 79, loss: -0.88006\n",
      "epoch: 80, loss: -0.88374\n",
      "epoch: 81, loss: -0.89064\n",
      "epoch: 82, loss: -0.89730\n",
      "epoch: 83, loss: -0.88990\n",
      "epoch: 84, loss: -0.88968\n",
      "epoch: 85, loss: -0.88936\n",
      "epoch: 86, loss: -0.88593\n",
      "epoch: 87, loss: -0.89262\n",
      "epoch: 88, loss: -0.89310\n",
      "epoch: 89, loss: -0.90227\n",
      "epoch: 90, loss: -0.89601\n",
      "epoch: 91, loss: -0.90046\n",
      "epoch: 92, loss: -0.90480\n",
      "epoch: 93, loss: -0.90424\n",
      "epoch: 94, loss: -0.90815\n",
      "epoch: 95, loss: -0.90648\n",
      "epoch: 96, loss: -0.90757\n",
      "epoch: 97, loss: -0.91148\n",
      "epoch: 98, loss: -0.91243\n",
      "epoch: 99, loss: -0.91430\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [32:17<47:31:54, 173.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "11 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0012.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0012\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.56554\n",
      "epoch: 01, loss: -0.73055\n",
      "epoch: 02, loss: -0.75473\n",
      "epoch: 03, loss: -0.76480\n",
      "epoch: 04, loss: -0.77677\n",
      "epoch: 05, loss: -0.79189\n",
      "epoch: 06, loss: -0.79174\n",
      "epoch: 07, loss: -0.79128\n",
      "epoch: 08, loss: -0.79522\n",
      "epoch: 09, loss: -0.79484\n",
      "epoch: 10, loss: -0.79369\n",
      "epoch: 11, loss: -0.80117\n",
      "epoch: 12, loss: -0.80963\n",
      "epoch: 13, loss: -0.80699\n",
      "epoch: 14, loss: -0.81761\n",
      "epoch: 15, loss: -0.81494\n",
      "epoch: 16, loss: -0.81890\n",
      "epoch: 17, loss: -0.82107\n",
      "epoch: 18, loss: -0.82041\n",
      "epoch: 19, loss: -0.82870\n",
      "epoch: 20, loss: -0.82954\n",
      "epoch: 21, loss: -0.82461\n",
      "epoch: 22, loss: -0.82030\n",
      "epoch: 23, loss: -0.82450\n",
      "epoch: 24, loss: -0.83185\n",
      "epoch: 25, loss: -0.83167\n",
      "epoch: 26, loss: -0.82750\n",
      "epoch: 27, loss: -0.83816\n",
      "epoch: 28, loss: -0.82648\n",
      "epoch: 29, loss: -0.82952\n",
      "epoch: 30, loss: -0.82896\n",
      "epoch: 31, loss: -0.81904\n",
      "epoch: 32, loss: -0.81946\n",
      "epoch: 33, loss: -0.81937\n",
      "epoch: 34, loss: -0.82117\n",
      "epoch: 35, loss: -0.81105\n",
      "epoch: 36, loss: -0.79701\n",
      "epoch: 37, loss: -0.81622\n",
      "epoch: 38, loss: -0.81004\n",
      "epoch: 39, loss: -0.81736\n",
      "epoch: 40, loss: -0.80412\n",
      "epoch: 41, loss: -0.80751\n",
      "epoch: 42, loss: -0.81438\n",
      "epoch: 43, loss: -0.81432\n",
      "epoch: 44, loss: -0.82694\n",
      "epoch: 45, loss: -0.83069\n",
      "epoch: 46, loss: -0.82665\n",
      "epoch: 47, loss: -0.81920\n",
      "epoch: 48, loss: -0.82545\n",
      "epoch: 49, loss: -0.82395\n",
      "epoch: 50, loss: -0.82225\n",
      "epoch: 51, loss: -0.83304\n",
      "epoch: 52, loss: -0.83808\n",
      "epoch: 53, loss: -0.84059\n",
      "epoch: 54, loss: -0.83836\n",
      "epoch: 55, loss: -0.83172\n",
      "epoch: 56, loss: -0.81943\n",
      "epoch: 57, loss: -0.82011\n",
      "epoch: 58, loss: -0.81873\n",
      "epoch: 59, loss: -0.81766\n",
      "epoch: 60, loss: -0.82167\n",
      "epoch: 61, loss: -0.80545\n",
      "epoch: 62, loss: -0.79730\n",
      "epoch: 63, loss: -0.80049\n",
      "epoch: 64, loss: -0.79968\n",
      "epoch: 65, loss: -0.79868\n",
      "epoch: 66, loss: -0.80435\n",
      "epoch: 67, loss: -0.79732\n",
      "epoch: 68, loss: -0.79803\n",
      "epoch: 69, loss: -0.80430\n",
      "epoch: 70, loss: -0.81532\n",
      "epoch: 71, loss: -0.83176\n",
      "epoch: 72, loss: -0.84376\n",
      "epoch: 73, loss: -0.85538\n",
      "epoch: 74, loss: -0.85147\n",
      "epoch: 75, loss: -0.84540\n",
      "epoch: 76, loss: -0.85069\n",
      "epoch: 77, loss: -0.85157\n",
      "epoch: 78, loss: -0.84928\n",
      "epoch: 79, loss: -0.84036\n",
      "epoch: 80, loss: -0.83529\n",
      "epoch: 81, loss: -0.83268\n",
      "epoch: 82, loss: -0.84396\n",
      "epoch: 83, loss: -0.84608\n",
      "epoch: 84, loss: -0.84396\n",
      "epoch: 85, loss: -0.83212\n",
      "epoch: 86, loss: -0.84976\n",
      "epoch: 87, loss: -0.84122\n",
      "epoch: 88, loss: -0.84888\n",
      "epoch: 89, loss: -0.84605\n",
      "epoch: 90, loss: -0.84745\n",
      "epoch: 91, loss: -0.85608\n",
      "epoch: 92, loss: -0.85978\n",
      "epoch: 93, loss: -0.85745\n",
      "epoch: 94, loss: -0.86107\n",
      "epoch: 95, loss: -0.85912\n",
      "epoch: 96, loss: -0.85490\n",
      "epoch: 97, loss: -0.85189\n",
      "epoch: 98, loss: -0.84835\n",
      "epoch: 99, loss: -0.84931\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [35:04<46:54:36, 170.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "12 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0013.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0013\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.48497\n",
      "epoch: 01, loss: -0.68736\n",
      "epoch: 02, loss: -0.71714\n",
      "epoch: 03, loss: -0.71947\n",
      "epoch: 04, loss: -0.71902\n",
      "epoch: 05, loss: -0.72287\n",
      "epoch: 06, loss: -0.74468\n",
      "epoch: 07, loss: -0.75578\n",
      "epoch: 08, loss: -0.76913\n",
      "epoch: 09, loss: -0.78349\n",
      "epoch: 10, loss: -0.78015\n",
      "epoch: 11, loss: -0.77891\n",
      "epoch: 12, loss: -0.78060\n",
      "epoch: 13, loss: -0.77686\n",
      "epoch: 14, loss: -0.79191\n",
      "epoch: 15, loss: -0.79692\n",
      "epoch: 16, loss: -0.78737\n",
      "epoch: 17, loss: -0.80241\n",
      "epoch: 18, loss: -0.79546\n",
      "epoch: 19, loss: -0.80472\n",
      "epoch: 20, loss: -0.80757\n",
      "epoch: 21, loss: -0.81130\n",
      "epoch: 22, loss: -0.81810\n",
      "epoch: 23, loss: -0.81843\n",
      "epoch: 24, loss: -0.81248\n",
      "epoch: 25, loss: -0.81260\n",
      "epoch: 26, loss: -0.81535\n",
      "epoch: 27, loss: -0.79842\n",
      "epoch: 28, loss: -0.80174\n",
      "epoch: 29, loss: -0.78975\n",
      "epoch: 30, loss: -0.76692\n",
      "epoch: 31, loss: -0.76018\n",
      "epoch: 32, loss: -0.79045\n",
      "epoch: 33, loss: -0.79770\n",
      "epoch: 34, loss: -0.80555\n",
      "epoch: 35, loss: -0.80510\n",
      "epoch: 36, loss: -0.82746\n",
      "epoch: 37, loss: -0.82928\n",
      "epoch: 38, loss: -0.79398\n",
      "epoch: 39, loss: -0.79798\n",
      "epoch: 40, loss: -0.80996\n",
      "epoch: 41, loss: -0.82566\n",
      "epoch: 42, loss: -0.83086\n",
      "epoch: 43, loss: -0.83512\n",
      "epoch: 44, loss: -0.82164\n",
      "epoch: 45, loss: -0.81617\n",
      "epoch: 46, loss: -0.81637\n",
      "epoch: 47, loss: -0.81370\n",
      "epoch: 48, loss: -0.81342\n",
      "epoch: 49, loss: -0.81000\n",
      "epoch: 50, loss: -0.81223\n",
      "epoch: 51, loss: -0.80500\n",
      "epoch: 52, loss: -0.80398\n",
      "epoch: 53, loss: -0.79903\n",
      "epoch: 54, loss: -0.80893\n",
      "epoch: 55, loss: -0.81114\n",
      "epoch: 56, loss: -0.79034\n",
      "epoch: 57, loss: -0.81210\n",
      "epoch: 58, loss: -0.81395\n",
      "epoch: 59, loss: -0.81981\n",
      "epoch: 60, loss: -0.80631\n",
      "epoch: 61, loss: -0.82708\n",
      "epoch: 62, loss: -0.82387\n",
      "epoch: 63, loss: -0.82175\n",
      "epoch: 64, loss: -0.81621\n",
      "epoch: 65, loss: -0.83648\n",
      "epoch: 66, loss: -0.83672\n",
      "epoch: 67, loss: -0.83547\n",
      "epoch: 68, loss: -0.83846\n",
      "epoch: 69, loss: -0.82963\n",
      "epoch: 70, loss: -0.84827\n",
      "epoch: 71, loss: -0.84469\n",
      "epoch: 72, loss: -0.83744\n",
      "epoch: 73, loss: -0.83501\n",
      "epoch: 74, loss: -0.82084\n",
      "epoch: 75, loss: -0.82081\n",
      "epoch: 76, loss: -0.83083\n",
      "epoch: 77, loss: -0.83327\n",
      "epoch: 78, loss: -0.83867\n",
      "epoch: 79, loss: -0.83630\n",
      "epoch: 80, loss: -0.84118\n",
      "epoch: 81, loss: -0.83720\n",
      "epoch: 82, loss: -0.83968\n",
      "epoch: 83, loss: -0.83198\n",
      "epoch: 84, loss: -0.83555\n",
      "epoch: 85, loss: -0.83208\n",
      "epoch: 86, loss: -0.82589\n",
      "epoch: 87, loss: -0.82665\n",
      "epoch: 88, loss: -0.83080\n",
      "epoch: 89, loss: -0.81539\n",
      "epoch: 90, loss: -0.81728\n",
      "epoch: 91, loss: -0.82810\n",
      "epoch: 92, loss: -0.83146\n",
      "epoch: 93, loss: -0.83425\n",
      "epoch: 94, loss: -0.83815\n",
      "epoch: 95, loss: -0.83886\n",
      "epoch: 96, loss: -0.84588\n",
      "epoch: 97, loss: -0.84374\n",
      "epoch: 98, loss: -0.84104\n",
      "epoch: 99, loss: -0.82732\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 13/1000 [37:52<46:40:03, 170.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "13 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0014.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0014\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.49810\n",
      "epoch: 01, loss: -0.65984\n",
      "epoch: 02, loss: -0.69154\n",
      "epoch: 03, loss: -0.68339\n",
      "epoch: 04, loss: -0.69084\n",
      "epoch: 05, loss: -0.68988\n",
      "epoch: 06, loss: -0.69770\n",
      "epoch: 07, loss: -0.71345\n",
      "epoch: 08, loss: -0.73036\n",
      "epoch: 09, loss: -0.73494\n",
      "epoch: 10, loss: -0.73860\n",
      "epoch: 11, loss: -0.74149\n",
      "epoch: 12, loss: -0.73563\n",
      "epoch: 13, loss: -0.73395\n",
      "epoch: 14, loss: -0.73410\n",
      "epoch: 15, loss: -0.74469\n",
      "epoch: 16, loss: -0.74077\n",
      "epoch: 17, loss: -0.72795\n",
      "epoch: 18, loss: -0.72336\n",
      "epoch: 19, loss: -0.72938\n",
      "epoch: 20, loss: -0.73171\n",
      "epoch: 21, loss: -0.72944\n",
      "epoch: 22, loss: -0.73069\n",
      "epoch: 23, loss: -0.72924\n",
      "epoch: 24, loss: -0.73326\n",
      "epoch: 25, loss: -0.73656\n",
      "epoch: 26, loss: -0.73307\n",
      "epoch: 27, loss: -0.72248\n",
      "epoch: 28, loss: -0.71235\n",
      "epoch: 29, loss: -0.71474\n",
      "epoch: 30, loss: -0.72011\n",
      "epoch: 31, loss: -0.71929\n",
      "epoch: 32, loss: -0.72517\n",
      "epoch: 33, loss: -0.74046\n",
      "epoch: 34, loss: -0.74091\n",
      "epoch: 35, loss: -0.74314\n",
      "epoch: 36, loss: -0.73245\n",
      "epoch: 37, loss: -0.72993\n",
      "epoch: 38, loss: -0.73790\n",
      "epoch: 39, loss: -0.72836\n",
      "epoch: 40, loss: -0.73694\n",
      "epoch: 41, loss: -0.72670\n",
      "epoch: 42, loss: -0.73382\n",
      "epoch: 43, loss: -0.74637\n",
      "epoch: 44, loss: -0.75741\n",
      "epoch: 45, loss: -0.75986\n",
      "epoch: 46, loss: -0.77123\n",
      "epoch: 47, loss: -0.79054\n",
      "epoch: 48, loss: -0.79828\n",
      "epoch: 49, loss: -0.80230\n",
      "epoch: 50, loss: -0.80776\n",
      "epoch: 51, loss: -0.81245\n",
      "epoch: 52, loss: -0.80437\n",
      "epoch: 53, loss: -0.80173\n",
      "epoch: 54, loss: -0.79720\n",
      "epoch: 55, loss: -0.79335\n",
      "epoch: 56, loss: -0.78569\n",
      "epoch: 57, loss: -0.77741\n",
      "epoch: 58, loss: -0.77735\n",
      "epoch: 59, loss: -0.78172\n",
      "epoch: 60, loss: -0.78718\n",
      "epoch: 61, loss: -0.77618\n",
      "epoch: 62, loss: -0.77142\n",
      "epoch: 63, loss: -0.77874\n",
      "epoch: 64, loss: -0.78011\n",
      "epoch: 65, loss: -0.78874\n",
      "epoch: 66, loss: -0.78507\n",
      "epoch: 67, loss: -0.77779\n",
      "epoch: 68, loss: -0.78453\n",
      "epoch: 69, loss: -0.78732\n",
      "epoch: 70, loss: -0.79269\n",
      "epoch: 71, loss: -0.79216\n",
      "epoch: 72, loss: -0.78954\n",
      "epoch: 73, loss: -0.78978\n",
      "epoch: 74, loss: -0.79196\n",
      "epoch: 75, loss: -0.78800\n",
      "epoch: 76, loss: -0.79151\n",
      "epoch: 77, loss: -0.80006\n",
      "epoch: 78, loss: -0.79692\n",
      "epoch: 79, loss: -0.80663\n",
      "epoch: 80, loss: -0.81427\n",
      "epoch: 81, loss: -0.82363\n",
      "epoch: 82, loss: -0.80751\n",
      "epoch: 83, loss: -0.80883\n",
      "epoch: 84, loss: -0.80989\n",
      "epoch: 85, loss: -0.81741\n",
      "epoch: 86, loss: -0.82055\n",
      "epoch: 87, loss: -0.81645\n",
      "epoch: 88, loss: -0.81557\n",
      "epoch: 89, loss: -0.80338\n",
      "epoch: 90, loss: -0.81181\n",
      "epoch: 91, loss: -0.79875\n",
      "epoch: 92, loss: -0.80053\n",
      "epoch: 93, loss: -0.80618\n",
      "epoch: 94, loss: -0.80447\n",
      "epoch: 95, loss: -0.80203\n",
      "epoch: 96, loss: -0.80426\n",
      "epoch: 97, loss: -0.80428\n",
      "epoch: 98, loss: -0.81189\n",
      "epoch: 99, loss: -0.81392\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 14/1000 [40:39<46:20:38, 169.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "14 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0015.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0015\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.53619\n",
      "epoch: 01, loss: -0.67824\n",
      "epoch: 02, loss: -0.70072\n",
      "epoch: 03, loss: -0.72229\n",
      "epoch: 04, loss: -0.74490\n",
      "epoch: 05, loss: -0.74792\n",
      "epoch: 06, loss: -0.76099\n",
      "epoch: 07, loss: -0.78772\n",
      "epoch: 08, loss: -0.79661\n",
      "epoch: 09, loss: -0.79498\n",
      "epoch: 10, loss: -0.79643\n",
      "epoch: 11, loss: -0.80152\n",
      "epoch: 12, loss: -0.80374\n",
      "epoch: 13, loss: -0.77803\n",
      "epoch: 14, loss: -0.78079\n",
      "epoch: 15, loss: -0.77761\n",
      "epoch: 16, loss: -0.77242\n",
      "epoch: 17, loss: -0.77050\n",
      "epoch: 18, loss: -0.77005\n",
      "epoch: 19, loss: -0.76872\n",
      "epoch: 20, loss: -0.77423\n",
      "epoch: 21, loss: -0.78119\n",
      "epoch: 22, loss: -0.78560\n",
      "epoch: 23, loss: -0.77688\n",
      "epoch: 24, loss: -0.75909\n",
      "epoch: 25, loss: -0.75605\n",
      "epoch: 26, loss: -0.74226\n",
      "epoch: 27, loss: -0.74537\n",
      "epoch: 28, loss: -0.75159\n",
      "epoch: 29, loss: -0.76631\n",
      "epoch: 30, loss: -0.77780\n",
      "epoch: 31, loss: -0.78916\n",
      "epoch: 32, loss: -0.78385\n",
      "epoch: 33, loss: -0.79099\n",
      "epoch: 34, loss: -0.79285\n",
      "epoch: 35, loss: -0.78802\n",
      "epoch: 36, loss: -0.79202\n",
      "epoch: 37, loss: -0.78913\n",
      "epoch: 38, loss: -0.79269\n",
      "epoch: 39, loss: -0.78459\n",
      "epoch: 40, loss: -0.77040\n",
      "epoch: 41, loss: -0.77176\n",
      "epoch: 42, loss: -0.77627\n",
      "epoch: 43, loss: -0.78226\n",
      "epoch: 44, loss: -0.79570\n",
      "epoch: 45, loss: -0.80095\n",
      "epoch: 46, loss: -0.80099\n",
      "epoch: 47, loss: -0.80801\n",
      "epoch: 48, loss: -0.83212\n",
      "epoch: 49, loss: -0.83249\n",
      "epoch: 50, loss: -0.81851\n",
      "epoch: 51, loss: -0.81284\n",
      "epoch: 52, loss: -0.81120\n",
      "epoch: 53, loss: -0.81819\n",
      "epoch: 54, loss: -0.81903\n",
      "epoch: 55, loss: -0.82536\n",
      "epoch: 56, loss: -0.80362\n",
      "epoch: 57, loss: -0.81384\n",
      "epoch: 58, loss: -0.81554\n",
      "epoch: 59, loss: -0.81379\n",
      "epoch: 60, loss: -0.81212\n",
      "epoch: 61, loss: -0.81391\n",
      "epoch: 62, loss: -0.81610\n",
      "epoch: 63, loss: -0.81840\n",
      "epoch: 64, loss: -0.82451\n",
      "epoch: 65, loss: -0.83969\n",
      "epoch: 66, loss: -0.84429\n",
      "epoch: 67, loss: -0.84111\n",
      "epoch: 68, loss: -0.84369\n",
      "epoch: 69, loss: -0.84033\n",
      "epoch: 70, loss: -0.83093\n",
      "epoch: 71, loss: -0.82112\n",
      "epoch: 72, loss: -0.81067\n",
      "epoch: 73, loss: -0.78504\n",
      "epoch: 74, loss: -0.74986\n",
      "epoch: 75, loss: -0.74630\n",
      "epoch: 76, loss: -0.76970\n",
      "epoch: 77, loss: -0.77870\n",
      "epoch: 78, loss: -0.76500\n",
      "epoch: 79, loss: -0.76766\n",
      "epoch: 80, loss: -0.76176\n",
      "epoch: 81, loss: -0.77384\n",
      "epoch: 82, loss: -0.76560\n",
      "epoch: 83, loss: -0.77485\n",
      "epoch: 84, loss: -0.79036\n",
      "epoch: 85, loss: -0.79566\n",
      "epoch: 86, loss: -0.78745\n",
      "epoch: 87, loss: -0.79996\n",
      "epoch: 88, loss: -0.79706\n",
      "epoch: 89, loss: -0.80296\n",
      "epoch: 90, loss: -0.80680\n",
      "epoch: 91, loss: -0.81461\n",
      "epoch: 92, loss: -0.80928\n",
      "epoch: 93, loss: -0.80343\n",
      "epoch: 94, loss: -0.81305\n",
      "epoch: 95, loss: -0.79925\n",
      "epoch: 96, loss: -0.80603\n",
      "epoch: 97, loss: -0.80411\n",
      "epoch: 98, loss: -0.81819\n",
      "epoch: 99, loss: -0.81082\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 15/1000 [43:30<46:26:55, 169.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "15 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0016.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0016\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.46829\n",
      "epoch: 01, loss: -0.63255\n",
      "epoch: 02, loss: -0.65881\n",
      "epoch: 03, loss: -0.68194\n",
      "epoch: 04, loss: -0.68807\n",
      "epoch: 05, loss: -0.71063\n",
      "epoch: 06, loss: -0.72741\n",
      "epoch: 07, loss: -0.74193\n",
      "epoch: 08, loss: -0.74203\n",
      "epoch: 09, loss: -0.72918\n",
      "epoch: 10, loss: -0.69334\n",
      "epoch: 11, loss: -0.69441\n",
      "epoch: 12, loss: -0.72208\n",
      "epoch: 13, loss: -0.73751\n",
      "epoch: 14, loss: -0.74325\n",
      "epoch: 15, loss: -0.74680\n",
      "epoch: 16, loss: -0.74886\n",
      "epoch: 17, loss: -0.75370\n",
      "epoch: 18, loss: -0.74986\n",
      "epoch: 19, loss: -0.74364\n",
      "epoch: 20, loss: -0.73875\n",
      "epoch: 21, loss: -0.71562\n",
      "epoch: 22, loss: -0.71765\n",
      "epoch: 23, loss: -0.71491\n",
      "epoch: 24, loss: -0.71853\n",
      "epoch: 25, loss: -0.72740\n",
      "epoch: 26, loss: -0.72384\n",
      "epoch: 27, loss: -0.72075\n",
      "epoch: 28, loss: -0.70629\n",
      "epoch: 29, loss: -0.70143\n",
      "epoch: 30, loss: -0.71799\n",
      "epoch: 31, loss: -0.72543\n",
      "epoch: 32, loss: -0.73456\n",
      "epoch: 33, loss: -0.74974\n",
      "epoch: 34, loss: -0.74665\n",
      "epoch: 35, loss: -0.73520\n",
      "epoch: 36, loss: -0.72487\n",
      "epoch: 37, loss: -0.72293\n",
      "epoch: 38, loss: -0.70331\n",
      "epoch: 39, loss: -0.70439\n",
      "epoch: 40, loss: -0.73260\n",
      "epoch: 41, loss: -0.73613\n",
      "epoch: 42, loss: -0.75289\n",
      "epoch: 43, loss: -0.78398\n",
      "epoch: 44, loss: -0.78627\n",
      "epoch: 45, loss: -0.76889\n",
      "epoch: 46, loss: -0.78229\n",
      "epoch: 47, loss: -0.77530\n",
      "epoch: 48, loss: -0.75200\n",
      "epoch: 49, loss: -0.72864\n",
      "epoch: 50, loss: -0.74979\n",
      "epoch: 51, loss: -0.75713\n",
      "epoch: 52, loss: -0.73723\n",
      "epoch: 53, loss: -0.73440\n",
      "epoch: 54, loss: -0.72726\n",
      "epoch: 55, loss: -0.71620\n",
      "epoch: 56, loss: -0.73410\n",
      "epoch: 57, loss: -0.74229\n",
      "epoch: 58, loss: -0.72878\n",
      "epoch: 59, loss: -0.73047\n",
      "epoch: 60, loss: -0.74034\n",
      "epoch: 61, loss: -0.74675\n",
      "epoch: 62, loss: -0.73211\n",
      "epoch: 63, loss: -0.73212\n",
      "epoch: 64, loss: -0.71668\n",
      "epoch: 65, loss: -0.71421\n",
      "epoch: 66, loss: -0.70616\n",
      "epoch: 67, loss: -0.71498\n",
      "epoch: 68, loss: -0.70143\n",
      "epoch: 69, loss: -0.72227\n",
      "epoch: 70, loss: -0.72205\n",
      "epoch: 71, loss: -0.73419\n",
      "epoch: 72, loss: -0.73756\n",
      "epoch: 73, loss: -0.74132\n",
      "epoch: 74, loss: -0.73804\n",
      "epoch: 75, loss: -0.73892\n",
      "epoch: 76, loss: -0.74304\n",
      "epoch: 77, loss: -0.73877\n",
      "epoch: 78, loss: -0.75069\n",
      "epoch: 79, loss: -0.76712\n",
      "epoch: 80, loss: -0.74699\n",
      "epoch: 81, loss: -0.75884\n",
      "epoch: 82, loss: -0.78034\n",
      "epoch: 83, loss: -0.78562\n",
      "epoch: 84, loss: -0.77459\n",
      "epoch: 85, loss: -0.75464\n",
      "epoch: 86, loss: -0.76420\n",
      "epoch: 87, loss: -0.78631\n",
      "epoch: 88, loss: -0.78305\n",
      "epoch: 89, loss: -0.77686\n",
      "epoch: 90, loss: -0.76390\n",
      "epoch: 91, loss: -0.74754\n",
      "epoch: 92, loss: -0.76230\n",
      "epoch: 93, loss: -0.76799\n",
      "epoch: 94, loss: -0.77781\n",
      "epoch: 95, loss: -0.77495\n",
      "epoch: 96, loss: -0.77131\n",
      "epoch: 97, loss: -0.76898\n",
      "epoch: 98, loss: -0.75998\n",
      "epoch: 99, loss: -0.78437\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 16/1000 [46:20<46:23:35, 169.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "16 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0017.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0017\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.57678\n",
      "epoch: 01, loss: -0.72146\n",
      "epoch: 02, loss: -0.74111\n",
      "epoch: 03, loss: -0.74854\n",
      "epoch: 04, loss: -0.75460\n",
      "epoch: 05, loss: -0.75215\n",
      "epoch: 06, loss: -0.75921\n",
      "epoch: 07, loss: -0.76627\n",
      "epoch: 08, loss: -0.75967\n",
      "epoch: 09, loss: -0.77267\n",
      "epoch: 10, loss: -0.76905\n",
      "epoch: 11, loss: -0.75978\n",
      "epoch: 12, loss: -0.76666\n",
      "epoch: 13, loss: -0.77466\n",
      "epoch: 14, loss: -0.77287\n",
      "epoch: 15, loss: -0.77258\n",
      "epoch: 16, loss: -0.77761\n",
      "epoch: 17, loss: -0.79621\n",
      "epoch: 18, loss: -0.79523\n",
      "epoch: 19, loss: -0.77066\n",
      "epoch: 20, loss: -0.77353\n",
      "epoch: 21, loss: -0.76977\n",
      "epoch: 22, loss: -0.77109\n",
      "epoch: 23, loss: -0.77657\n",
      "epoch: 24, loss: -0.78383\n",
      "epoch: 25, loss: -0.79252\n",
      "epoch: 26, loss: -0.80148\n",
      "epoch: 27, loss: -0.79534\n",
      "epoch: 28, loss: -0.79791\n",
      "epoch: 29, loss: -0.78990\n",
      "epoch: 30, loss: -0.78078\n",
      "epoch: 31, loss: -0.78444\n",
      "epoch: 32, loss: -0.79063\n",
      "epoch: 33, loss: -0.80025\n",
      "epoch: 34, loss: -0.80473\n",
      "epoch: 35, loss: -0.80693\n",
      "epoch: 36, loss: -0.79983\n",
      "epoch: 37, loss: -0.78686\n",
      "epoch: 38, loss: -0.77439\n",
      "epoch: 39, loss: -0.77973\n",
      "epoch: 40, loss: -0.77758\n",
      "epoch: 41, loss: -0.78033\n",
      "epoch: 42, loss: -0.77190\n",
      "epoch: 43, loss: -0.76370\n",
      "epoch: 44, loss: -0.76273\n",
      "epoch: 45, loss: -0.76937\n",
      "epoch: 46, loss: -0.76616\n",
      "epoch: 47, loss: -0.76877\n",
      "epoch: 48, loss: -0.76533\n",
      "epoch: 49, loss: -0.76821\n",
      "epoch: 50, loss: -0.77149\n",
      "epoch: 51, loss: -0.77451\n",
      "epoch: 52, loss: -0.75943\n",
      "epoch: 53, loss: -0.76787\n",
      "epoch: 54, loss: -0.76786\n",
      "epoch: 55, loss: -0.75572\n",
      "epoch: 56, loss: -0.76058\n",
      "epoch: 57, loss: -0.77333\n",
      "epoch: 58, loss: -0.77982\n",
      "epoch: 59, loss: -0.78230\n",
      "epoch: 60, loss: -0.79070\n",
      "epoch: 61, loss: -0.80258\n",
      "epoch: 62, loss: -0.81405\n",
      "epoch: 63, loss: -0.81607\n",
      "epoch: 64, loss: -0.80643\n",
      "epoch: 65, loss: -0.80451\n",
      "epoch: 66, loss: -0.80477\n",
      "epoch: 67, loss: -0.81454\n",
      "epoch: 68, loss: -0.82571\n",
      "epoch: 69, loss: -0.82884\n",
      "epoch: 70, loss: -0.83136\n",
      "epoch: 71, loss: -0.82022\n",
      "epoch: 72, loss: -0.79449\n",
      "epoch: 73, loss: -0.78969\n",
      "epoch: 74, loss: -0.78810\n",
      "epoch: 75, loss: -0.79002\n",
      "epoch: 76, loss: -0.79485\n",
      "epoch: 77, loss: -0.80603\n",
      "epoch: 78, loss: -0.79948\n",
      "epoch: 79, loss: -0.80467\n",
      "epoch: 80, loss: -0.81774\n",
      "epoch: 81, loss: -0.82343\n",
      "epoch: 82, loss: -0.83613\n",
      "epoch: 83, loss: -0.82964\n",
      "epoch: 84, loss: -0.82374\n",
      "epoch: 85, loss: -0.82950\n",
      "epoch: 86, loss: -0.83783\n",
      "epoch: 87, loss: -0.83521\n",
      "epoch: 88, loss: -0.83805\n",
      "epoch: 89, loss: -0.83961\n",
      "epoch: 90, loss: -0.83055\n",
      "epoch: 91, loss: -0.84355\n",
      "epoch: 92, loss: -0.84874\n",
      "epoch: 93, loss: -0.86553\n",
      "epoch: 94, loss: -0.87329\n",
      "epoch: 95, loss: -0.86732\n",
      "epoch: 96, loss: -0.86915\n",
      "epoch: 97, loss: -0.86671\n",
      "epoch: 98, loss: -0.85821\n",
      "epoch: 99, loss: -0.85281\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 17/1000 [49:09<46:18:48, 169.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "17 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0018.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0018\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.57205\n",
      "epoch: 01, loss: -0.76407\n",
      "epoch: 02, loss: -0.79693\n",
      "epoch: 03, loss: -0.79483\n",
      "epoch: 04, loss: -0.81237\n",
      "epoch: 05, loss: -0.82240\n",
      "epoch: 06, loss: -0.83369\n",
      "epoch: 07, loss: -0.83549\n",
      "epoch: 08, loss: -0.82973\n",
      "epoch: 09, loss: -0.83194\n",
      "epoch: 10, loss: -0.83357\n",
      "epoch: 11, loss: -0.83923\n",
      "epoch: 12, loss: -0.84748\n",
      "epoch: 13, loss: -0.85103\n",
      "epoch: 14, loss: -0.85183\n",
      "epoch: 15, loss: -0.85543\n",
      "epoch: 16, loss: -0.86393\n",
      "epoch: 17, loss: -0.86266\n",
      "epoch: 18, loss: -0.86375\n",
      "epoch: 19, loss: -0.85469\n",
      "epoch: 20, loss: -0.85567\n",
      "epoch: 21, loss: -0.85906\n",
      "epoch: 22, loss: -0.86617\n",
      "epoch: 23, loss: -0.86758\n",
      "epoch: 24, loss: -0.86750\n",
      "epoch: 25, loss: -0.87406\n",
      "epoch: 26, loss: -0.88201\n",
      "epoch: 27, loss: -0.88219\n",
      "epoch: 28, loss: -0.88306\n",
      "epoch: 29, loss: -0.88871\n",
      "epoch: 30, loss: -0.88990\n",
      "epoch: 31, loss: -0.89307\n",
      "epoch: 32, loss: -0.88716\n",
      "epoch: 33, loss: -0.89440\n",
      "epoch: 34, loss: -0.89297\n",
      "epoch: 35, loss: -0.89646\n",
      "epoch: 36, loss: -0.89921\n",
      "epoch: 37, loss: -0.90107\n",
      "epoch: 38, loss: -0.90200\n",
      "epoch: 39, loss: -0.90608\n",
      "epoch: 40, loss: -0.90951\n",
      "epoch: 41, loss: -0.91293\n",
      "epoch: 42, loss: -0.91582\n",
      "epoch: 43, loss: -0.91389\n",
      "epoch: 44, loss: -0.91523\n",
      "epoch: 45, loss: -0.91739\n",
      "epoch: 46, loss: -0.91490\n",
      "epoch: 47, loss: -0.91259\n",
      "epoch: 48, loss: -0.91166\n",
      "epoch: 49, loss: -0.91142\n",
      "epoch: 50, loss: -0.91516\n",
      "epoch: 51, loss: -0.91179\n",
      "epoch: 52, loss: -0.91247\n",
      "epoch: 53, loss: -0.91307\n",
      "epoch: 54, loss: -0.91431\n",
      "epoch: 55, loss: -0.91350\n",
      "epoch: 56, loss: -0.91152\n",
      "epoch: 57, loss: -0.90937\n",
      "epoch: 58, loss: -0.91360\n",
      "epoch: 59, loss: -0.91002\n",
      "epoch: 60, loss: -0.91031\n",
      "epoch: 61, loss: -0.91436\n",
      "epoch: 62, loss: -0.91084\n",
      "epoch: 63, loss: -0.91107\n",
      "epoch: 64, loss: -0.91714\n",
      "epoch: 65, loss: -0.92234\n",
      "epoch: 66, loss: -0.92510\n",
      "epoch: 67, loss: -0.93099\n",
      "epoch: 68, loss: -0.93210\n",
      "epoch: 69, loss: -0.93363\n",
      "epoch: 70, loss: -0.93423\n",
      "epoch: 71, loss: -0.93170\n",
      "epoch: 72, loss: -0.93185\n",
      "epoch: 73, loss: -0.93452\n",
      "epoch: 74, loss: -0.93622\n",
      "epoch: 75, loss: -0.93549\n",
      "epoch: 76, loss: -0.93988\n",
      "epoch: 77, loss: -0.94403\n",
      "epoch: 78, loss: -0.94159\n",
      "epoch: 79, loss: -0.94362\n",
      "epoch: 80, loss: -0.94052\n",
      "epoch: 81, loss: -0.93786\n",
      "epoch: 82, loss: -0.94104\n",
      "epoch: 83, loss: -0.93628\n",
      "epoch: 84, loss: -0.93683\n",
      "epoch: 85, loss: -0.93126\n",
      "epoch: 86, loss: -0.93367\n",
      "epoch: 87, loss: -0.93762\n",
      "epoch: 88, loss: -0.94255\n",
      "epoch: 89, loss: -0.94313\n",
      "epoch: 90, loss: -0.94317\n",
      "epoch: 91, loss: -0.94485\n",
      "epoch: 92, loss: -0.94164\n",
      "epoch: 93, loss: -0.94247\n",
      "epoch: 94, loss: -0.93923\n",
      "epoch: 95, loss: -0.93844\n",
      "epoch: 96, loss: -0.94269\n",
      "epoch: 97, loss: -0.94645\n",
      "epoch: 98, loss: -0.94516\n",
      "epoch: 99, loss: -0.94652\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 18/1000 [51:58<46:14:42, 169.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "18 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0019.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0019\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.53142\n",
      "epoch: 01, loss: -0.68149\n",
      "epoch: 02, loss: -0.70203\n",
      "epoch: 03, loss: -0.71287\n",
      "epoch: 04, loss: -0.71613\n",
      "epoch: 05, loss: -0.72259\n",
      "epoch: 06, loss: -0.72630\n",
      "epoch: 07, loss: -0.73154\n",
      "epoch: 08, loss: -0.74696\n",
      "epoch: 09, loss: -0.75974\n",
      "epoch: 10, loss: -0.76634\n",
      "epoch: 11, loss: -0.77020\n",
      "epoch: 12, loss: -0.78467\n",
      "epoch: 13, loss: -0.79073\n",
      "epoch: 14, loss: -0.79101\n",
      "epoch: 15, loss: -0.78744\n",
      "epoch: 16, loss: -0.80295\n",
      "epoch: 17, loss: -0.80217\n",
      "epoch: 18, loss: -0.80438\n",
      "epoch: 19, loss: -0.80390\n",
      "epoch: 20, loss: -0.80923\n",
      "epoch: 21, loss: -0.80182\n",
      "epoch: 22, loss: -0.79815\n",
      "epoch: 23, loss: -0.80577\n",
      "epoch: 24, loss: -0.80479\n",
      "epoch: 25, loss: -0.80966\n",
      "epoch: 26, loss: -0.80564\n",
      "epoch: 27, loss: -0.80339\n",
      "epoch: 28, loss: -0.80267\n",
      "epoch: 29, loss: -0.80200\n",
      "epoch: 30, loss: -0.80400\n",
      "epoch: 31, loss: -0.81293\n",
      "epoch: 32, loss: -0.81200\n",
      "epoch: 33, loss: -0.80759\n",
      "epoch: 34, loss: -0.80950\n",
      "epoch: 35, loss: -0.80806\n",
      "epoch: 36, loss: -0.80826\n",
      "epoch: 37, loss: -0.80656\n",
      "epoch: 38, loss: -0.81189\n",
      "epoch: 39, loss: -0.80583\n",
      "epoch: 40, loss: -0.80589\n",
      "epoch: 41, loss: -0.80623\n",
      "epoch: 42, loss: -0.79426\n",
      "epoch: 43, loss: -0.79795\n",
      "epoch: 44, loss: -0.79848\n",
      "epoch: 45, loss: -0.80495\n",
      "epoch: 46, loss: -0.80362\n",
      "epoch: 47, loss: -0.79193\n",
      "epoch: 48, loss: -0.78043\n",
      "epoch: 49, loss: -0.79276\n",
      "epoch: 50, loss: -0.77885\n",
      "epoch: 51, loss: -0.78281\n",
      "epoch: 52, loss: -0.78237\n",
      "epoch: 53, loss: -0.79251\n",
      "epoch: 54, loss: -0.78339\n",
      "epoch: 55, loss: -0.78576\n",
      "epoch: 56, loss: -0.79256\n",
      "epoch: 57, loss: -0.78575\n",
      "epoch: 58, loss: -0.77345\n",
      "epoch: 59, loss: -0.77524\n",
      "epoch: 60, loss: -0.77666\n",
      "epoch: 61, loss: -0.76278\n",
      "epoch: 62, loss: -0.77493\n",
      "epoch: 63, loss: -0.78836\n",
      "epoch: 64, loss: -0.78613\n",
      "epoch: 65, loss: -0.78643\n",
      "epoch: 66, loss: -0.76927\n",
      "epoch: 67, loss: -0.75543\n",
      "epoch: 68, loss: -0.72416\n",
      "epoch: 69, loss: -0.74368\n",
      "epoch: 70, loss: -0.75706\n",
      "epoch: 71, loss: -0.76901\n",
      "epoch: 72, loss: -0.77586\n",
      "epoch: 73, loss: -0.78740\n",
      "epoch: 74, loss: -0.78135\n",
      "epoch: 75, loss: -0.78284\n",
      "epoch: 76, loss: -0.78202\n",
      "epoch: 77, loss: -0.79707\n",
      "epoch: 78, loss: -0.80962\n",
      "epoch: 79, loss: -0.81553\n",
      "epoch: 80, loss: -0.82537\n",
      "epoch: 81, loss: -0.83641\n",
      "epoch: 82, loss: -0.84108\n",
      "epoch: 83, loss: -0.84428\n",
      "epoch: 84, loss: -0.85127\n",
      "epoch: 85, loss: -0.85153\n",
      "epoch: 86, loss: -0.85235\n",
      "epoch: 87, loss: -0.84197\n",
      "epoch: 88, loss: -0.84763\n",
      "epoch: 89, loss: -0.84908\n",
      "epoch: 90, loss: -0.85017\n",
      "epoch: 91, loss: -0.85119\n",
      "epoch: 92, loss: -0.86216\n",
      "epoch: 93, loss: -0.85909\n",
      "epoch: 94, loss: -0.86862\n",
      "epoch: 95, loss: -0.86163\n",
      "epoch: 96, loss: -0.86365\n",
      "epoch: 97, loss: -0.86302\n",
      "epoch: 98, loss: -0.86398\n",
      "epoch: 99, loss: -0.86723\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 19/1000 [54:50<46:21:52, 170.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "19 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0020.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0020\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.49862\n",
      "epoch: 01, loss: -0.64388\n",
      "epoch: 02, loss: -0.67072\n",
      "epoch: 03, loss: -0.66998\n",
      "epoch: 04, loss: -0.67896\n",
      "epoch: 05, loss: -0.68433\n",
      "epoch: 06, loss: -0.68666\n",
      "epoch: 07, loss: -0.69020\n",
      "epoch: 08, loss: -0.69436\n",
      "epoch: 09, loss: -0.68861\n",
      "epoch: 10, loss: -0.70485\n",
      "epoch: 11, loss: -0.70803\n",
      "epoch: 12, loss: -0.71434\n",
      "epoch: 13, loss: -0.70674\n",
      "epoch: 14, loss: -0.68898\n",
      "epoch: 15, loss: -0.70016\n",
      "epoch: 16, loss: -0.71696\n",
      "epoch: 17, loss: -0.71284\n",
      "epoch: 18, loss: -0.71697\n",
      "epoch: 19, loss: -0.70707\n",
      "epoch: 20, loss: -0.70891\n",
      "epoch: 21, loss: -0.71583\n",
      "epoch: 22, loss: -0.72766\n",
      "epoch: 23, loss: -0.74200\n",
      "epoch: 24, loss: -0.75128\n",
      "epoch: 25, loss: -0.77688\n",
      "epoch: 26, loss: -0.77066\n",
      "epoch: 27, loss: -0.77744\n",
      "epoch: 28, loss: -0.77202\n",
      "epoch: 29, loss: -0.78691\n",
      "epoch: 30, loss: -0.79505\n",
      "epoch: 31, loss: -0.79454\n",
      "epoch: 32, loss: -0.79092\n",
      "epoch: 33, loss: -0.79397\n",
      "epoch: 34, loss: -0.79340\n",
      "epoch: 35, loss: -0.78420\n",
      "epoch: 36, loss: -0.77215\n",
      "epoch: 37, loss: -0.76787\n",
      "epoch: 38, loss: -0.78326\n",
      "epoch: 39, loss: -0.77804\n",
      "epoch: 40, loss: -0.78544\n",
      "epoch: 41, loss: -0.78148\n",
      "epoch: 42, loss: -0.77985\n",
      "epoch: 43, loss: -0.77520\n",
      "epoch: 44, loss: -0.77079\n",
      "epoch: 45, loss: -0.76885\n",
      "epoch: 46, loss: -0.75880\n",
      "epoch: 47, loss: -0.76138\n",
      "epoch: 48, loss: -0.75715\n",
      "epoch: 49, loss: -0.76501\n",
      "epoch: 50, loss: -0.77597\n",
      "epoch: 51, loss: -0.77835\n",
      "epoch: 52, loss: -0.77143\n",
      "epoch: 53, loss: -0.78446\n",
      "epoch: 54, loss: -0.77290\n",
      "epoch: 55, loss: -0.78368\n",
      "epoch: 56, loss: -0.77825\n",
      "epoch: 57, loss: -0.76916\n",
      "epoch: 58, loss: -0.76934\n",
      "epoch: 59, loss: -0.75708\n",
      "epoch: 60, loss: -0.77144\n",
      "epoch: 61, loss: -0.77384\n",
      "epoch: 62, loss: -0.77126\n",
      "epoch: 63, loss: -0.77837\n",
      "epoch: 64, loss: -0.77377\n",
      "epoch: 65, loss: -0.76552\n",
      "epoch: 66, loss: -0.76417\n",
      "epoch: 67, loss: -0.77125\n",
      "epoch: 68, loss: -0.78574\n",
      "epoch: 69, loss: -0.77667\n",
      "epoch: 70, loss: -0.77036\n",
      "epoch: 71, loss: -0.75712\n",
      "epoch: 72, loss: -0.76269\n",
      "epoch: 73, loss: -0.76054\n",
      "epoch: 74, loss: -0.74546\n",
      "epoch: 75, loss: -0.75665\n",
      "epoch: 76, loss: -0.76016\n",
      "epoch: 77, loss: -0.75024\n",
      "epoch: 78, loss: -0.75228\n",
      "epoch: 79, loss: -0.76697\n",
      "epoch: 80, loss: -0.76384\n",
      "epoch: 81, loss: -0.76910\n",
      "epoch: 82, loss: -0.76654\n",
      "epoch: 83, loss: -0.76131\n",
      "epoch: 84, loss: -0.76189\n",
      "epoch: 85, loss: -0.72565\n",
      "epoch: 86, loss: -0.71039\n",
      "epoch: 87, loss: -0.71295\n",
      "epoch: 88, loss: -0.70331\n",
      "epoch: 89, loss: -0.71182\n",
      "epoch: 90, loss: -0.70498\n",
      "epoch: 91, loss: -0.70870\n",
      "epoch: 92, loss: -0.68981\n",
      "epoch: 93, loss: -0.69058\n",
      "epoch: 94, loss: -0.69244\n",
      "epoch: 95, loss: -0.71005\n",
      "epoch: 96, loss: -0.72724\n",
      "epoch: 97, loss: -0.72136\n",
      "epoch: 98, loss: -0.73460\n",
      "epoch: 99, loss: -0.73223\n",
      "After Unsqueezing, feature size= torch.Size([400, 1, 1, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 20/1000 [57:37<46:05:44, 169.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "20 /home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16/0021.pth\n",
      "dict_keys(['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape'])\n",
      "0021\n",
      "Starting Training\n",
      "epoch: 00, loss: -0.53701\n",
      "epoch: 01, loss: -0.68998\n",
      "epoch: 02, loss: -0.71440\n",
      "epoch: 03, loss: -0.73850\n",
      "epoch: 04, loss: -0.73495\n",
      "epoch: 05, loss: -0.73167\n",
      "epoch: 06, loss: -0.73512\n",
      "epoch: 07, loss: -0.74253\n",
      "epoch: 08, loss: -0.75544\n",
      "epoch: 09, loss: -0.76161\n",
      "epoch: 10, loss: -0.76046\n",
      "epoch: 11, loss: -0.76540\n",
      "epoch: 12, loss: -0.77553\n",
      "epoch: 13, loss: -0.77703\n",
      "epoch: 14, loss: -0.78016\n",
      "epoch: 15, loss: -0.79286\n",
      "epoch: 16, loss: -0.79823\n",
      "epoch: 17, loss: -0.80072\n",
      "epoch: 18, loss: -0.78380\n",
      "epoch: 19, loss: -0.78596\n",
      "epoch: 20, loss: -0.77947\n",
      "epoch: 21, loss: -0.78181\n",
      "epoch: 22, loss: -0.78196\n",
      "epoch: 23, loss: -0.76536\n",
      "epoch: 24, loss: -0.75433\n",
      "epoch: 25, loss: -0.76282\n",
      "epoch: 26, loss: -0.78407\n",
      "epoch: 27, loss: -0.79307\n",
      "epoch: 28, loss: -0.80250\n",
      "epoch: 29, loss: -0.80475\n",
      "epoch: 30, loss: -0.80633\n",
      "epoch: 31, loss: -0.79946\n",
      "epoch: 32, loss: -0.79194\n",
      "epoch: 33, loss: -0.78718\n",
      "epoch: 34, loss: -0.79179\n",
      "epoch: 35, loss: -0.78704\n",
      "epoch: 36, loss: -0.77964\n",
      "epoch: 37, loss: -0.78592\n",
      "epoch: 38, loss: -0.79298\n",
      "epoch: 39, loss: -0.79621\n",
      "epoch: 40, loss: -0.79656\n",
      "epoch: 41, loss: -0.81395\n",
      "epoch: 42, loss: -0.80536\n",
      "epoch: 43, loss: -0.80972\n",
      "epoch: 44, loss: -0.82234\n",
      "epoch: 45, loss: -0.84090\n",
      "epoch: 46, loss: -0.84315\n",
      "epoch: 47, loss: -0.83900\n",
      "epoch: 48, loss: -0.83435\n",
      "epoch: 49, loss: -0.80991\n",
      "epoch: 50, loss: -0.79426\n",
      "epoch: 51, loss: -0.79695\n",
      "epoch: 52, loss: -0.79951\n",
      "epoch: 53, loss: -0.81451\n",
      "epoch: 54, loss: -0.80783\n",
      "epoch: 55, loss: -0.81665\n",
      "epoch: 56, loss: -0.81971\n",
      "epoch: 57, loss: -0.82075\n",
      "epoch: 58, loss: -0.82871\n",
      "epoch: 59, loss: -0.82497\n",
      "epoch: 60, loss: -0.82784\n",
      "epoch: 61, loss: -0.83089\n",
      "epoch: 62, loss: -0.83113\n",
      "epoch: 63, loss: -0.83523\n",
      "epoch: 64, loss: -0.83457\n",
      "epoch: 65, loss: -0.83774\n",
      "epoch: 66, loss: -0.80804\n",
      "epoch: 67, loss: -0.81390\n",
      "epoch: 68, loss: -0.78904\n",
      "epoch: 69, loss: -0.77310\n",
      "epoch: 70, loss: -0.77691\n",
      "epoch: 71, loss: -0.78591\n",
      "epoch: 72, loss: -0.78585\n",
      "epoch: 73, loss: -0.79089\n",
      "epoch: 74, loss: -0.77327\n",
      "epoch: 75, loss: -0.77270\n",
      "epoch: 76, loss: -0.78306\n",
      "epoch: 77, loss: -0.79217\n",
      "epoch: 78, loss: -0.78761\n",
      "epoch: 79, loss: -0.79700\n",
      "epoch: 80, loss: -0.78676\n"
     ]
    }
   ],
   "source": [
    "utils.make_output_dir(output_dir)\n",
    "feat_list=[]\n",
    "inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "for inp in tqdm(inputs):\n",
    "    index, features_file = inp\n",
    "    print(index, features_file)\n",
    "     # Load\n",
    "    data_dict = torch.load(features_file, map_location='cpu')\n",
    "    print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "    # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "    image_id = data_dict['file'][:-4]\n",
    "    print(image_id)\n",
    "    # Load\n",
    "    output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "    if Path(output_file).is_file():\n",
    "        print(f'Skipping existing file {str(output_file)}')\n",
    "        # break\n",
    "        # return  # skip because already generated\n",
    "\n",
    "    # Load affinity matrix\n",
    "    feats = data_dict[which_features].squeeze().cuda()\n",
    "    # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "    if normalize:\n",
    "        feats = F.normalize(feats, p=2, dim=-1)\n",
    "    # print(\"After normalization, Features Shape\",feats.shape)\n",
    "    # print(\"which_matrix=\", which_matrix)\n",
    "    # Eigenvectors of affinity matrix\n",
    "    if which_matrix == 'affinity_torch':\n",
    "        W = feats @ feats.T\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "            # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = torch.eig(W, eigenvectors=True)\n",
    "        eigenvalues = eigenvalues.cpu()\n",
    "        eigenvectors = eigenvectors.cpu()\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity_svd':\n",
    "        USV = torch.linalg.svd(feats, full_matrices=False)\n",
    "        eigenvectors = USV[0][:, :K].T.to('cpu', non_blocking=True)\n",
    "        eigenvalues = USV[1][:K].to('cpu', non_blocking=True)\n",
    "        print(\"which matrix=\",which_matrix,\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity':\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "        W = (feats @ feats.T)\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "        W = W.cpu().numpy()\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = eigsh(W, which='LM', k=K)\n",
    "        eigenvectors = torch.flip(torch.from_numpy(eigenvectors), dims=(-1,)).T\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of matting laplacian matrix\n",
    "    elif which_matrix in ['matting_laplacian', 'laplacian']:\n",
    "\n",
    "        # Get sizes\n",
    "        B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "        if image_downsample_factor is None:\n",
    "            image_downsample_factor = P\n",
    "        H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "        # Upscale features to match the resolution\n",
    "        if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "            feats = F.interpolate(\n",
    "                feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "                size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "            ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "        ### Feature affinities\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "\n",
    "        W_feat_ds = (feats @ feats.T)\n",
    "        # feat_list.append(feats)\n",
    "        feat_dataset = Feature_Dataset(feats)\n",
    "        if feats.shape[0]%2==0:\n",
    "            features_dataloader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True)\n",
    "        else:\n",
    "            features_dataloader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        model_simsiam = SimSiam()\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model_simsiam.to(device)\n",
    "        criterion = NegativeCosineSimilarity()\n",
    "        optimizer = torch.optim.SGD(model_simsiam.parameters(), lr=0.06)\n",
    "        print(\"Starting Training\")\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x0 in features_dataloader:\n",
    "            # for (x0), _, _ in features_dataloader:\n",
    "            #     print(\"Before Unsqueezing, x0 shape=\", x0.shape)\n",
    "                x0 = x0.unsqueeze(0).to(device)\n",
    "                x0 = x0.unsqueeze(1).to(device)\n",
    "                # print(\"After Unsqueezing x0 shape=\", x0.shape)\n",
    "                x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "                # print(\"After Unsqueezing x1 shape=\", x1.shape)\n",
    "                # x0 = x0.squeeze(0).to(device)\n",
    "                # print(\"batch_size=\",batch_size)\n",
    "                # x0_new = torch.tensor(x0).view(batch_size, 1, 1, 384)\n",
    "                # x0_new = torch.tensor(x0).view(batch_size, 1, 384)\n",
    "                x0_new = x0.view(batch_size, 1, 1, 384)\n",
    "                # print(\"After viewing x0 shape=\", x0_new.shape)\n",
    "                # print(\"x0.shape=\", x0.shape)\n",
    "                # x1 = x1.squeeze(0).to(device)\n",
    "                # x1 = torch.tensor(x1).view(batch_size, 1, 1,384)\n",
    "                x1_new = x1.view(batch_size, 1, 1, 384)\n",
    "                # print(\"After viewing x1 shape=\", x1_new.shape)\n",
    "                z0, p0 = model_simsiam(x0_new)\n",
    "                z1, p1 = model_simsiam(x1_new)\n",
    "                loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "                total_loss += loss.detach()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            avg_loss = total_loss / len(features_dataloader)\n",
    "            print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "        feats=feats.unsqueeze(1).to(device)\n",
    "        feats=feats.unsqueeze(2).to(device)\n",
    "        print(\"After Unsqueezing, feature size=\", feats.shape)\n",
    "        projected_feature=model_simsiam(feats)\n",
    "        W_feat_siam=torch.matmul(projected_feature[0], projected_feature[0].t())\n",
    "        W_feat=W_feat_ds + 0.1*W_feat_siam\n",
    "        # print(\"W_feat.shape=\", W_feat.shape)\n",
    "        # print(\"W_feat.shape=\", W_feat.shape)\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        if threshold_at_zero:\n",
    "            W_feat = (W_feat * (W_feat > 0))\n",
    "        W_feat = W_feat / W_feat.max()  # NOTE: If features are normalized, this naturally does nothing\n",
    "        # W_feat = W_feat.cpu().numpy()\n",
    "        W_feat = W_feat.detach().cpu().numpy()\n",
    "        # print(\"W_feat shape=\",W_feat.shape)\n",
    "\n",
    "        ### Color affinities\n",
    "        # If we are fusing with color affinites, then load the image and compute\n",
    "        if image_color_lambda > 0:\n",
    "\n",
    "            # Load image\n",
    "            image_file = str(Path(images_root) / f'{image_id}.jpg')\n",
    "            image_lr = Image.open(image_file).resize((W_pad_lr, H_pad_lr), Image.BILINEAR)\n",
    "            image_lr = np.array(image_lr) / 255.\n",
    "\n",
    "            # Color affinities (of type scipy.sparse.csr_matrix)\n",
    "            if which_color_matrix == 'knn':\n",
    "                W_lr = utils.knn_affinity(image_lr / 255)\n",
    "            elif which_color_matrix == 'rw':\n",
    "                W_lr = utils.rw_affinity(image_lr / 255)\n",
    "\n",
    "            # Convert to dense numpy array\n",
    "            W_color = np.array(W_lr.todense().astype(np.float32))\n",
    "            # print(\"W_color shape\", W_color.shape)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # No color affinity\n",
    "            W_color = 0\n",
    "\n",
    "        # Combine\n",
    "        W_comb = W_feat + W_color * image_color_lambda  # combination\n",
    "        D_comb = np.array(utils.get_diagonal(W_comb).todense())  # is dense or sparse faster? not sure, should check\n",
    "        # print(\"W_comb shape= \", W_comb.shape, \"D_comb shape\",  D_comb.shape)\n",
    "        if lapnorm:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM', M=D_comb)\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM', M=D_comb)\n",
    "        else:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM')\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM')\n",
    "        eigenvalues, eigenvectors = torch.from_numpy(eigenvalues), torch.from_numpy(eigenvectors.T).float()\n",
    "    print(\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "    # Sign ambiguity\n",
    "    for k in range(eigenvectors.shape[0]):\n",
    "        if 0.5 < torch.mean((eigenvectors[k] > 0).float()).item() < 1.0:  # reverse segment\n",
    "            eigenvectors[k] = 0 - eigenvectors[k]\n",
    "\n",
    "    # Save dict\n",
    "    output_dict = {'eigenvalues': eigenvalues, 'eigenvectors': eigenvectors}\n",
    "    torch.save(output_dict, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}