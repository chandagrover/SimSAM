{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "from pathlib import Path\n",
    "# from typing import Optional, Tuple\n",
    "# import cv2\n",
    "# import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from PIL import Image\n",
    "from scipy.sparse.linalg import eigsh\n",
    "# from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "# from torchvision.utils import draw_bounding_boxes\n",
    "from tqdm import tqdm\n",
    "import extract_utils as utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import datetime, dateutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract Eigen Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_root=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/images\"\n",
    "features_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16\"\n",
    "output_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/eigs_dot1PCApred_ds_model_10_jn\"\n",
    "which_matrix= 'laplacian'\n",
    "which_color_matrix= 'knn'\n",
    "which_features= 'k'\n",
    "normalize=True\n",
    "threshold_at_zero=True\n",
    "lapnorm= True\n",
    "K= 5\n",
    "image_downsample_factor = None\n",
    "image_color_lambda = 0.0\n",
    "multiprocessing = 0\n",
    "batch_size=2\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ResNet Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=128, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(128, out_channels * self.expansion, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels * self.expansion)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        # print(\"Before squeezing, out shape=\", out.shape)\n",
    "        out =  out.squeeze().to('cuda')\n",
    "        # print(\"After squeezing, out shape=\", out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Incorporating SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class Feature_Dataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, train=True):\n",
    "        super().__init__()\n",
    "        # self.projection_head = SimSiamProjectionHead(feats.shape[1], 128,feats.shape[1])\n",
    "        self.train=train\n",
    "        self.projection_head = BasicBlock()\n",
    "        # self.projection_head = ResidualBlock(feats.shape[1], feats.shape[1])\n",
    "        # self.prediction_head = SimSiamPredictionHead(feats.shape[1], 128, feats.shape[1])\n",
    "        self.prediction_head = BasicBlock()\n",
    "\n",
    "    def forward(self, x,train=True):\n",
    "        z = self.projection_head(x)\n",
    "        # print(\"z.shape\", z.shape)\n",
    "        z_new=z.view(feats.shape[0],1 , 384)\n",
    "        # if train:\n",
    "        #     z_new = z.view(2, 1, 384)\n",
    "        # else:\n",
    "        #     z_new=z.view(feats.shape[0],1 , 384)\n",
    "            # print(z_new.shape)\n",
    "        p = self.prediction_head(z_new)\n",
    "        z_new.detach()\n",
    "        # if train:\n",
    "        #     z_new = z.view(2, 1, 384)\n",
    "        #     # print(z_new.shape)\n",
    "        #     p = self.prediction_head(z_new)\n",
    "        #     z_new.detach()\n",
    "        # else:\n",
    "        #     p = self.prediction_head(z)\n",
    "        # z = z.detach()\n",
    "        return z_new, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# utils.make_output_dir(output_dir)\n",
    "# inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "# model_simsiam = SimSiam()\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model_simsiam.to(device)\n",
    "# criterion = NegativeCosineSimilarity()\n",
    "# optimizer = torch.optim.SGD(model_simsiam.parameters(), lr=0.06)\n",
    "# for inp in tqdm(inputs):\n",
    "#     index, features_file = inp\n",
    "#     print(index, features_file)\n",
    "#      # Load\n",
    "#     data_dict = torch.load(features_file, map_location='cpu')\n",
    "#     # print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "#     # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "#     image_id = data_dict['file'][:-4]\n",
    "#     print(image_id)\n",
    "#     # Load\n",
    "#     output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "#     if Path(output_file).is_file():\n",
    "#         print(f'Skipping existing file {str(output_file)}')\n",
    "#         # break\n",
    "#         # return  # skip because already generated\n",
    "#\n",
    "#     # Load affinity matrix\n",
    "#     feats = data_dict[which_features].squeeze().cuda()\n",
    "#     # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "#     if normalize:\n",
    "#         feats = F.normalize(feats, p=2, dim=-1)\n",
    "#\n",
    "#      # Get sizes\n",
    "#         B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "#         if image_downsample_factor is None:\n",
    "#             image_downsample_factor = P\n",
    "#         H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "#\n",
    "#         # Upscale features to match the resolution\n",
    "#         if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "#             feats = F.interpolate(\n",
    "#                 feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "#                 size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "#             ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "#\n",
    "#         ### Feature affinities\n",
    "#         # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "#\n",
    "#         W_feat_ds = (feats @ feats.T)\n",
    "#         # feat_list.append(feats)\n",
    "#         # feat_dataset = Feature_Dataset(feats)\n",
    "#         # if feats.shape[0]%2==0:\n",
    "#         #     features_dataloader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True)\n",
    "#         # else:\n",
    "#         #     features_dataloader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "#         print(\"Starting Training\")\n",
    "#         x0=feats\n",
    "#         x0 = x0.unsqueeze(0).to(device)\n",
    "#         # x0 = x0.unsqueeze(1).to(device)\n",
    "#         print(\"After Unsqueezing x0 shape=\", x0.shape)\n",
    "#         # print(\"x0 shape=\", x0.shape)\n",
    "#         x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "#         print(\"After Unsqueezing x1 shape=\", x1.shape)\n",
    "#          # x0 = x0.squeeze(0).to(device)\n",
    "#         # print(\"batch_size=\",batch_size)\n",
    "#         # x0_new = torch.tensor(x0).view(batch_size, 1, 1, 384)\n",
    "#         # x0_new = torch.tensor(x0).view(batch_size, 1, 384)\n",
    "#         x0_new = x0.view(feats.shape[0], 1, 384)\n",
    "#         # print(\"After viewing x0 shape=\", x0_new.shape)\n",
    "#         # print(\"x0.shape=\", x0.shape)\n",
    "#         # x1 = x1.squeeze(0).to(device)\n",
    "#         # x1 = torch.tensor(x1).view(batch_size, 1, 1,384)\n",
    "#         x1_new = x1.view(feats.shape[0], 1, 384)\n",
    "#         # print(\"After viewing x1 shape=\", x1_new.shape)\n",
    "#         for epoch in range(epochs):\n",
    "#             total_loss = 0\n",
    "#             z0, p0 = model_simsiam(x0_new, True)\n",
    "#             # print(\"zo.shape\", z0.shape)\n",
    "#             # print(\"p0.shape\", p0.shape)\n",
    "#             z1, p1 = model_simsiam(x1_new, True)\n",
    "#             loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "#             total_loss += loss.detach()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#         avg_loss = total_loss / feats.shape[0]\n",
    "#         print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Based Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [02:07<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 00, loss: -0.38912\n",
      "Saved Best Model! in epoch 1\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:52<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 01, loss: -0.39813\n",
      "Saved Best Model! in epoch 2\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:19<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 02, loss: -0.40181\n",
      "Saved Best Model! in epoch 3\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:17<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 03, loss: -0.40442\n",
      "Saved Best Model! in epoch 4\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:34<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 04, loss: -0.40646\n",
      "Saved Best Model! in epoch 5\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:36<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 05, loss: -0.40814\n",
      "Saved Best Model! in epoch 6\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:35<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 06, loss: -0.40956\n",
      "Saved Best Model! in epoch 7\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:36<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 07, loss: -0.41081\n",
      "Saved Best Model! in epoch 8\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:39<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 08, loss: -0.41192\n",
      "Saved Best Model! in epoch 9\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [01:31<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 09, loss: -0.41290\n",
      "Saved Best Model! in epoch 10\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "model_path=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/weights/dot1PCApred_ds_model_10_jn%s.pt\" % (timestamp)\n",
    "utils.make_output_dir(output_dir)\n",
    "inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "model_simsiam = SimSiam()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_simsiam.to(device)\n",
    "criterion = NegativeCosineSimilarity()\n",
    "optimizer = torch.optim.SGD(model_simsiam.parameters(), lr=0.06)\n",
    "\n",
    "print(\"Starting Training\")\n",
    "best_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch+1)\n",
    "    total_loss = 0\n",
    "    for inp in tqdm(inputs):\n",
    "        index, features_file = inp\n",
    "         # Load\n",
    "        data_dict = torch.load(features_file, map_location='cpu')\n",
    "        # image_id = data_dict['file'][:-4]\n",
    "        # Load\n",
    "        feats = data_dict[which_features].squeeze().cuda()\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "        if normalize:\n",
    "            feats = F.normalize(feats, p=2, dim=-1)\n",
    "\n",
    "        # Get sizes\n",
    "        B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "        if image_downsample_factor is None:\n",
    "            image_downsample_factor = P\n",
    "        H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "        # Upscale features to match the resolution\n",
    "        if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "            feats = F.interpolate(\n",
    "                feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "                size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "            ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "        ### Model-Based Optimization\n",
    "        x0=feats\n",
    "        x0 = x0.unsqueeze(0).to(device)\n",
    "        x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "        x0_new = x0.view(feats.shape[0], 1, 384)\n",
    "        x1_new = x1.view(feats.shape[0], 1, 384)\n",
    "        z0, p0 = model_simsiam(x0_new, True)\n",
    "\n",
    "        z1, p1 = model_simsiam(x1_new, True)\n",
    "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    avg_val_loss = total_loss / len(inputs)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_val_loss:.5f}\")\n",
    "    if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model_simsiam.state_dict(), model_path)\n",
    "            print(\"Saved Best Model! in epoch\", epoch+1)\n",
    "    else:\n",
    "        print(\"Weigh not updated in epoch\", epoch+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model_simsiam.state_dict(), model_path)\n",
    "# print(\"Saved Best Model!\")\n",
    "\n",
    "# model_simsiam.load_state_dict(torch.load(model_path, map_location=CFG.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                   | 1/1000 [00:01<26:49,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0002\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                  | 2/1000 [00:02<22:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0003\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                  | 3/1000 [00:03<21:22,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0004\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                  | 4/1000 [00:05<20:11,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0005\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                  | 5/1000 [00:06<18:39,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0006\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                                                  | 6/1000 [00:07<18:07,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0007\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                  | 8/1000 [00:08<13:25,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0008\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0009\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                  | 9/1000 [00:08<10:34,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0010\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:935: LinAlgWarning: Diagonal number 400 is exactly zero. Singular matrix.\n",
      "  self.M_lu = lu_factor(M)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      " ** On entry to SLASCL parameter number  4 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                 | 10/1000 [00:09<09:49,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0011\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                 | 11/1000 [00:09<08:19,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0012\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                 | 12/1000 [00:09<07:04,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0013\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                 | 14/1000 [00:10<05:18,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0014\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0015\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                                                 | 15/1000 [00:10<05:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0016\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0017\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█                                                                 | 17/1000 [00:10<03:40,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0018\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▏                                                                | 18/1000 [00:10<03:46,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0019\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                | 19/1000 [00:11<03:55,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0020\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                | 20/1000 [00:11<04:06,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0021\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                | 22/1000 [00:11<03:45,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0022\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0023\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                | 23/1000 [00:12<03:19,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0024\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                | 25/1000 [00:12<03:24,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0025\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0026\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▋                                                                | 26/1000 [00:12<03:44,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0027\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▊                                                                | 28/1000 [00:13<03:05,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0028\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0029\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▉                                                                | 30/1000 [00:13<02:34,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0030\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0031\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                | 32/1000 [00:13<02:23,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0032\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0033\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                               | 33/1000 [00:13<02:33,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0034\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                               | 34/1000 [00:14<02:49,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0035\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▎                                                               | 35/1000 [00:14<03:20,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0036\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▍                                                               | 36/1000 [00:14<03:43,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0037\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:935: LinAlgWarning: Diagonal number 450 is exactly zero. Singular matrix.\n",
      "  self.M_lu = lu_factor(M)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      " ** On entry to SLASCL parameter number  4 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▌                                                               | 38/1000 [00:15<04:20,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0038\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0039\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▌                                                               | 39/1000 [00:15<03:50,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0040\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▋                                                               | 40/1000 [00:15<03:45,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0041\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▋                                                               | 41/1000 [00:15<03:40,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0042\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▊                                                               | 42/1000 [00:16<03:49,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0043\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▊                                                               | 43/1000 [00:16<03:56,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0044\n",
      "projected feature shape= torch.Size([525, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                               | 44/1000 [00:16<04:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 525])\n",
      "0045\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                               | 45/1000 [00:16<03:57,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0046\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███                                                               | 46/1000 [00:17<04:05,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0047\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0048\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▏                                                              | 48/1000 [00:17<03:12,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0049\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▏                                                              | 49/1000 [00:17<03:17,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0050\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0051\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▎                                                              | 51/1000 [00:18<02:51,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0052\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▍                                                              | 52/1000 [00:18<03:11,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0053\n",
      "projected feature shape= torch.Size([375, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▍                                                              | 53/1000 [00:18<03:13,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 375])\n",
      "0054\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▌                                                              | 54/1000 [00:18<03:27,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0055\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███▋                                                              | 55/1000 [00:19<03:38,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0056\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███▋                                                              | 56/1000 [00:19<03:45,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0057\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███▊                                                              | 57/1000 [00:19<03:53,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0058\n",
      "projected feature shape= torch.Size([425, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███▊                                                              | 58/1000 [00:19<03:57,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0059\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███▉                                                              | 59/1000 [00:20<03:50,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0060\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███▉                                                              | 60/1000 [00:20<03:58,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0061\n",
      "projected feature shape= torch.Size([425, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████                                                              | 61/1000 [00:20<04:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0062\n",
      "projected feature shape= torch.Size([425, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████                                                              | 62/1000 [00:21<05:50,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0063\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▏                                                             | 63/1000 [00:21<05:43,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0064\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0065\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▎                                                             | 65/1000 [00:21<04:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0066\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▎                                                             | 66/1000 [00:22<04:03,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0067\n",
      "projected feature shape= torch.Size([350, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 350])\n",
      "0068\n",
      "projected feature shape= torch.Size([525, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▌                                                             | 69/1000 [00:22<02:58,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 525])\n",
      "0069\n",
      "projected feature shape= torch.Size([425, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0070\n",
      "projected feature shape= torch.Size([500, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▌                                                             | 70/1000 [00:22<02:51,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 500])\n",
      "0071\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▋                                                             | 71/1000 [00:22<03:01,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0072\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▊                                                             | 73/1000 [00:23<02:48,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0073\n",
      "projected feature shape= torch.Size([450, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0074\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▉                                                             | 74/1000 [00:23<03:01,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0075\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▉                                                             | 75/1000 [00:23<03:03,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0076\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████                                                             | 76/1000 [00:24<03:20,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0077\n",
      "projected feature shape= torch.Size([450, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0078\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▏                                                            | 78/1000 [00:24<02:43,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0079\n",
      "projected feature shape= torch.Size([525, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▎                                                            | 80/1000 [00:24<02:58,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 525])\n",
      "0080\n",
      "projected feature shape= torch.Size([450, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0081\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▎                                                            | 81/1000 [00:24<02:46,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0082\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▍                                                            | 82/1000 [00:25<02:52,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0083\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▍                                                            | 83/1000 [00:25<03:21,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0084\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▌                                                            | 84/1000 [00:25<03:35,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0085\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▌                                                            | 85/1000 [00:25<03:34,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0086\n",
      "projected feature shape= torch.Size([450, 384])\n",
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      " ** On entry to SLASCL parameter number  4 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|█████▋                                                            | 86/1000 [00:26<04:42,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0087\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|█████▋                                                            | 87/1000 [00:26<04:35,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0088\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|█████▊                                                            | 88/1000 [00:26<04:29,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0089\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████▉                                                            | 90/1000 [00:27<03:49,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0090\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0091\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████                                                            | 92/1000 [00:27<03:17,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0092\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0093\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▏                                                           | 93/1000 [00:27<03:25,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0094\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▏                                                           | 94/1000 [00:28<03:34,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0095\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▎                                                           | 95/1000 [00:28<03:37,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0096\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▎                                                           | 96/1000 [00:28<03:35,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0097\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▍                                                           | 97/1000 [00:28<03:45,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0098\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▌                                                           | 99/1000 [00:29<03:38,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      " ** On entry to SLASCL parameter number  4 had an illegal value\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0099\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0100\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▌                                                          | 100/1000 [00:29<03:49,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0101\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▋                                                          | 102/1000 [00:30<03:04,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0102\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0103\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▋                                                          | 103/1000 [00:30<02:57,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0104\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▊                                                          | 104/1000 [00:30<03:14,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0105\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▊                                                          | 105/1000 [00:30<03:22,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0106\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████▉                                                          | 107/1000 [00:31<03:02,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0107\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0108\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████                                                          | 108/1000 [00:31<02:45,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0109\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████                                                          | 109/1000 [00:31<03:11,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0110\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████▏                                                         | 110/1000 [00:31<03:23,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0111\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████▏                                                         | 111/1000 [00:32<03:31,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0112\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▎                                                         | 113/1000 [00:32<03:29,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0113\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0114\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████▍                                                         | 115/1000 [00:32<02:51,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0115\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0116\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▌                                                         | 116/1000 [00:33<03:03,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0117\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▌                                                         | 117/1000 [00:33<03:20,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0118\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▋                                                         | 118/1000 [00:33<03:29,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0119\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▋                                                         | 119/1000 [00:33<03:33,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0120\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▊                                                         | 120/1000 [00:34<03:46,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0121\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▊                                                         | 121/1000 [00:34<03:50,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0122\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▉                                                         | 122/1000 [00:34<03:46,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0123\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▉                                                         | 123/1000 [00:35<03:37,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0124\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████                                                         | 124/1000 [00:35<03:42,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0125\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████▏                                                        | 125/1000 [00:35<03:48,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0126\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0127\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▎                                                        | 127/1000 [00:35<02:58,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0128\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▎                                                        | 128/1000 [00:36<03:12,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0129\n",
      "projected feature shape= torch.Size([425, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▍                                                        | 129/1000 [00:36<03:23,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0130\n",
      "projected feature shape= torch.Size([425, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▍                                                        | 130/1000 [00:36<03:26,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0131\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▌                                                        | 131/1000 [00:36<03:35,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0132\n",
      "projected feature shape= torch.Size([400, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0133\n",
      "projected feature shape= torch.Size([525, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▋                                                        | 133/1000 [00:37<02:58,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 525])\n",
      "0134\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████▋                                                        | 134/1000 [00:37<03:04,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0135\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████▊                                                        | 136/1000 [00:37<02:59,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0136\n",
      "projected feature shape= torch.Size([450, 384])\n",
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0137\n",
      "projected feature shape= torch.Size([475, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████▉                                                        | 137/1000 [00:37<02:45,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 475])\n",
      "0138\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████▉                                                        | 138/1000 [00:38<02:57,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0139\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████                                                        | 139/1000 [00:38<03:12,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0140\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████                                                        | 140/1000 [00:38<03:27,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0141\n",
      "projected feature shape= torch.Size([350, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████▏                                                       | 141/1000 [00:39<03:35,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 350])\n",
      "0142\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████▏                                                       | 142/1000 [00:39<03:34,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0143\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████▎                                                       | 143/1000 [00:39<03:50,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0144\n",
      "projected feature shape= torch.Size([425, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████▎                                                       | 144/1000 [00:39<03:50,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 425])\n",
      "0145\n",
      "projected feature shape= torch.Size([450, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████▍                                                       | 145/1000 [00:40<03:47,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 450])\n",
      "0146\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████▍                                                       | 146/1000 [00:40<03:42,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 400])\n",
      "0147\n",
      "projected feature shape= torch.Size([550, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████▌                                                       | 147/1000 [00:40<03:48,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues shape torch.Size([5]) eigenvectors shape torch.Size([5, 550])\n",
      "0148\n",
      "projected feature shape= torch.Size([400, 384])\n"
     ]
    }
   ],
   "source": [
    "utils.make_output_dir(output_dir)\n",
    "feat_list=[]\n",
    "inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "for inp in tqdm(inputs):\n",
    "    index, features_file = inp\n",
    "    # print(index, features_file)\n",
    "     # Load\n",
    "    data_dict = torch.load(features_file, map_location='cpu')\n",
    "    # print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "    # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "    image_id = data_dict['file'][:-4]\n",
    "    print(image_id)\n",
    "    # Load\n",
    "    output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "    if Path(output_file).is_file():\n",
    "        print(f'Skipping existing file {str(output_file)}')\n",
    "        # break\n",
    "        # return  # skip because already generated\n",
    "\n",
    "    # Load affinity matrix\n",
    "    feats = data_dict[which_features].squeeze().cuda()\n",
    "    # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "    if normalize:\n",
    "        feats = F.normalize(feats, p=2, dim=-1)\n",
    "    # print(\"After normalization, Features Shape\",feats.shape)\n",
    "    # print(\"which_matrix=\", which_matrix)\n",
    "    # Eigenvectors of affinity matrix\n",
    "    if which_matrix == 'affinity_torch':\n",
    "        W = feats @ feats.T\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "            # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = torch.eig(W, eigenvectors=True)\n",
    "        eigenvalues = eigenvalues.cpu()\n",
    "        eigenvectors = eigenvectors.cpu()\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity_svd':\n",
    "        USV = torch.linalg.svd(feats, full_matrices=False)\n",
    "        eigenvectors = USV[0][:, :K].T.to('cpu', non_blocking=True)\n",
    "        eigenvalues = USV[1][:K].to('cpu', non_blocking=True)\n",
    "        print(\"which matrix=\",which_matrix,\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity':\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "        W = (feats @ feats.T)\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "        W = W.cpu().numpy()\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = eigsh(W, which='LM', k=K)\n",
    "        eigenvectors = torch.flip(torch.from_numpy(eigenvectors), dims=(-1,)).T\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of matting laplacian matrix\n",
    "    elif which_matrix in ['matting_laplacian', 'laplacian']:\n",
    "\n",
    "        # Get sizes\n",
    "        B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "        if image_downsample_factor is None:\n",
    "            image_downsample_factor = P\n",
    "        H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "        # Upscale features to match the resolution\n",
    "        if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "            feats = F.interpolate(\n",
    "                feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "                size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "            ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "        ### Feature affinities\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "\n",
    "        W_feat_ds = (feats @ feats.T)\n",
    "        # feat_list.append(feats)\n",
    "        # feat_dataset = Feature_Dataset(feats)\n",
    "        # if feats.shape[0]%2==0:\n",
    "        #     features_dataloader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True)\n",
    "        # else:\n",
    "        #     features_dataloader = DataLoader(feat_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        # model_simsiam = SimSiam()\n",
    "        # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        # model_simsiam.to(device)\n",
    "        # criterion = NegativeCosineSimilarity()\n",
    "        # optimizer = torch.optim.SGD(model_simsiam.parameters(), lr=0.06)\n",
    "        #\n",
    "        # print(\"type(features_dataloader\", type(features_dataloader))\n",
    "        # print(features_dataloader.shape)\n",
    "        # print(\"Starting Training\")\n",
    "        # for epoch in range(epochs):\n",
    "        #     total_loss = 0\n",
    "        #     for x0 in features_dataloader:\n",
    "        #     # for (x0), _, _ in features_dataloader:\n",
    "        #     #     print(\"Before Unsqueezing, x0 shape=\", x0.shape)\n",
    "        #         x0 = x0.unsqueeze(0).to(device)\n",
    "        #         # x0 = x0.unsqueeze(1).to(device)\n",
    "        #         # print(\"After Unsqueezing x0 shape=\", x0.shape)\n",
    "        #         x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "        #         # print(\"After Unsqueezing x1 shape=\", x1.shape)\n",
    "        #         # x0 = x0.squeeze(0).to(device)\n",
    "        #         # print(\"batch_size=\",batch_size)\n",
    "        #         # x0_new = torch.tensor(x0).view(batch_size, 1, 1, 384)\n",
    "        #         # x0_new = torch.tensor(x0).view(batch_size, 1, 384)\n",
    "        #         x0_new = x0.view(batch_size, 1, 384)\n",
    "        #         # print(\"After viewing x0 shape=\", x0_new.shape)\n",
    "        #         # print(\"x0.shape=\", x0.shape)\n",
    "        #         # x1 = x1.squeeze(0).to(device)\n",
    "        #         # x1 = torch.tensor(x1).view(batch_size, 1, 1,384)\n",
    "        #         x1_new = x1.view(batch_size, 1, 384)\n",
    "        #         # print(\"After viewing x1 shape=\", x1_new.shape)\n",
    "        #         z0, p0 = model_simsiam(x0_new, True)\n",
    "        #         # print(\"zo.shape\", z0.shape)\n",
    "        #         # print(\"p0.shape\", p0.shape)\n",
    "        #         z1, p1 = model_simsiam(x1_new, True)\n",
    "        #         loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        #         total_loss += loss.detach()\n",
    "        #         loss.backward()\n",
    "        #         optimizer.step()\n",
    "        #         optimizer.zero_grad()\n",
    "        #     avg_loss = total_loss / len(features_dataloader)\n",
    "        #     print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "        feats=feats.unsqueeze(1).to(device)\n",
    "        # feats=feats.unsqueeze(2).to(device)\n",
    "        # print(\"After Unsqueezing, feature size=\", feats.shape)\n",
    "        proj_pred_feature=model_simsiam(feats, False)\n",
    "        projected_feature=proj_pred_feature[0]\n",
    "        projected_feature = projected_feature.squeeze().to(device)\n",
    "        # print(\"type(projected_feature)\", type(projected_feature))\n",
    "        print(\"projected feature shape=\", projected_feature.shape)\n",
    "        W_feat_siam=torch.matmul(projected_feature, projected_feature.t())\n",
    "        W_feat=W_feat_ds + 0.1*W_feat_siam\n",
    "        # print(\"W_feat.shape=\", W_feat.shape)\n",
    "        # print(\"W_feat.shape=\", W_feat.shape)\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        if threshold_at_zero:\n",
    "            W_feat = (W_feat * (W_feat > 0))\n",
    "        W_feat = W_feat / W_feat.max()  # NOTE: If features are normalized, this naturally does nothing\n",
    "        # W_feat = W_feat.cpu().numpy()\n",
    "        W_feat = W_feat.detach().cpu().numpy()\n",
    "        # print(\"W_feat shape=\",W_feat.shape)\n",
    "\n",
    "        ### Color affinities\n",
    "        # If we are fusing with color affinites, then load the image and compute\n",
    "        if image_color_lambda > 0:\n",
    "\n",
    "            # Load image\n",
    "            image_file = str(Path(images_root) / f'{image_id}.jpg')\n",
    "            image_lr = Image.open(image_file).resize((W_pad_lr, H_pad_lr), Image.BILINEAR)\n",
    "            image_lr = np.array(image_lr) / 255.\n",
    "\n",
    "            # Color affinities (of type scipy.sparse.csr_matrix)\n",
    "            if which_color_matrix == 'knn':\n",
    "                W_lr = utils.knn_affinity(image_lr / 255)\n",
    "            elif which_color_matrix == 'rw':\n",
    "                W_lr = utils.rw_affinity(image_lr / 255)\n",
    "\n",
    "            # Convert to dense numpy array\n",
    "            W_color = np.array(W_lr.todense().astype(np.float32))\n",
    "            # print(\"W_color shape\", W_color.shape)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # No color affinity\n",
    "            W_color = 0\n",
    "\n",
    "        # Combine\n",
    "        W_comb = W_feat + W_color * image_color_lambda  # combination\n",
    "        D_comb = np.array(utils.get_diagonal(W_comb).todense())  # is dense or sparse faster? not sure, should check\n",
    "        # print(\"W_comb shape= \", W_comb.shape, \"D_comb shape\",  D_comb.shape)\n",
    "        if lapnorm:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM', M=D_comb)\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM', M=D_comb)\n",
    "        else:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM')\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM')\n",
    "        eigenvalues, eigenvectors = torch.from_numpy(eigenvalues), torch.from_numpy(eigenvectors.T).float()\n",
    "    print(\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "    # Sign ambiguity\n",
    "    for k in range(eigenvectors.shape[0]):\n",
    "        if 0.5 < torch.mean((eigenvectors[k] > 0).float()).item() < 1.0:  # reverse segment\n",
    "            eigenvectors[k] = 0 - eigenvectors[k]\n",
    "\n",
    "    # Save dict\n",
    "    output_dict = {'eigenvalues': eigenvalues, 'eigenvectors': eigenvectors}\n",
    "    torch.save(output_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
