{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "from pathlib import Path\n",
    "# from typing import Optional, Tuple\n",
    "# import cv2\n",
    "# import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from PIL import Image\n",
    "from scipy.sparse.linalg import eigsh\n",
    "# from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# from torchvision.utils import draw_bounding_boxes\n",
    "from tqdm import tqdm\n",
    "import extract_utils as utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from scipy.ndimage import affine_transform\n",
    "import datetime, dateutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract Eigen Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_root=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/images\"\n",
    "features_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/features/dino_vits16\"\n",
    "output_dir=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/eigs_dot1PCApred_ds_model_10_jn\"\n",
    "which_matrix= 'laplacian'\n",
    "which_color_matrix= 'knn'\n",
    "which_features= 'k'\n",
    "normalize=True\n",
    "threshold_at_zero=True\n",
    "lapnorm= True\n",
    "K= 5\n",
    "image_downsample_factor = None\n",
    "image_color_lambda = 0.0\n",
    "multiprocessing = 0\n",
    "batch_size=2\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Incorporating SimSiam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class Feature_Dataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SimSiam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.projection_head = SimSiamProjectionHead(feats.shape[1], 128,feats.shape[1])\n",
    "        self.prediction_head = SimSiamPredictionHead(feats.shape[1], 128, feats.shape[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.projection_head(x)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Based Training\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/1000 [00:00<?, ?it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  0%|                                                                   | 1/1000 [00:01<21:50,  1.31s/it]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  0%|▎                                                                  | 5/1000 [00:01<03:51,  4.29it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  1%|▋                                                                 | 10/1000 [00:02<02:19,  7.08it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  1%|▊                                                                 | 12/1000 [00:02<02:09,  7.63it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  2%|▉                                                                 | 15/1000 [00:03<01:58,  8.31it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  2%|█▎                                                                | 20/1000 [00:03<01:56,  8.39it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  2%|█▌                                                                | 24/1000 [00:04<02:06,  7.73it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  2%|█▋                                                                | 25/1000 [00:04<02:08,  7.62it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  3%|█▉                                                                | 30/1000 [00:05<02:14,  7.19it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  4%|██▍                                                               | 36/1000 [00:05<01:55,  8.37it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  4%|██▍                                                               | 37/1000 [00:05<01:56,  8.27it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  4%|██▌                                                               | 38/1000 [00:05<02:01,  7.95it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  4%|██▋                                                               | 41/1000 [00:06<01:44,  9.18it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  4%|██▉                                                               | 45/1000 [00:07<04:24,  3.61it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  5%|███                                                               | 46/1000 [00:07<03:42,  4.29it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  5%|███▎                                                              | 50/1000 [00:08<02:47,  5.66it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  5%|███▎                                                              | 51/1000 [00:08<02:39,  5.93it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  5%|███▍                                                              | 52/1000 [00:08<02:28,  6.38it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  5%|███▌                                                              | 54/1000 [00:08<02:14,  7.01it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  6%|███▋                                                              | 55/1000 [00:09<02:09,  7.29it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  6%|███▋                                                              | 56/1000 [00:09<02:02,  7.68it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  6%|███▊                                                              | 58/1000 [00:09<02:08,  7.33it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  6%|███▉                                                              | 59/1000 [00:09<02:01,  7.77it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████                                                              | 61/1000 [00:09<01:54,  8.20it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  6%|████▎                                                             | 65/1000 [00:10<01:53,  8.22it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  7%|████▎                                                             | 66/1000 [00:10<01:53,  8.22it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  7%|████▊                                                             | 72/1000 [00:12<03:40,  4.21it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  7%|████▊                                                             | 73/1000 [00:12<03:12,  4.81it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  8%|█████▏                                                            | 78/1000 [00:13<02:26,  6.31it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  8%|█████▏                                                            | 79/1000 [00:14<07:22,  2.08it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  8%|█████▎                                                            | 80/1000 [00:14<05:42,  2.69it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  8%|█████▍                                                            | 82/1000 [00:15<04:06,  3.73it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  9%|█████▊                                                            | 88/1000 [00:15<02:09,  7.06it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "  9%|█████▊                                                            | 89/1000 [00:15<02:12,  6.89it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 10%|██████▎                                                           | 96/1000 [00:17<02:21,  6.40it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 10%|██████▌                                                          | 100/1000 [00:17<02:12,  6.79it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 10%|██████▋                                                          | 103/1000 [00:18<02:03,  7.26it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 11%|██████▉                                                          | 107/1000 [00:18<01:58,  7.54it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 11%|███████                                                          | 108/1000 [00:18<01:50,  8.05it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 11%|███████                                                          | 109/1000 [00:18<01:50,  8.06it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 11%|███████▏                                                         | 110/1000 [00:18<01:44,  8.54it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 11%|███████▍                                                         | 114/1000 [00:19<02:00,  7.38it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 12%|███████▋                                                         | 118/1000 [00:20<02:01,  7.28it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 12%|███████▊                                                         | 120/1000 [00:20<02:04,  7.06it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 12%|███████▉                                                         | 122/1000 [00:20<01:54,  7.66it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 13%|████████▏                                                        | 126/1000 [00:21<02:00,  7.25it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 13%|████████▍                                                        | 130/1000 [00:21<01:49,  7.98it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████▌                                                        | 131/1000 [00:21<01:46,  8.16it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 13%|████████▋                                                        | 133/1000 [00:23<07:07,  2.03it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 14%|████████▊                                                        | 136/1000 [00:23<04:04,  3.53it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 14%|█████████                                                        | 139/1000 [00:24<02:48,  5.12it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 14%|█████████▎                                                       | 143/1000 [00:24<02:13,  6.42it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 14%|█████████▎                                                       | 144/1000 [00:24<02:10,  6.55it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 15%|█████████▍                                                       | 146/1000 [00:25<02:09,  6.57it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 15%|█████████▌                                                       | 148/1000 [00:26<04:50,  2.93it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 15%|█████████▊                                                       | 151/1000 [00:27<07:20,  1.93it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 15%|█████████▉                                                       | 153/1000 [00:28<04:57,  2.85it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 16%|██████████▏                                                      | 157/1000 [00:28<02:57,  4.76it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 16%|██████████▎                                                      | 159/1000 [00:28<02:15,  6.21it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 16%|██████████▍                                                      | 160/1000 [00:29<02:05,  6.71it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 16%|██████████▌                                                      | 162/1000 [00:29<01:41,  8.28it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 17%|██████████▉                                                      | 168/1000 [00:31<02:46,  4.99it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 17%|███████████▏                                                     | 173/1000 [00:31<01:55,  7.17it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 17%|███████████▎                                                     | 174/1000 [00:31<01:51,  7.42it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 18%|███████████▍                                                     | 175/1000 [00:31<01:50,  7.45it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 18%|███████████▋                                                     | 179/1000 [00:33<03:28,  3.95it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 18%|████████████                                                     | 185/1000 [00:38<12:18,  1.10it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 19%|████████████                                                     | 186/1000 [00:39<13:16,  1.02it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 19%|████████████▍                                                    | 192/1000 [00:40<03:31,  3.82it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████▊                                                    | 197/1000 [00:42<05:32,  2.42it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 20%|████████████▊                                                    | 198/1000 [00:42<04:17,  3.12it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 20%|█████████████                                                    | 200/1000 [00:42<02:54,  4.60it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 20%|█████████████▏                                                   | 202/1000 [00:42<02:18,  5.76it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 21%|█████████████▌                                                   | 209/1000 [00:43<02:33,  5.14it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 21%|█████████████▋                                                   | 211/1000 [00:44<02:29,  5.29it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 22%|██████████████                                                   | 217/1000 [00:46<02:22,  5.48it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 22%|██████████████▏                                                  | 218/1000 [00:46<02:11,  5.96it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 23%|██████████████▉                                                  | 229/1000 [00:47<01:36,  8.02it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 23%|███████████████                                                  | 231/1000 [00:48<05:06,  2.51it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 23%|███████████████▏                                                 | 233/1000 [00:49<03:33,  3.59it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 23%|███████████████▏                                                 | 234/1000 [00:49<03:03,  4.17it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 24%|███████████████▎                                                 | 235/1000 [00:49<02:42,  4.70it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 24%|███████████████▍                                                 | 237/1000 [00:49<02:01,  6.26it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 24%|███████████████▌                                                 | 239/1000 [00:49<01:42,  7.42it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 24%|███████████████▋                                                 | 241/1000 [00:49<01:29,  8.49it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 24%|███████████████▊                                                 | 243/1000 [00:50<01:25,  8.82it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 24%|███████████████▉                                                 | 245/1000 [00:50<01:22,  9.15it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 25%|████████████████▏                                                | 249/1000 [00:50<01:24,  8.85it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 25%|████████████████▍                                                | 252/1000 [00:51<01:32,  8.10it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 26%|████████████████▌                                                | 255/1000 [00:53<05:33,  2.23it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 26%|████████████████▋                                                | 257/1000 [00:53<04:01,  3.08it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████▉                                                | 261/1000 [00:54<02:39,  4.64it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 26%|█████████████████                                                | 263/1000 [00:54<02:12,  5.55it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 27%|█████████████████▎                                               | 266/1000 [00:55<03:43,  3.29it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 27%|█████████████████▍                                               | 268/1000 [00:57<07:02,  1.73it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 28%|█████████████████▉                                               | 275/1000 [00:59<04:40,  2.59it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 28%|██████████████████                                               | 277/1000 [01:00<05:22,  2.24it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 28%|██████████████████                                               | 278/1000 [01:01<07:06,  1.69it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 28%|██████████████████▍                                              | 284/1000 [01:03<03:19,  3.59it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 29%|██████████████████▊                                              | 289/1000 [01:03<02:04,  5.72it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 29%|███████████████████                                              | 294/1000 [01:04<01:40,  7.00it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 30%|███████████████████▎                                             | 298/1000 [01:05<01:15,  9.32it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 30%|███████████████████▌                                             | 301/1000 [01:05<01:20,  8.66it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 30%|███████████████████▋                                             | 303/1000 [01:05<01:21,  8.50it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 31%|████████████████████                                             | 308/1000 [01:06<01:22,  8.39it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 32%|████████████████████▍                                            | 315/1000 [01:07<01:24,  8.09it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 32%|████████████████████▌                                            | 316/1000 [01:07<01:29,  7.66it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 32%|████████████████████▊                                            | 320/1000 [01:07<01:38,  6.90it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 32%|████████████████████▉                                            | 323/1000 [01:08<01:28,  7.69it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 33%|█████████████████████▎                                           | 327/1000 [01:08<01:27,  7.67it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 34%|█████████████████████▊                                           | 335/1000 [01:09<01:13,  9.03it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 34%|█████████████████████▊                                           | 336/1000 [01:09<01:11,  9.25it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 34%|█████████████████████▉                                           | 337/1000 [01:09<01:13,  9.07it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 34%|██████████████████████▏                                          | 342/1000 [01:10<01:22,  7.96it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████▎                                          | 343/1000 [01:10<01:19,  8.27it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 35%|██████████████████████▊                                          | 350/1000 [01:11<01:21,  7.97it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 35%|██████████████████████▊                                          | 351/1000 [01:11<01:19,  8.17it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 35%|███████████████████████                                          | 354/1000 [01:12<02:18,  4.65it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 36%|███████████████████████▋                                         | 364/1000 [01:14<04:05,  2.59it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 37%|████████████████████████                                         | 370/1000 [01:17<07:03,  1.49it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 37%|████████████████████████▎                                        | 374/1000 [01:19<05:11,  2.01it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 38%|████████████████████████▌                                        | 378/1000 [01:21<04:27,  2.33it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 38%|████████████████████████▊                                        | 381/1000 [01:22<02:23,  4.30it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 39%|█████████████████████████▎                                       | 389/1000 [01:24<02:15,  4.51it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 39%|█████████████████████████▎                                       | 390/1000 [01:24<02:03,  4.94it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 39%|█████████████████████████▍                                       | 391/1000 [01:24<01:50,  5.51it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 39%|█████████████████████████▍                                       | 392/1000 [01:24<01:41,  5.98it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 39%|█████████████████████████▌                                       | 394/1000 [01:25<01:29,  6.74it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 40%|█████████████████████████▊                                       | 397/1000 [01:25<01:25,  7.09it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 40%|█████████████████████████▊                                       | 398/1000 [01:25<01:18,  7.66it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 40%|██████████████████████████                                       | 400/1000 [01:25<01:13,  8.18it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 40%|██████████████████████████▏                                      | 403/1000 [01:26<01:04,  9.19it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 41%|██████████████████████████▌                                      | 408/1000 [01:26<01:26,  6.87it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 41%|██████████████████████████▋                                      | 410/1000 [01:27<01:15,  7.85it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 41%|██████████████████████████▊                                      | 412/1000 [01:27<01:25,  6.90it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 41%|██████████████████████████▊                                      | 413/1000 [01:27<01:22,  7.10it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████                                      | 416/1000 [01:28<01:16,  7.61it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 43%|███████████████████████████▉                                     | 429/1000 [01:33<02:15,  4.22it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 43%|████████████████████████████▏                                    | 433/1000 [01:34<01:30,  6.23it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 44%|████████████████████████████▌                                    | 439/1000 [01:35<03:23,  2.75it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 44%|████████████████████████████▊                                    | 443/1000 [01:36<02:03,  4.52it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 44%|████████████████████████████▉                                    | 445/1000 [01:36<01:43,  5.39it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 45%|████████████████████████████▉                                    | 446/1000 [01:36<01:29,  6.18it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 45%|█████████████████████████████                                    | 448/1000 [01:37<01:16,  7.24it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 45%|█████████████████████████████▍                                   | 452/1000 [01:37<01:11,  7.66it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 46%|█████████████████████████████▌                                   | 455/1000 [01:37<01:04,  8.50it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 46%|█████████████████████████████▋                                   | 457/1000 [01:38<01:04,  8.42it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 46%|█████████████████████████████▊                                   | 458/1000 [01:38<01:05,  8.31it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 46%|█████████████████████████████▊                                   | 459/1000 [01:38<01:10,  7.68it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 46%|██████████████████████████████▏                                  | 464/1000 [01:39<01:05,  8.24it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 47%|██████████████████████████████▌                                  | 470/1000 [01:39<01:14,  7.07it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 47%|██████████████████████████████▋                                  | 472/1000 [01:40<01:15,  6.97it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 48%|███████████████████████████████▏                                 | 479/1000 [01:41<01:21,  6.40it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 49%|███████████████████████████████▌                                 | 486/1000 [01:43<01:31,  5.63it/s]/home/phdcs2/Hard_Disk/Projects/T2I/deep-spectral-segmentation/venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py:545: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 49%|███████████████████████████████▋                                 | 488/1000 [01:43<01:48,  4.71it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "model_path=\"/home/phdcs2/Hard_Disk/Datasets/Deep-Spectral-Segmentation/data/object-segmentation/ECSSD/weights/dot1_pcapredlinear_ds_10_model_jn%s.pt\" % (timestamp)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "utils.make_output_dir(output_dir)\n",
    "\n",
    "inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "pca_comp=128\n",
    "pca = PCA(n_components=pca_comp)\n",
    "layer=nn.Linear(pca_comp,pca_comp).cuda()\n",
    "\n",
    "criterion = NegativeCosineSimilarity()\n",
    "optimizer = torch.optim.SGD(layer.parameters(), lr=0.06)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting Model Based Training\")\n",
    "best_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch+1)\n",
    "    total_loss = 0\n",
    "    for inp in tqdm(inputs):\n",
    "        index, features_file = inp\n",
    "         # Load\n",
    "        data_dict = torch.load(features_file, map_location='cpu')\n",
    "        # image_id = data_dict['file'][:-4]\n",
    "        # Load\n",
    "        feats = data_dict[which_features].squeeze().cuda()\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "        if normalize:\n",
    "            feats = F.normalize(feats, p=2, dim=-1)\n",
    "\n",
    "        # Get sizes\n",
    "        B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "        if image_downsample_factor is None:\n",
    "            image_downsample_factor = P\n",
    "        H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "        # Upscale features to match the resolution\n",
    "        if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "            feats = F.interpolate(\n",
    "                feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "                size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "            ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "        ### Model-Based Optimization\n",
    "        x0=feats\n",
    "        x0_arr=x0.cpu()\n",
    "        \n",
    "        # print(x0_arr.shape)\n",
    "        z0_arr= pca.fit_transform(x0_arr)\n",
    "\n",
    "        \n",
    "        # Define the affine transformation parameters\n",
    "        scale = np.random.uniform(0.8, 1.2)  # Random scaling factor between 0.8 and 1.2\n",
    "        translation = np.random.uniform(-10, 10, size=2)  # Random translation vector between -10 and 10 in both directions\n",
    "        rotation = np.random.uniform(-15, 15)  # Random rotation angle between -15 and 15 degrees\n",
    "        shear = np.random.uniform(-0.2, 0.2, size=2)  # Random shear factor between -0.2 and 0.2 in both directions\n",
    "\n",
    "        # Define the affine matrix\n",
    "        affine_matrix = np.array([[scale * np.cos(rotation), -shear[0] * scale * np.sin(rotation), translation[0]],\n",
    "                                  [shear[1] * scale * np.sin(rotation), scale * np.cos(rotation), translation[1]],\n",
    "                                  [0, 0, 1]])\n",
    "        z1_arr=affine_transform(z0_arr, affine_matrix)\n",
    "        z1_arr=pca.fit_transform(z1_arr)\n",
    "        z0 = torch.from_numpy(z0_arr).float()\n",
    "        z1 = torch.from_numpy(z1_arr).float()\n",
    "        \n",
    "        z0 = z0.to(device)\n",
    "        z1 = z1.to(device)\n",
    "        p0=layer(z0)\n",
    "        p1=layer(z1)\n",
    "            \n",
    "#         x0 = x0.unsqueeze(0).to(device)\n",
    "#         x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "#         x0_new = x0.view(feats.shape[0], 1, 384)\n",
    "#         x1_new = x1.view(feats.shape[0], 1, 384)\n",
    "#         z0, p0 = model_simsiam(x0_new, True)\n",
    "#         z1, p1 = model_simsiam(x1_new, True)\n",
    "\n",
    "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    avg_val_loss = total_loss / len(inputs)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_val_loss:.5f}\")\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save(layer.state_dict(), model_path)\n",
    "        print(\"Saved Best Model! in epoch\", epoch+1)\n",
    "    else:\n",
    "        print(\"Weigh not updated in epoch\", epoch+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_comp=128\n",
    "pca = PCA(n_components=pca_comp)\n",
    "utils.make_output_dir(output_dir)\n",
    "inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "for inp in tqdm(inputs):\n",
    "    index, features_file = inp\n",
    "    print(index, features_file)\n",
    "     # Load\n",
    "    data_dict = torch.load(features_file, map_location='cpu')\n",
    "    print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "    # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "    image_id = data_dict['file'][:-4]\n",
    "    print(image_id)\n",
    "    # Load\n",
    "    output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "    if Path(output_file).is_file():\n",
    "        print(f'Skipping existing file {str(output_file)}')\n",
    "        # break\n",
    "        # return  # skip because already generated\n",
    "\n",
    "    # Load affinity matrix\n",
    "    feats = data_dict[which_features].squeeze().cuda()\n",
    "    # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "    if normalize:\n",
    "        feats = F.normalize(feats, p=2, dim=-1)\n",
    "    # print(\"After normalization, Features Shape\",feats.shape)\n",
    "    # print(\"which_matrix=\", which_matrix)\n",
    "    # Eigenvectors of affinity matrix\n",
    "    if which_matrix == 'affinity_torch':\n",
    "        W = feats @ feats.T\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "            # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = torch.eig(W, eigenvectors=True)\n",
    "        eigenvalues = eigenvalues.cpu()\n",
    "        eigenvectors = eigenvectors.cpu()\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity_svd':\n",
    "        USV = torch.linalg.svd(feats, full_matrices=False)\n",
    "        eigenvectors = USV[0][:, :K].T.to('cpu', non_blocking=True)\n",
    "        eigenvalues = USV[1][:K].to('cpu', non_blocking=True)\n",
    "        print(\"which matrix=\",which_matrix,\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of affinity matrix with scipy\n",
    "    elif which_matrix == 'affinity':\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "        W = (feats @ feats.T)\n",
    "        # W_feat=contrastive_affinity(feats, feats.T)\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        if threshold_at_zero:\n",
    "            W = (W * (W > 0))\n",
    "        W = W.cpu().numpy()\n",
    "        # print(\"W shape=\", W.shape)\n",
    "        eigenvalues, eigenvectors = eigsh(W, which='LM', k=K)\n",
    "        eigenvectors = torch.flip(torch.from_numpy(eigenvectors), dims=(-1,)).T\n",
    "        print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "    # Eigenvectors of matting laplacian matrix\n",
    "    elif which_matrix in ['matting_laplacian', 'laplacian']:\n",
    "\n",
    "        # Get sizes\n",
    "        B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "        if image_downsample_factor is None:\n",
    "            image_downsample_factor = P\n",
    "        H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "        # Upscale features to match the resolution\n",
    "        if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "            feats = F.interpolate(\n",
    "                feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "                size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "            ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "        ### Feature affinities\n",
    "        # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "\n",
    "        W_feat_ds = (feats @ feats.T)\n",
    "#         layer=nn.Linear(pca_comp,pca_comp).cuda()\n",
    "#         x0=feats\n",
    "#         x0_arr=x0.cpu()\n",
    "#         # print(x0_arr.shape)\n",
    "#         z0_arr= pca.fit_transform(x0_arr)\n",
    "\n",
    "#         # Define the affine transformation parameters\n",
    "#         scale = np.random.uniform(0.8, 1.2)  # Random scaling factor between 0.8 and 1.2\n",
    "#         translation = np.random.uniform(-10, 10, size=2)  # Random translation vector between -10 and 10 in both directions\n",
    "#         rotation = np.random.uniform(-15, 15)  # Random rotation angle between -15 and 15 degrees\n",
    "#         shear = np.random.uniform(-0.2, 0.2, size=2)  # Random shear factor between -0.2 and 0.2 in both directions\n",
    "\n",
    "#         # Define the affine matrix\n",
    "#         affine_matrix = np.array([[scale * np.cos(rotation), -shear[0] * scale * np.sin(rotation), translation[0]],\n",
    "#                                   [shear[1] * scale * np.sin(rotation), scale * np.cos(rotation), translation[1]],\n",
    "#                                   [0, 0, 1]])\n",
    "#         z1_arr=affine_transform(z0_arr, affine_matrix)\n",
    "#         z1_arr=pca.fit_transform(z1_arr)\n",
    "#         z0 = torch.from_numpy(z0_arr).float()\n",
    "#         z1 = torch.from_numpy(z1_arr).float()\n",
    "\n",
    "#         # feat_list.append(feats)\n",
    "#         feat_dataset_z0 = Feature_Dataset(z0)\n",
    "#         if feats.shape[0]%2==0:\n",
    "#             features_dataloader_z0 = DataLoader(feat_dataset_z0, batch_size=batch_size, shuffle=True)\n",
    "#         else:\n",
    "#             features_dataloader_z0 = DataLoader(feat_dataset_z0, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "#         feat_dataset_z1 = Feature_Dataset(z1)\n",
    "#         if feats.shape[0]%2==0:\n",
    "#             features_dataloader_z1 = DataLoader(feat_dataset_z1, batch_size=batch_size, shuffle=True)\n",
    "#         else:\n",
    "#             features_dataloader_z1 = DataLoader(feat_dataset_z1, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "#         device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#         criterion = NegativeCosineSimilarity()\n",
    "#         optimizer = torch.optim.SGD(layer.parameters(), lr=0.06)\n",
    "#         print(\"Starting Training\")\n",
    "#         for epoch in range(epochs):\n",
    "#             total_loss = 0\n",
    "#             for z0_new,z1_new in zip(features_dataloader_z0,features_dataloader_z1):\n",
    "#                 z0_new = z0_new.to(device)\n",
    "#                 z1_new = z1_new.to(device)\n",
    "#     #             print(\"z0_new.shape\", z0_new.shape)\n",
    "#     #             print(\"z1_new.shape\", z1_new.shape)\n",
    "#                 p0=layer(z0_new)\n",
    "#                 p1=layer(z1_new)\n",
    "#     #             print(\"p0.shape\", p0.shape)\n",
    "#     #             print(\"p1.shape\", p1.shape)\n",
    "#                 loss = 0.5 * (criterion(z0_new, p1) + criterion(z1_new, p0))\n",
    "#                 total_loss += loss.detach()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "#             avg_loss = total_loss / len(features_dataloader_z0)\n",
    "#             print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "#         projected_feature=layer(z0.to(device))\n",
    "#         print(projected_feature.shape)\n",
    "#         W_feat_siam=torch.matmul(projected_feature, projected_feature.t())\n",
    "        x0=feats\n",
    "        x0_arr=x0.cpu()\n",
    "        z0_arr= pca.fit_transform(x0_arr)\n",
    "        z0 = torch.from_numpy(z0_arr).float()\n",
    "        z0 = z0.to(device)\n",
    "        projected_feature=layer(z0)\n",
    "        print(projected_feature.shape)\n",
    "        W_feat_siam=torch.matmul(projected_feature, projected_feature.t())\n",
    "        W_feat=W_feat_ds + 0.1*W_feat_siam\n",
    "        if threshold_at_zero:\n",
    "            W_feat = (W_feat * (W_feat > 0))\n",
    "        W_feat = W_feat / W_feat.max()  # NOTE: If features are normalized, this naturally does nothing\n",
    "        # W_feat = W_feat.cpu().numpy()\n",
    "        W_feat = W_feat.detach().cpu().numpy()\n",
    "        # print(\"W_feat shape=\",W_feat.shape)\n",
    "\n",
    "        ### Color affinities\n",
    "        # If we are fusing with color affinites, then load the image and compute\n",
    "        if image_color_lambda > 0:\n",
    "\n",
    "            # Load image\n",
    "            image_file = str(Path(images_root) / f'{image_id}.jpg')\n",
    "            image_lr = Image.open(image_file).resize((W_pad_lr, H_pad_lr), Image.BILINEAR)\n",
    "            image_lr = np.array(image_lr) / 255.\n",
    "\n",
    "            # Color affinities (of type scipy.sparse.csr_matrix)\n",
    "            if which_color_matrix == 'knn':\n",
    "                W_lr = utils.knn_affinity(image_lr / 255)\n",
    "            elif which_color_matrix == 'rw':\n",
    "                W_lr = utils.rw_affinity(image_lr / 255)\n",
    "\n",
    "            # Convert to dense numpy array\n",
    "            W_color = np.array(W_lr.todense().astype(np.float32))\n",
    "            # print(\"W_color shape\", W_color.shape)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # No color affinity\n",
    "            W_color = 0\n",
    "\n",
    "        # Combine\n",
    "        W_comb = W_feat + W_color * image_color_lambda  # combination\n",
    "        D_comb = np.array(utils.get_diagonal(W_comb).todense())  # is dense or sparse faster? not sure, should check\n",
    "        # print(\"W_comb shape= \", W_comb.shape, \"D_comb shape\",  D_comb.shape)\n",
    "        if lapnorm:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM', M=D_comb)\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM', M=D_comb)\n",
    "        else:\n",
    "            try:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM')\n",
    "            except:\n",
    "                eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM')\n",
    "        eigenvalues, eigenvectors = torch.from_numpy(eigenvalues), torch.from_numpy(eigenvectors.T).float()\n",
    "    print(\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "    # Sign ambiguity\n",
    "    for k in range(eigenvectors.shape[0]):\n",
    "        if 0.5 < torch.mean((eigenvectors[k] > 0).float()).item() < 1.0:  # reverse segment\n",
    "            eigenvectors[k] = 0 - eigenvectors[k]\n",
    "\n",
    "    # Save dict\n",
    "    output_dict = {'eigenvalues': eigenvalues, 'eigenvectors': eigenvectors}\n",
    "    torch.save(output_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# utils.make_output_dir(output_dir)\n",
    "# feat_list=[]\n",
    "# inputs = list(enumerate(sorted(Path(features_dir).iterdir())))\n",
    "# for inp in tqdm(inputs):\n",
    "#     index, features_file = inp\n",
    "#     print(index, features_file)\n",
    "#      # Load\n",
    "#     data_dict = torch.load(features_file, map_location='cpu')\n",
    "#     print(data_dict.keys())   #['k', 'indices', 'file', 'id', 'model_name', 'patch_size', 'shape']\n",
    "#     # print(\"shape=\", data_dict['shape'], \"k shape\", data_dict['k'].shape, \"patch_size=\", data_dict['patch_size'])\n",
    "#     image_id = data_dict['file'][:-4]\n",
    "#     print(image_id)\n",
    "#     # Load\n",
    "#     output_file = str(Path(output_dir) / f'{image_id}.pth')\n",
    "#     if Path(output_file).is_file():\n",
    "#         print(f'Skipping existing file {str(output_file)}')\n",
    "#         # break\n",
    "#         # return  # skip because already generated\n",
    "\n",
    "#     # Load affinity matrix\n",
    "#     feats = data_dict[which_features].squeeze().cuda()\n",
    "#     # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "#     if normalize:\n",
    "#         feats = F.normalize(feats, p=2, dim=-1)\n",
    "#     # print(\"After normalization, Features Shape\",feats.shape)\n",
    "#     # print(\"which_matrix=\", which_matrix)\n",
    "#     # Eigenvectors of affinity matrix\n",
    "#     if which_matrix == 'affinity_torch':\n",
    "#         W = feats @ feats.T\n",
    "#         # W_feat=contrastive_affinity(feats, feats.T)\n",
    "#         # print(\"W shape=\", W.shape)\n",
    "#         if threshold_at_zero:\n",
    "#             W = (W * (W > 0))\n",
    "#             # print(\"W shape=\", W.shape)\n",
    "#         eigenvalues, eigenvectors = torch.eig(W, eigenvectors=True)\n",
    "#         eigenvalues = eigenvalues.cpu()\n",
    "#         eigenvectors = eigenvectors.cpu()\n",
    "#         print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "\n",
    "#     # Eigenvectors of affinity matrix with scipy\n",
    "#     elif which_matrix == 'affinity_svd':\n",
    "#         USV = torch.linalg.svd(feats, full_matrices=False)\n",
    "#         eigenvectors = USV[0][:, :K].T.to('cpu', non_blocking=True)\n",
    "#         eigenvalues = USV[1][:K].to('cpu', non_blocking=True)\n",
    "#         print(\"which matrix=\",which_matrix,\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "#     # Eigenvectors of affinity matrix with scipy\n",
    "#     elif which_matrix == 'affinity':\n",
    "#         # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "#         W = (feats @ feats.T)\n",
    "#         # W_feat=contrastive_affinity(feats, feats.T)\n",
    "#         # print(\"W shape=\", W.shape)\n",
    "#         if threshold_at_zero:\n",
    "#             W = (W * (W > 0))\n",
    "#         W = W.cpu().numpy()\n",
    "#         # print(\"W shape=\", W.shape)\n",
    "#         eigenvalues, eigenvectors = eigsh(W, which='LM', k=K)\n",
    "#         eigenvectors = torch.flip(torch.from_numpy(eigenvectors), dims=(-1,)).T\n",
    "#         print(\"which matrix=\",which_matrix, \"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "\n",
    "#     # Eigenvectors of matting laplacian matrix\n",
    "#     elif which_matrix in ['matting_laplacian', 'laplacian']:\n",
    "\n",
    "#         # Get sizes\n",
    "#         B, C, H, W, P, H_patch, W_patch, H_pad, W_pad = utils.get_image_sizes(data_dict)\n",
    "#         if image_downsample_factor is None:\n",
    "#             image_downsample_factor = P\n",
    "#         H_pad_lr, W_pad_lr = H_pad // image_downsample_factor, W_pad // image_downsample_factor\n",
    "\n",
    "#         # Upscale features to match the resolution\n",
    "#         if (H_patch, W_patch) != (H_pad_lr, W_pad_lr):\n",
    "#             feats = F.interpolate(\n",
    "#                 feats.T.reshape(1, -1, H_patch, W_patch),\n",
    "#                 size=(H_pad_lr, W_pad_lr), mode='bilinear', align_corners=False\n",
    "#             ).reshape(-1, H_pad_lr * W_pad_lr).T\n",
    "\n",
    "#         ### Feature affinities\n",
    "#         # print(\"Without normalizing, Features Shape is\",feats.shape)\n",
    "\n",
    "#         W_feat_ds = (feats @ feats.T)\n",
    "#         feats_arr=feats.cpu()\n",
    "        \n",
    "#         # feat_list.append(feats)\n",
    "#         feat_dataset = Feature_Dataset(feats)\n",
    "#         if feats.shape[0]%2==0:\n",
    "#             features_dataloader = DataLoader(feat_dataset, batch_size=2, shuffle=True)\n",
    "#         else:\n",
    "#             features_dataloader = DataLoader(feat_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
    "#         layer=nn.Linear(pca_comp,pca_comp).cuda()\n",
    "#         device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "#         criterion = NegativeCosineSimilarity()\n",
    "#         optimizer = torch.optim.SGD(model_simsiam.parameters(), lr=0.06)\n",
    "#         print(\"Starting Training\")\n",
    "#         for epoch in range(1):\n",
    "#             total_loss = 0\n",
    "#             for x0 in features_dataloader:\n",
    "#             # for (x0), _, _ in features_dataloader:\n",
    "#                 print(x0.shape)\n",
    "# #                 z0=pca.fit_transform()\n",
    "#                 x0 = x0.unsqueeze(0).to(device)\n",
    "#                 # print(x0.shape)\n",
    "#                 x1=torchvision.transforms.RandomAffine(0)(x0)\n",
    "#                 # print(x1.shape)\n",
    "#                 x0 = x0.squeeze(0).to(device)\n",
    "#                 # print(\"x0.shape=\", x0.shape)\n",
    "#                 x1 = x1.squeeze(0).to(device)\n",
    "#                 # print(\"x1 shape=\", x1.shape)\n",
    "\n",
    "#                 z0, p0 = model_simsiam(x0)\n",
    "#                 z1, p1 = model_simsiam(x1)\n",
    "#                 loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
    "#                 total_loss += loss.detach()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "#             avg_loss = total_loss / len(features_dataloader)\n",
    "#             print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "#         projected_feature=model_simsiam(feats)\n",
    "#         W_feat_siam=torch.matmul(projected_feature[0], projected_feature[0].t())\n",
    "#         W_feat=W_feat_ds + W_feat_siam\n",
    "#         # print(\"W_feat.shape=\", W_feat.shape)\n",
    "#         # print(\"W_feat.shape=\", W_feat.shape)\n",
    "#         # W_feat=contrastive_affinity(feats, feats.T)\n",
    "#         if threshold_at_zero:\n",
    "#             W_feat = (W_feat * (W_feat > 0))\n",
    "#         W_feat = W_feat / W_feat.max()  # NOTE: If features are normalized, this naturally does nothing\n",
    "#         # W_feat = W_feat.cpu().numpy()\n",
    "#         W_feat = W_feat.detach().cpu().numpy()\n",
    "#         # print(\"W_feat shape=\",W_feat.shape)\n",
    "\n",
    "#         ### Color affinities\n",
    "#         # If we are fusing with color affinites, then load the image and compute\n",
    "#         if image_color_lambda > 0:\n",
    "\n",
    "#             # Load image\n",
    "#             image_file = str(Path(images_root) / f'{image_id}.jpg')\n",
    "#             image_lr = Image.open(image_file).resize((W_pad_lr, H_pad_lr), Image.BILINEAR)\n",
    "#             image_lr = np.array(image_lr) / 255.\n",
    "\n",
    "#             # Color affinities (of type scipy.sparse.csr_matrix)\n",
    "#             if which_color_matrix == 'knn':\n",
    "#                 W_lr = utils.knn_affinity(image_lr / 255)\n",
    "#             elif which_color_matrix == 'rw':\n",
    "#                 W_lr = utils.rw_affinity(image_lr / 255)\n",
    "\n",
    "#             # Convert to dense numpy array\n",
    "#             W_color = np.array(W_lr.todense().astype(np.float32))\n",
    "#             # print(\"W_color shape\", W_color.shape)\n",
    "\n",
    "#         else:\n",
    "\n",
    "#             # No color affinity\n",
    "#             W_color = 0\n",
    "\n",
    "#         # Combine\n",
    "#         W_comb = W_feat + W_color * image_color_lambda  # combination\n",
    "#         D_comb = np.array(utils.get_diagonal(W_comb).todense())  # is dense or sparse faster? not sure, should check\n",
    "#         # print(\"W_comb shape= \", W_comb.shape, \"D_comb shape\",  D_comb.shape)\n",
    "#         if lapnorm:\n",
    "#             try:\n",
    "#                 eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM', M=D_comb)\n",
    "#             except:\n",
    "#                 eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM', M=D_comb)\n",
    "#         else:\n",
    "#             try:\n",
    "#                 eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, sigma=0, which='LM')\n",
    "#             except:\n",
    "#                 eigenvalues, eigenvectors = eigsh(D_comb - W_comb, k=K, which='SM')\n",
    "#         eigenvalues, eigenvectors = torch.from_numpy(eigenvalues), torch.from_numpy(eigenvectors.T).float()\n",
    "#     print(\"eigenvalues shape\", eigenvalues.shape, \"eigenvectors shape\", eigenvectors.shape)\n",
    "#     # Sign ambiguity\n",
    "#     for k in range(eigenvectors.shape[0]):\n",
    "#         if 0.5 < torch.mean((eigenvectors[k] > 0).float()).item() < 1.0:  # reverse segment\n",
    "#             eigenvectors[k] = 0 - eigenvectors[k]\n",
    "\n",
    "#     # Save dict\n",
    "#     output_dict = {'eigenvalues': eigenvalues, 'eigenvectors': eigenvectors}\n",
    "#     torch.save(output_dict, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
